{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Car Racing DQN agent \n",
        "Training a DQN agent for the OpenAI gym Car-Racing-v0 environment.\n",
        "\n",
        "\n",
        "### Notes\n",
        "- The first 50 frames afer resetting the environment are of the camera zooming into the track, and look very different from \"normal\" gameplay.\n",
        "    - I exclude these frames from the training of each episode.\n",
        "- Preprocessing\n",
        "    - I have applied similar preprocessing steps as used in the DeepMind paper.\n",
        "    - Images are converted to grayscale and cropped to $56 x 56$ to reduce dimensionality and speed up training.\n",
        "    - Consecutive frames are then stacked to form a $56 x 56 x 3$ image, where the channels represent the game screen at different points in time instead of RGB channels.\n",
        "- How often the target network weights are updated seems to make a BIG difference on training performance. Less seems to be more.\n",
        "\n",
        "### To do\n",
        "- Research literature.\n",
        "- Increase replay buffer size.\n",
        "- Trial simplified CNN architectures.\n",
        "- Add more frames to the frame stack.\n",
        "- Adjust max consecutive negative rewards threholds.\n",
        "- Trial different epsilon decay schedules.\n",
        "\n",
        "### Environment setup\n",
        "\n",
        "        conda create -c conda-forge -n gymenv swig pip  \n",
        "        conda activate gymenv  \n",
        "        pip install gym==0.17.3\n",
        "        pip install Box2D gym\n",
        "        pip install gym[all]\n",
        "\n",
        "        pip install tensorflow\n",
        "        pip install matplotlib\n",
        "\n",
        "        pip install gym pyvirtualdisplay   \n",
        "        sudo apt-get install -y xvfb python-opengl ffmpeg  \n",
        "\n",
        "        # The following steps are so that I can access the new env in Azure ML notebooks\n",
        "        conda install ipykernel\n",
        "        python -m ipykernel install --user --name gymenv --display-name \"Python (gymenv)\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### Useful links\n",
        "\n",
        "#### Papers\n",
        "https://arxiv.org/pdf/1312.5602.pdf \n",
        "\n",
        "#### Environment setup  \n",
        "https://stackoverflow.com/questions/60268769/gyms-box-2d-openai-doesnt-install-successfully-pip-error  \n",
        "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-access-terminal#add-new-kernels  \n",
        "\n",
        "#### Code adapted from:   \n",
        "https://keras.io/examples/rl/deep_q_network_breakout/  \n",
        "https://towardsdatascience.com/reinforcement-learning-w-keras-openai-dqns-1eed3a5338c  \n",
        "https://pythonprogramming.net/training-deep-q-learning-dqn-reinforcement-learning-python-tutorial/?completed=/deep-q-learning-dqn-reinforcement-learning-python-tutorial/   \n",
        "https://github.com/andywu0913/OpenAI-GYM-CarRacing-DQN  \n",
        "https://github.com/pekaalto/DQN "
      ],
      "metadata": {
        "id": "wue1BiEaaRFz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Import libraries"
      ],
      "metadata": {
        "id": "nva7ZgSRd0Rf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "from gym.wrappers import Monitor\n",
        "import glob\n",
        "import io\n",
        "import base64\n",
        "from IPython.display import HTML\n",
        "from pyvirtualdisplay import Display\n",
        "from IPython import display as ipythondisplay\n",
        "import pickle\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from collections import deque\n",
        "import time\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Sequential, load_model, Model\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Input, \\\n",
        "                        GlobalMaxPool2D, BatchNormalization, Dropout, Activation\n",
        "from keras.backend import clear_session\n",
        "\n",
        "display = Display(visible=0, size=(1400, 900))\n",
        "display.start()\n",
        "\n",
        "from dqn_agent import *\n",
        "from dqn_agent_trainer import *"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "id": "1TmGSnj7V38I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f8a4eb5-ac3f-49d5-fb14-1ced0acc16fe",
        "gather": {
          "logged": 1649539081083
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the DQN agent"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# actions = np.array([[0.0, 1.0, 0.0],  \r\n",
        "#                     [1.0, 0.0, 0.0],\r\n",
        "#                     [-1.0, 0.0, 0.0],\r\n",
        "#                     [0.0, 0.0, 0.8],\r\n",
        "#                     [0.0, 0.0, 0.0]]   \r\n",
        "#                 )\r\n",
        "# action_probs = np.array([0.5] + [(1 - 0.5)/4.0] * 4)\r\n",
        "\r\n",
        "actions = np.array([[0.0, 1.0, 0.0],  \r\n",
        "                    [0.0, 0.5, 0.0],  \r\n",
        "                    [1.0, 0.0, 0.0],\r\n",
        "                    [-1.0, 0.0, 0.0],\r\n",
        "                    [0.0, 0.0, 1.0],\r\n",
        "                    [0.0, 0.0, 0.5],   \r\n",
        "                    [0.0, 0.0, 0.0]]   \r\n",
        "                   )\r\n",
        "\r\n",
        "action_probs = [0.35, 0.15] + [(1 - 0.5)/5.0] * 5\r\n",
        "\r\n",
        "\r\n",
        "dqn_agent = DQNAgent(actions,\r\n",
        "                    action_probs,\r\n",
        "                    lr=0.00025, \r\n",
        "                    batch_size=32, \r\n",
        "                    gamma=0.95)\r\n",
        "\r\n",
        "agent_trainer = DQNAgentTrainer(img_len=56, \r\n",
        "                                frame_stack_num=4, \r\n",
        "                                number_of_episodes=800, \r\n",
        "                                epsilon=1.0, \r\n",
        "                                epsilon_min=0.05, \r\n",
        "                                epsilon_step_episodes=100.0,\r\n",
        "                                final_epsilon_episode=600,\r\n",
        "                                max_replay_memory_size=100000, \r\n",
        "                                min_replay_memory_size=1000, \r\n",
        "                                random_action_frames=2000,\r\n",
        "                                max_consecutive_negative_rewards=50, \r\n",
        "                                update_target_model_frames=5000, \r\n",
        "                                max_frames_per_episode=10000,\r\n",
        "                                skip_frames=4, \r\n",
        "                                save_training_frequency=10000, \r\n",
        "                                save_models=False, \r\n",
        "                                save_run_results=True,\r\n",
        "                                verbose_cnn=50, \r\n",
        "                                verbose=True)\r\n",
        "\r\n",
        "env = gym.make(\"CarRacing-v0\")\r\n",
        "agent_trainer.train_agent(env, dqn_agent)\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/anaconda/envs/gymenv/lib/python3.10/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n2022-04-09 21:17:46.367873: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n2022-04-09 21:17:46.367945: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (x-wing): /proc/driver/nvidia/version does not exist\n2022-04-09 21:17:46.368607: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Episode: 0\nTrack generation: 1069..1340 -> 271-tiles track\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 63\nReplay buffer size: 63\nTotal frame count: 63\nEpsilon: 1.0\nTotal reward for episode: 15.54074074074041\nRunning average rewards: 15.54074074074041 \n\nEpisode: 1\nTrack generation: 1003..1258 -> 255-tiles track\n"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 48>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m agent_trainer \u001b[38;5;241m=\u001b[39m DQNAgentTrainer(img_len\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m56\u001b[39m, \n\u001b[1;32m     28\u001b[0m                                 frame_stack_num\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, \n\u001b[1;32m     29\u001b[0m                                 number_of_episodes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m800\u001b[39m, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     44\u001b[0m                                 verbose_cnn\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, \n\u001b[1;32m     45\u001b[0m                                 verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     47\u001b[0m env \u001b[38;5;241m=\u001b[39m gym\u001b[38;5;241m.\u001b[39mmake(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCarRacing-v0\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 48\u001b[0m \u001b[43magent_trainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_agent\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdqn_agent\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/mnt/batch/tasks/shared/LS_root/mounts/clusters/x-wing/code/Users/CA_NightinG/rl_assignment_2/dqn/dqn_agent_trainer.py:88\u001b[0m, in \u001b[0;36mDQNAgentTrainer.train_agent\u001b[0;34m(self, env, agent)\u001b[0m\n\u001b[1;32m     85\u001b[0m     s_0, _, _, _ \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep([\u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m1.0\u001b[39m, \u001b[38;5;241m0.0\u001b[39m])\n\u001b[1;32m     87\u001b[0m \u001b[38;5;66;03m# Generate episode\u001b[39;00m\n\u001b[0;32m---> 88\u001b[0m episode_reward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_episode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms_0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43magent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m episode_rewards\u001b[38;5;241m.\u001b[39mappend(episode_reward)\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose:\n",
            "File \u001b[0;32m/mnt/batch/tasks/shared/LS_root/mounts/clusters/x-wing/code/Users/CA_NightinG/rl_assignment_2/dqn/dqn_agent_trainer.py:146\u001b[0m, in \u001b[0;36mDQNAgentTrainer.generate_episode\u001b[0;34m(self, s_0, env, agent)\u001b[0m\n\u001b[1;32m    143\u001b[0m action_reward \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskip_frames):\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;66;03m# Take action and reshape new state\u001b[39;00m\n\u001b[0;32m--> 146\u001b[0m     s_1, reward, done, _ \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactions\u001b[49m\u001b[43m[\u001b[49m\u001b[43ma_0\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    148\u001b[0m     action_reward \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m reward\n\u001b[1;32m    149\u001b[0m     episode_reward \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m reward\n",
            "File \u001b[0;32m/anaconda/envs/gymenv/lib/python3.10/site-packages/gym/wrappers/time_limit.py:16\u001b[0m, in \u001b[0;36mTimeLimit.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action):\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_elapsed_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot call env.step() before calling reset()\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 16\u001b[0m     observation, reward, done, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_elapsed_steps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_elapsed_steps \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_episode_steps:\n",
            "File \u001b[0;32m/anaconda/envs/gymenv/lib/python3.10/site-packages/gym/envs/box2d/car_racing.py:376\u001b[0m, in \u001b[0;36mCarRacing.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworld\u001b[38;5;241m.\u001b[39mStep(\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m FPS, \u001b[38;5;241m6\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m30\u001b[39m, \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m30\u001b[39m)\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mt \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m FPS\n\u001b[0;32m--> 376\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstate_pixels\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    378\u001b[0m step_reward \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    379\u001b[0m done \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
            "File \u001b[0;32m/anaconda/envs/gymenv/lib/python3.10/site-packages/gym/envs/box2d/car_racing.py:464\u001b[0m, in \u001b[0;36mCarRacing.render\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mviewer\u001b[38;5;241m.\u001b[39monetime_geoms \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    463\u001b[0m t\u001b[38;5;241m.\u001b[39mdisable()\n\u001b[0;32m--> 464\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender_indicators\u001b[49m\u001b[43m(\u001b[49m\u001b[43mWINDOW_W\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mWINDOW_H\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhuman\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    467\u001b[0m     win\u001b[38;5;241m.\u001b[39mflip()\n",
            "File \u001b[0;32m/anaconda/envs/gymenv/lib/python3.10/site-packages/gym/envs/box2d/car_racing.py:586\u001b[0m, in \u001b[0;36mCarRacing.render_indicators\u001b[0;34m(self, W, H)\u001b[0m\n\u001b[1;32m    584\u001b[0m vertical_ind(\u001b[38;5;241m9\u001b[39m, \u001b[38;5;241m0.01\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcar\u001b[38;5;241m.\u001b[39mwheels[\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m.\u001b[39momega, (\u001b[38;5;241m0.2\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m    585\u001b[0m vertical_ind(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m0.01\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcar\u001b[38;5;241m.\u001b[39mwheels[\u001b[38;5;241m3\u001b[39m]\u001b[38;5;241m.\u001b[39momega, (\u001b[38;5;241m0.2\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m--> 586\u001b[0m \u001b[43mhoriz_ind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m10.0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwheels\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoint\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mangle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    587\u001b[0m horiz_ind(\u001b[38;5;241m30\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.8\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcar\u001b[38;5;241m.\u001b[39mhull\u001b[38;5;241m.\u001b[39mangularVelocity, (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m    588\u001b[0m vl \u001b[38;5;241m=\u001b[39m pyglet\u001b[38;5;241m.\u001b[39mgraphics\u001b[38;5;241m.\u001b[39mvertex_list(\n\u001b[1;32m    589\u001b[0m     \u001b[38;5;28mlen\u001b[39m(polygons) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m3\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mv3f\u001b[39m\u001b[38;5;124m\"\u001b[39m, polygons), (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mc4f\u001b[39m\u001b[38;5;124m\"\u001b[39m, colors)  \u001b[38;5;66;03m# gl.GL_QUADS,\u001b[39;00m\n\u001b[1;32m    590\u001b[0m )\n",
            "File \u001b[0;32m/anaconda/envs/gymenv/lib/python3.10/site-packages/gym/envs/box2d/car_racing.py:559\u001b[0m, in \u001b[0;36mCarRacing.render_indicators.<locals>.horiz_ind\u001b[0;34m(place, val, color)\u001b[0m\n\u001b[1;32m    557\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhoriz_ind\u001b[39m(place, val, color):\n\u001b[1;32m    558\u001b[0m     colors\u001b[38;5;241m.\u001b[39mextend([color[\u001b[38;5;241m0\u001b[39m], color[\u001b[38;5;241m1\u001b[39m], color[\u001b[38;5;241m2\u001b[39m], \u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m4\u001b[39m)\n\u001b[0;32m--> 559\u001b[0m     \u001b[43mpolygons\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    560\u001b[0m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\n\u001b[1;32m    561\u001b[0m \u001b[43m            \u001b[49m\u001b[43m(\u001b[49m\u001b[43mplace\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    562\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    563\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    564\u001b[0m \u001b[43m            \u001b[49m\u001b[43m(\u001b[49m\u001b[43mplace\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mval\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    565\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    566\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[43m            \u001b[49m\u001b[43m(\u001b[49m\u001b[43mplace\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mval\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    568\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    569\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    570\u001b[0m \u001b[43m            \u001b[49m\u001b[43m(\u001b[49m\u001b[43mplace\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    571\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    572\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    573\u001b[0m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    574\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1649539070115
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the rewards\r\n",
        "episode_rewards = agent_trainer.episode_rewards\r\n",
        "\r\n",
        "plt.figure(figsize=(8, 6))\r\n",
        "plt.title('DQN Agent')\r\n",
        "plt.plot(episode_rewards, label='Episode reward')\r\n",
        "plt.plot([np.mean(episode_rewards[::-1][i:i+100]) for i in range(len(episode_rewards))][::-1], label='Average reward (last 100 episodes)')\r\n",
        "plt.ylim((-50, 800))\r\n",
        "plt.xlabel('episode')\r\n",
        "plt.ylabel('reward')\r\n",
        "plt.legend()\r\n",
        "plt.show()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 576x432 with 1 Axes>",
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1649531730398
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"./runs/dqn_results_20220409-160900.pickle\", 'rb') as fp:\r\n",
        "    results = pickle.load(fp)\r\n",
        "\r\n",
        "model = results['model']\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "2022-04-09 21:09:02.756199: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n2022-04-09 21:09:02.756266: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (x-wing): /proc/driver/nvidia/version does not exist\n2022-04-09 21:09:02.757036: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1649538543379
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env.close()"
      ],
      "outputs": [],
      "execution_count": 50,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1649487795461
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_q_model():\n",
        "    \"\"\"Returns a CNN model - same architecture as in the DeepMind paper.\"\"\"\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32, 8, activation='relu', strides=4,\n",
        "            input_shape=(56, 56, 4,)))\n",
        "    model.add(Conv2D(64, 4, activation='relu', strides=2))\n",
        "    model.add(Conv2D(64, 3, activation='relu', strides=1))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(512, activation='relu'))\n",
        "    model.add(Dense(num_actions, activation=\"linear\"))\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def image_processing(s):\n",
        "    \"\"\"Crop image, convert to grayscale and reshape.\"\"\"\n",
        "\n",
        "    s = s[20:76, 20:76, :]\n",
        "    s = np.dot(s[...,:3], [0.2989, 0.5870, 0.1140]).astype(np.int16)\n",
        "    s = np.reshape(s, (1, 56, 56))\n",
        "\n",
        "    return s\n",
        "\n",
        "\n",
        "def experience_replay(d, model, target_model, verbose=False):\n",
        "    \"\"\"Experience replay step.\"\"\"\n",
        "\n",
        "    # Create random batch from replay buffer\n",
        "    batch = random.sample(d, BATCH_SIZE)\n",
        "\n",
        "    # Get states\n",
        "    s_0 = np.array([np.reshape(x[0], (56, 56, 4)) for x in batch])\n",
        "    s_1 = np.array([np.reshape(x[3], (56, 56, 4)) for x in batch])\n",
        "\n",
        "    # Get q values from models\n",
        "    q_0 = model.predict(s_0)\n",
        "    q_1 = target_model.predict(s_1)\n",
        "\n",
        "    # Loop through batch and update q-values\n",
        "    for i, (_, a, r, _, done) in enumerate(batch):\n",
        "        if done:\n",
        "            q_new = r\n",
        "        else: \n",
        "            q_new = r + GAMMA * max(q_1[i])\n",
        "\n",
        "        # Update the q-value\n",
        "        q_0[i][a] = q_new \n",
        "\n",
        "    # Fit model\n",
        "    model.fit(s_0, q_0, epochs=1, batch_size=BATCH_SIZE, verbose=verbose)\n",
        "\n",
        "\n",
        "def get_stacked_state(grayscale_state_buffer):\n",
        "    \"\"\"Returns a stacked image from the grayscale buffer.\"\"\"\n",
        "\n",
        "    # Create image from grayscale buffer\n",
        "    img = np.zeros((56, 56, 4))\n",
        "    img[:, :, 0] = grayscale_state_buffer[0]\n",
        "    img[:, :, 1] = grayscale_state_buffer[1]\n",
        "    img[:, :, 2] = grayscale_state_buffer[2]\n",
        "    img[:, :, 3] = grayscale_state_buffer[3]\n",
        "    img = np.reshape(img, (1, 56, 56, 4))\n",
        "\n",
        "    # Remove first image from buffer\n",
        "    grayscale_state_buffer.popleft()\n",
        "    return img\n",
        "\n",
        "\n",
        "def generate_episode(s_0, env, d, actions, epsilon, frame_count):\n",
        "    \"\"\"Generate an episode of learning.\"\"\"\n",
        "    \n",
        "    episode_reward = 0\n",
        "    episode_frame_count = 0\n",
        "    consecutive_negative_rewards = 0\n",
        "\n",
        "    # Get stacked state representation\n",
        "    s_0 = image_processing(s_0)\n",
        "    grayscale_state_buffer = deque([s_0]*4)\n",
        "    s_0_stacked = get_stacked_state(grayscale_state_buffer)\n",
        "\n",
        "    while True:\n",
        "\n",
        "        # Increment counters\n",
        "        episode_frame_count += 1\n",
        "        frame_count += 1\n",
        "\n",
        "        # Select action\n",
        "        if frame_count < RANDOM_ACTION_FRAMES or np.random.rand() < epsilon:\n",
        "            a_0 = np.random.choice(np.arange(num_actions), p=PROBS)\n",
        "            #a_0 = random.choice(np.arange(num_actions))\n",
        "        else:\n",
        "            a_0 = np.argmax(model.predict(s_0_stacked))\n",
        "\n",
        "        # Action reward aggregates rewards over the skip frame loop\n",
        "        action_reward = 0\n",
        "        for _ in range(SKIP_FRAMES):\n",
        "            # Take action and reshape new state\n",
        "            s_1, reward, done, _ = env.step(actions[a_0])\n",
        "            \n",
        "            action_reward += reward\n",
        "            episode_reward += reward\n",
        "            if done:\n",
        "                break\n",
        "\n",
        "        # Increment consecutive negative reward counter\n",
        "        if action_reward < 0:\n",
        "            consecutive_negative_rewards += 1 \n",
        "        else: \n",
        "            consecutive_negative_rewards = 0\n",
        "\n",
        "        # Append latest state and get new stacked representation\n",
        "        s_1 = image_processing(s_1)\n",
        "        grayscale_state_buffer.append(s_1)\n",
        "        s_1_stacked = get_stacked_state(grayscale_state_buffer)\n",
        "\n",
        "        # Append (s, a, r, s') to d\n",
        "        d.append((s_0_stacked, a_0, action_reward, s_1_stacked, done))\n",
        "\n",
        "        # Start experience replay\n",
        "        if len(d) >= MIN_REPLAY_MEMORY_SIZE:\n",
        "            verbose = True if frame_count % VERBOSE_N == 0 else False\n",
        "            experience_replay(d, model, target_model, verbose)\n",
        "\n",
        "        # Drop the oldest experience if the length of d exceeeds MAX_REPLAY_MEMORY_SIZE\n",
        "        if len(d) > MAX_REPLAY_MEMORY_SIZE:\n",
        "            d.popleft()\n",
        "\n",
        "        # Set target weights to model weights\n",
        "        if frame_count % UPDATE_TARGET_MODEL_FRAMES == 0:\n",
        "            target_model.set_weights(model.get_weights())\n",
        "\n",
        "        # Save model\n",
        "        if frame_count % SAVE_TRAINING_FREQUENCY == 0 and SAVE_MODELS is True:\n",
        "            model.save(f'./saved_models/dqn_trial_{frame_count}.h5')\n",
        "\n",
        "        # End the episode if following conditions are met\n",
        "        if done or (episode_frame_count > MAX_FRAMES_PER_EPISODE) or (consecutive_negative_rewards > MAX_CONSECUTIVE_NEGATIVE_REWARDS):\n",
        "            print(f\"Ending episode: done {done}, consecutive negative rewards {consecutive_negative_rewards}\")\n",
        "            print(f\"Total frames in episode: {episode_frame_count}\")\n",
        "            break\n",
        "\n",
        "        # Current state  new state\n",
        "        s_0_stacked = s_1_stacked.copy()\n",
        "\n",
        "    print(f'Replay buffer size: {len(d)}')\n",
        "    return d, episode_reward, epsilon, frame_count\n",
        "\n",
        "\n",
        "def dqn_agent(s, actions, model):\n",
        "    \"\"\"Returns the best action as learnt by the DQN agent.\"\"\"\n",
        "    s = np.reshape(s, (1, 96, 96, 3))\n",
        "    action_index = np.argmax(model.predict(s))\n",
        "    return actions[action_index]\n"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "id": "z49ClA_j_uII",
        "gather": {
          "logged": 1649444867343
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Discretize actions\r\n",
        "actions = np.array([[0.0, 1.0, 0.0],  # Full throttle\r\n",
        "                    [1.0, 1.0, 0.0],\r\n",
        "                    [-1.0, 1.0, 0.0],\r\n",
        "                    [-1.0, 0.8, 0.0],  # Full left, half throttle\r\n",
        "                    [1.0, 0.8, 0.0],   # Full right, half throttle\r\n",
        "                    [-1.0, 0.0, 0.2], # Full left, quarter brake\r\n",
        "                    [1.0, 0.0, 0.2],  # Full right, quarter brake\r\n",
        "                    [0.0, 0.0, 0.2],  # Quarter brake\r\n",
        "                    [0.0, 0.0, 0.0]]   # No action\r\n",
        "                   )\r\n",
        "\r\n",
        "actions = np.array([[0.0, 1.0, 0.0],  \r\n",
        "                    [0.0, 0.5, 0.0],  \r\n",
        "                    [1.0, 0.0, 0.0],\r\n",
        "                    [-1.0, 0.0, 0.0],\r\n",
        "                    [0.0, 0.0, 1.0],\r\n",
        "                    [0.0, 0.0, 0.5],   \r\n",
        "                    [0.0, 0.0, 0.0]]   \r\n",
        "                   )\r\n",
        "\r\n",
        "num_actions = actions.shape[0]\r\n",
        "\r\n",
        "# When selecting random actions, put more weight on actions that move forward.\r\n",
        "# This seem to speed up training considerably.\r\n",
        "# PROBS = [0.3, 0.15, 0.15] + [(1 - 0.6)/6.0] * 6\r\n",
        "# sum(PROBS)\r\n",
        "\r\n",
        "\r\n",
        "PROBS = [0.35, 0.15] + [(1 - 0.5)/5.0] * 5\r\n",
        "PROBS\r\n"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 3,
          "data": {
            "text/plain": "[0.35, 0.15, 0.1, 0.1, 0.1, 0.1, 0.1]"
          },
          "metadata": {}
        }
      ],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1649444891578
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Init constants\n",
        "NUMBER_OF_EPISODES = 1000\n",
        "GAMMA = 0.95\n",
        "EPSILON_MIN = 0.05\n",
        "EPSILON_STEP_EPISODES = 100.0\n",
        "EPSILON_STEP = (1.0 - EPSILON_MIN)/EPSILON_STEP_EPISODES\n",
        "MAX_REPLAY_MEMORY_SIZE = 100000\n",
        "MIN_REPLAY_MEMORY_SIZE = 1000\n",
        "RANDOM_ACTION_FRAMES = 2000\n",
        "MAX_CONSECUTIVE_NEGATIVE_REWARDS = 50\n",
        "BATCH_SIZE = 32\n",
        "UPDATE_TARGET_MODEL_FRAMES = 5000\n",
        "MAX_FRAMES_PER_EPISODE = 10000\n",
        "SKIP_FRAMES = 4\n",
        "SAVE_TRAINING_FREQUENCY = 10000\n",
        "SAVE_MODELS = False\n",
        "VERBOSE_N = 50\n",
        "\n",
        "# Create models\n",
        "clear_session()\n",
        "target_model = create_q_model()\n",
        "model = create_q_model()\n",
        "loss_function = keras.losses.Huber()\n",
        "opt = Adam(learning_rate=0.00025, epsilon=1e-7, clipnorm=1.0)\n",
        "model.compile(loss=loss_function, optimizer=opt, metrics=['mean_squared_error'])\n",
        "target_model.compile(loss=loss_function, optimizer=opt, metrics=['mean_squared_error'])\n",
        "\n",
        "# Init variables\n",
        "epsilon = 1.0\n",
        "d = deque()\n",
        "episode_rewards =[]\n",
        "average_rewards = []\n",
        "frame_count = 0\n",
        "env = gym.make(\"CarRacing-v0\")\n",
        "\n",
        "# Train the agent!\n",
        "for i in range(NUMBER_OF_EPISODES):\n",
        "    print(f'Episode: {i}')\n",
        "    # Reset the environment\n",
        "    _ = env.reset()\n",
        "\n",
        "    # First 50 frames are zooming into track so ignore for training!\n",
        "    for _ in range(50):\n",
        "        s_0, _, _, _ = env.step([0.0, 1.0, 0.0])\n",
        "\n",
        "    # Generate episode\n",
        "    d, episode_reward, epsilon, frame_count = generate_episode(s_0, env, d, actions, epsilon, frame_count)\n",
        "    episode_rewards.append(episode_reward)\n",
        "\n",
        "    print(f'Total frame count: {frame_count}')\n",
        "    print(f'Epsilon: {epsilon}')\n",
        "    print(f'Total reward for episode: {episode_reward}')\n",
        "    print(f'Running average rewards: {np.mean(episode_rewards[-100:])} \\n')\n",
        "\n",
        "    # Start decaying epsilon when policy is used to select actions\n",
        "    if frame_count > RANDOM_ACTION_FRAMES and frame_count > MIN_REPLAY_MEMORY_SIZE:\n",
        "        epsilon =  max(EPSILON_MIN, epsilon - EPSILON_STEP)\n",
        "\n",
        "# Save model\n",
        "if SAVE_MODELS is True:\n",
        "    model.save(f'./saved_models/dqn_final.h5')\n",
        "\n",
        "env.close()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "2022-04-08 19:09:17.388344: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n2022-04-08 19:09:17.388418: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (x-wing): /proc/driver/nvidia/version does not exist\n2022-04-08 19:09:17.389948: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\nBad pipe message: %s [b'-\\nR(\\xc7/\\xc2U$d\\xb4\\x9fC>\\xe6\\xce\\xc1j \\xd2\\xe6\\x0f\\xc4\\xdc\\xdf\\xbd\\xdc|\\n\\xf3T\\xc3C\\t\\x90\\xf0\\xf9\\xe4G0\\xcf\\xd5\\x89_-L\\xd9\\xd8l\\x00\\xad\\x00\\x08\\x13\\x02\\x13\\x03\\x13\\x01\\x00\\xff\\x01\\x00\\x00\\x8f\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x0c\\x00\\n\\x00\\x1d\\x00\\x17\\x00\\x1e\\x00\\x19\\x00\\x18\\x00#\\x00\\x00\\x00\\x16\\x00\\x00\\x00\\x17\\x00\\x00\\x00\\r\\x00\\x1e\\x00\\x1c\\x04\\x03\\x05\\x03\\x06\\x03\\x08\\x07\\x08\\x08\\x08\\t\\x08\\n\\x08\\x0b\\x08\\x04']\nBad pipe message: %s [b'\\x08\\x06\\x04\\x01\\x05\\x01\\x06', b'']\nBad pipe message: %s [b'\\x03\\x02\\x03\\x04\\x00-\\x00\\x02\\x01\\x01\\x003\\x00&\\x00$\\x00\\x1d\\x00 q\\x1c\\xb9\\x9cQ\\xee\\xdb\\xd6)6\\xfd\\x9aK\\xfd\\x8dcY\\x876Ec(']\nBad pipe message: %s [b\"\\xa1\\xc9\\x1c{\\xce\\xa1$n\\xe8\\xe9M\\xe5\\x11q\\xc2\\x1f\\xc6\\xcd\\x00\\x00|\\xc0,\\xc00\\x00\\xa3\\x00\\x9f\\xcc\\xa9\\xcc\\xa8\\xcc\\xaa\\xc0\\xaf\\xc0\\xad\\xc0\\xa3\\xc0\\x9f\\xc0]\\xc0a\\xc0W\\xc0S\\xc0+\\xc0/\\x00\\xa2\\x00\\x9e\\xc0\\xae\\xc0\\xac\\xc0\\xa2\\xc0\\x9e\\xc0\\\\\\xc0`\\xc0V\\xc0R\\xc0$\\xc0(\\x00k\\x00j\\xc0#\\xc0'\\x00g\\x00@\\xc0\\n\\xc0\\x14\\x009\\x008\\xc0\\t\\xc0\\x13\\x003\\x002\\x00\\x9d\\xc0\\xa1\\xc0\\x9d\\xc0Q\\x00\\x9c\\xc0\\xa0\\xc0\\x9c\\xc0P\\x00=\\x00<\\x005\\x00/\\x00\\x9a\\x00\\x99\\xc0\\x07\\xc0\\x11\\x00\\x96\\x00\\x05\\x00\\xff\\x01\\x00\\x00j\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\"]\nBad pipe message: %s [b'']\nBad pipe message: %s [b'\\\\\\x97$\\x84\\x1e<@']\nBad pipe message: %s [b\"M\\xed\\x19\\xee=\\xad!\\xeeZ\\x00\\x00\\xa6\\xc0,\\xc00\\x00\\xa3\\x00\\x9f\\xcc\\xa9\\xcc\\xa8\\xcc\\xaa\\xc0\\xaf\\xc0\\xad\\xc0\\xa3\\xc0\\x9f\\xc0]\\xc0a\\xc0W\\xc0S\\xc0+\\xc0/\\x00\\xa2\\x00\\x9e\\xc0\\xae\\xc0\\xac\\xc0\\xa2\\xc0\\x9e\\xc0\\\\\\xc0`\\xc0V\\xc0R\\xc0$\\xc0(\\x00k\\x00j\\xc0s\\xc0w\\x00\\xc4\\x00\\xc3\\xc0#\\xc0'\\x00g\\x00@\\xc0r\\xc0v\\x00\\xbe\\x00\\xbd\\xc0\\n\\xc0\\x14\\x009\\x008\\x00\\x88\\x00\\x87\\xc0\\t\\xc0\\x13\\x003\\x002\\x00\\x9a\\x00\\x99\\x00E\\x00D\\xc0\\x07\\xc0\\x11\\xc0\\x08\\xc0\\x12\\x00\\x16\\x00\\x13\\x00\\x9d\\xc0\\xa1\\xc0\\x9d\\xc0Q\\x00\\x9c\\xc0\\xa0\\xc0\\x9c\\xc0P\\x00=\\x00\\xc0\\x00<\\x00\\xba\\x005\\x00\\x84\\x00/\\x00\\x96\\x00A\\x00\\x05\\x00\\n\\x00\\xff\\x01\\x00\\x00j\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x0c\"]\nBad pipe message: %s [b'<\\xf6\\x9f|\\xe8\\x7f\\xfd\\x03\\x90\\xf1\\xa1M\\xb8\\x8b\\xfdWfu\\x00\\x00>\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\xc0\\x0f\\xc0\\x05\\x005\\xc0\\x13\\xc0\\t\\x003\\x002\\x001\\x000\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00\\x96\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\x00\\xff\\x02\\x01\\x00\\x00C\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x1c\\x00\\x1a\\x00\\x17\\x00\\x19\\x00\\x1c\\x00\\x1b\\x00\\x18\\x00']\nBad pipe message: %s [b'\\x16\\x00\\x0e\\x00\\r\\x00\\x0b\\x00\\x0c\\x00\\t\\x00\\n\\x00#\\x00\\x00\\x00\\x0f\\x00\\x01\\x01\\x15\\x03\\x01']\nBad pipe message: %s [b'L\\xd9\\x8b\\x898\\xee\\x9c\\xec\\tar\\xb3 \\x83y\\x90e\\x90\\x00\\x00\\xa2\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\x00\\x88\\x00\\x87\\x00\\x86\\x00\\x85\\xc0\\x19\\x00:\\x00\\x89\\xc0\\x0f\\xc0\\x05\\x005\\x00\\x84\\xc0\\x13\\xc0\\t\\x003\\x002\\x001\\x000\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00E\\x00D\\x00C\\x00B\\xc0\\x18\\x004\\x00\\x9b\\x00F\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x96\\x00A\\x00']\nBad pipe message: %s [b'\\x11\\xc0\\x07\\xc0\\x16\\x00']\nBad pipe message: %s [b'\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\xc0\\x12\\xc0\\x08\\x00\\x16\\x00\\x13\\x00\\x10\\x00\\r\\xc0\\x17\\x00\\x1b']\nBad pipe message: %s [b'\\x12\\x93I\\x00\\xa7h\\x00\\x06?6u\\xe0\\x1e\\x8a\\xa7\\x80\\xd9\\xbe\\x00\\x00\\xa2\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\x00\\x88\\x00\\x87\\x00\\x86\\x00\\x85\\xc0\\x19\\x00:\\x00\\x89\\xc0\\x0f\\xc0\\x05\\x005\\x00\\x84\\xc0\\x13\\xc0\\t\\x003\\x002\\x001\\x000\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00E\\x00D\\x00C\\x00B\\xc0\\x18\\x004\\x00\\x9b\\x00F\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x96\\x00A\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x16\\x00\\x18\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\xc0\\x12\\xc0\\x08\\x00\\x16\\x00\\x13\\x00\\x10\\x00\\r\\xc0\\x17\\x00\\x1b\\xc0\\r\\xc0\\x03\\x00\\n\\x00\\x15\\x00\\x12\\x00\\x0f\\x00\\x0c\\x00\\x1a\\x00\\t\\x00\\x14\\x00\\x11\\x00\\x19\\x00\\x08\\x00\\x06\\x00\\x17\\x00\\x03\\xc0']\nBad pipe message: %s [b'\\x06\\xc0\\x15\\xc0\\x0b\\xc0\\x01\\x00\\x02\\x00\\x01\\x00\\xff\\x02\\x01']\nBad pipe message: %s [b\"\\xaa_\\xd6S\\x9e\\x87>\\xe8\\xa0\\x8a\\xf5\\xbc\\xbb\\xc6jEm>\\x00\\x00\\x86\\xc00\\xc0,\\xc0(\\xc0$\\xc0\\x14\\xc0\\n\\x00\\xa5\\x00\\xa3\\x00\\xa1\\x00\\x9f\\x00k\\x00j\\x00i\\x00h\\x009\\x008\\x007\\x006\\xc02\\xc0.\\xc0*\\xc0&\\xc0\\x0f\\xc0\\x05\\x00\\x9d\\x00=\\x005\\xc0/\\xc0+\\xc0'\\xc0#\\xc0\\x13\\xc0\\t\\x00\\xa4\\x00\\xa2\\x00\\xa0\\x00\\x9e\\x00g\\x00@\\x00?\\x00>\\x003\\x002\\x001\\x000\\xc01\\xc0-\\xc0)\\xc0%\\xc0\\x0e\\xc0\\x04\\x00\\x9c\\x00<\\x00/\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00\\x96\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\x00\\xff\\x02\\x01\\x00\\x00g\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0\", b'\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x1c\\x00\\x1a\\x00\\x17\\x00\\x19\\x00\\x1c\\x00\\x1b\\x00\\x18\\x00\\x1a\\x00\\x16\\x00\\x0e\\x00\\r\\x00\\x0b\\x00\\x0c\\x00\\t\\x00\\n\\x00#\\x00\\x00\\x00', b' \\x00\\x1e\\x06\\x01\\x06\\x02\\x06\\x03\\x05\\x01\\x05']\nBad pipe message: %s [b'\\x03', b'\\x04\\x02\\x04', b'\\x01\\x03', b'\\x03', b'\\x02', b'\\x03']\nBad pipe message: %s [b\"BM\\xc3|#\\xa2C.\\x14\\xd3\\xe0\\xb0$H\\xd9\\xdf0a\\x00\\x00\\xf4\\xc00\\xc0,\\xc0(\\xc0$\\xc0\\x14\\xc0\\n\\x00\\xa5\\x00\\xa3\\x00\\xa1\\x00\\x9f\\x00k\\x00j\\x00i\\x00h\\x009\\x008\\x007\\x006\\x00\\x88\\x00\\x87\\x00\\x86\\x00\\x85\\xc0\\x19\\x00\\xa7\\x00m\\x00:\\x00\\x89\\xc02\\xc0.\\xc0*\\xc0&\\xc0\\x0f\\xc0\\x05\\x00\\x9d\\x00=\\x005\\x00\\x84\\xc0/\\xc0+\\xc0'\\xc0#\\xc0\\x13\\xc0\\t\\x00\\xa4\\x00\\xa2\\x00\\xa0\\x00\\x9e\\x00g\\x00@\\x00?\\x00>\\x003\\x002\\x001\\x000\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00E\\x00D\\x00C\\x00B\\xc0\\x18\\x00\\xa6\\x00l\\x004\\x00\\x9b\\x00F\\xc01\\xc0-\\xc0)\\xc0%\\xc0\\x0e\\xc0\\x04\\x00\\x9c\\x00<\\x00/\\x00\\x96\\x00A\\x00\\x07\\xc0\", b'\\x07\\xc0\\x16\\x00\\x18\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\xc0\\x12\\xc0']\nBad pipe message: %s [b'\\x16\\x00\\x13\\x00\\x10\\x00\\r']\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Episode: 0\nTrack generation: 1200..1504 -> 304-tiles track\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 57\nReplay buffer size: 57\nTotal frame count: 57\nEpsilon: 1.0\nTotal reward for episode: -2.998019801980533\nRunning average rewards: -2.998019801980533 \n\nEpisode: 1\nTrack generation: 954..1199 -> 245-tiles track\nretry to generate track (normal if there are not manyinstances of this message)\nTrack generation: 1208..1514 -> 306-tiles track\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 60\nReplay buffer size: 117\nTotal frame count: 117\nEpsilon: 1.0\nTotal reward for episode: 8.786885245901317\nRunning average rewards: 2.894432721960392 \n\nEpisode: 2\nTrack generation: 1010..1272 -> 262-tiles track\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 112\nReplay buffer size: 229\nTotal frame count: 229\nEpsilon: 1.0\nTotal reward for episode: 27.996934865901018\nRunning average rewards: 11.261933436607267 \n\nEpisode: 3\nTrack generation: 1128..1413 -> 285-tiles track\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 97\nReplay buffer size: 326\nTotal frame count: 326\nEpsilon: 1.0\nTotal reward for episode: 6.974647887323432\nRunning average rewards: 10.19011204928631 \n\nEpisode: 4\nTrack generation: 1224..1534 -> 310-tiles track\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 58\nReplay buffer size: 384\nTotal frame count: 384\nEpsilon: 1.0\nTotal reward for episode: -0.5462783171524315\nRunning average rewards: 8.042833975998562 \n\nEpisode: 5\nTrack generation: 1316..1649 -> 333-tiles track\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 62\nReplay buffer size: 446\nTotal frame count: 446\nEpsilon: 1.0\nTotal reward for episode: 8.332530120481557\nRunning average rewards: 8.091116666745728 \n\nEpisode: 6\nTrack generation: 1258..1576 -> 318-tiles track\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 61\nReplay buffer size: 507\nTotal frame count: 507\nEpsilon: 1.0\nTotal reward for episode: 13.454889589905036\nRunning average rewards: 8.857369941482771 \n\nEpisode: 7\nTrack generation: 1015..1279 -> 264-tiles track\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 56\nReplay buffer size: 563\nTotal frame count: 563\nEpsilon: 1.0\nTotal reward for episode: -3.388593155893865\nRunning average rewards: 7.326624554310692 \n\nEpisode: 8\nTrack generation: 1131..1418 -> 287-tiles track\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 75\nReplay buffer size: 638\nTotal frame count: 638\nEpsilon: 1.0\nTotal reward for episode: 11.95804195804152\nRunning average rewards: 7.841226488058562 \n\nEpisode: 9\nTrack generation: 1263..1576 -> 313-tiles track\nretry to generate track (normal if there are not manyinstances of this message)\nTrack generation: 1224..1534 -> 310-tiles track\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 74\nReplay buffer size: 712\nTotal frame count: 712\nEpsilon: 1.0\nTotal reward for episode: 5.998705501617703\nRunning average rewards: 7.656974389414477 \n\nEpisode: 10\nTrack generation: 1160..1454 -> 294-tiles track\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 70\nReplay buffer size: 782\nTotal frame count: 782\nEpsilon: 1.0\nTotal reward for episode: 12.955631399317035\nRunning average rewards: 8.1386704812238 \n\nEpisode: 11\nTrack generation: 1146..1444 -> 298-tiles track\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 60\nReplay buffer size: 842\nTotal frame count: 842\nEpsilon: 1.0\nTotal reward for episode: 9.670033670033352\nRunning average rewards: 8.266284080291262 \n\nEpisode: 12\nTrack generation: 1099..1378 -> 279-tiles track\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 60\nReplay buffer size: 902\nTotal frame count: 902\nEpsilon: 1.0\nTotal reward for episode: 8.374100719424135\nRunning average rewards: 8.274577667916867 \n\nEpisode: 13\nTrack generation: 1027..1292 -> 265-tiles track\nretry to generate track (normal if there are not manyinstances of this message)\nTrack generation: 1043..1308 -> 265-tiles track\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 65\nReplay buffer size: 967\nTotal frame count: 967\nEpsilon: 1.0\nTotal reward for episode: 23.242424242424576\nRunning average rewards: 9.34370956609599 \n\nEpisode: 14\nTrack generation: 1189..1490 -> 301-tiles track\n1/1 [==============================] - 1s 603ms/step - loss: 2.1167 - mean_squared_error: 54.6318\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 61\nReplay buffer size: 1028\nTotal frame count: 1028\nEpsilon: 1.0\nTotal reward for episode: 15.599999999999675\nRunning average rewards: 9.760795595022902 \n\nEpisode: 15\nTrack generation: 1096..1374 -> 278-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2498 - mean_squared_error: 1.2869\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 59\nReplay buffer size: 1087\nTotal frame count: 1087\nEpsilon: 1.0\nTotal reward for episode: 8.890974729241556\nRunning average rewards: 9.706431790911568 \n\nEpisode: 16\nTrack generation: 1254..1574 -> 320-tiles track\nretry to generate track (normal if there are not manyinstances of this message)\nTrack generation: 1127..1413 -> 286-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.1338 - mean_squared_error: 0.4060\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1462 - mean_squared_error: 0.5462\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 75\nReplay buffer size: 1162\nTotal frame count: 1162\nEpsilon: 1.0\nTotal reward for episode: 12.105263157894306\nRunning average rewards: 9.84753951838114 \n\nEpisode: 17\nTrack generation: 1280..1604 -> 324-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.1960 - mean_squared_error: 0.7833\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 76\nReplay buffer size: 1238\nTotal frame count: 1238\nEpsilon: 1.0\nTotal reward for episode: 3.655727554179137\nRunning average rewards: 9.503549964814361 \n\nEpisode: 18\nTrack generation: 1144..1434 -> 290-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2179 - mean_squared_error: 0.9184\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1496 - mean_squared_error: 0.5577\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 80\nReplay buffer size: 1318\nTotal frame count: 1318\nEpsilon: 1.0\nTotal reward for episode: 9.522491349480529\nRunning average rewards: 9.504546879796791 \n\nEpisode: 19\nTrack generation: 1214..1527 -> 313-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0850 - mean_squared_error: 0.2378\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0986 - mean_squared_error: 0.2998\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1575 - mean_squared_error: 0.5289\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 139\nReplay buffer size: 1457\nTotal frame count: 1457\nEpsilon: 1.0\nTotal reward for episode: 18.117948717948025\nRunning average rewards: 9.935216971704353 \n\nEpisode: 20\nTrack generation: 1233..1545 -> 312-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.1114 - mean_squared_error: 0.3233\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 91\nReplay buffer size: 1548\nTotal frame count: 1548\nEpsilon: 1.0\nTotal reward for episode: -1.0302250803863515\nRunning average rewards: 9.41305306446194 \n\nEpisode: 21\nTrack generation: 945..1185 -> 240-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.1581 - mean_squared_error: 0.4738\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0673 - mean_squared_error: 0.1631\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 99\nReplay buffer size: 1647\nTotal frame count: 1647\nEpsilon: 1.0\nTotal reward for episode: 10.609205020920022\nRunning average rewards: 9.467423607937308 \n\nEpisode: 22\nTrack generation: 1188..1489 -> 301-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.1111 - mean_squared_error: 0.3195\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1678 - mean_squared_error: 0.6475\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 83\nReplay buffer size: 1730\nTotal frame count: 1730\nEpsilon: 1.0\nTotal reward for episode: 10.133333333332882\nRunning average rewards: 9.496376204693636 \n\nEpisode: 23\nTrack generation: 1052..1319 -> 267-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0824 - mean_squared_error: 0.2826\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1208 - mean_squared_error: 0.3989\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 80\nReplay buffer size: 1810\nTotal frame count: 1810\nEpsilon: 1.0\nTotal reward for episode: 20.631578947368475\nRunning average rewards: 9.960342985638421 \n\nEpisode: 24\nTrack generation: 1263..1583 -> 320-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0706 - mean_squared_error: 0.1811\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 59\nReplay buffer size: 1869\nTotal frame count: 1869\nEpsilon: 1.0\nTotal reward for episode: 4.613166144200285\nRunning average rewards: 9.746455911980895 \n\nEpisode: 25\nTrack generation: 1075..1348 -> 273-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0994 - mean_squared_error: 0.2752\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 66\nReplay buffer size: 1935\nTotal frame count: 1935\nEpsilon: 1.0\nTotal reward for episode: 25.070588235294558\nRunning average rewards: 10.335845616723729 \n\nEpisode: 26\nTrack generation: 1210..1516 -> 306-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.1640 - mean_squared_error: 0.4946\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 59\nReplay buffer size: 1994\nTotal frame count: 1994\nEpsilon: 1.0\nTotal reward for episode: 9.186885245901323\nRunning average rewards: 10.293291528915491 \n\nEpisode: 27\nTrack generation: 1154..1447 -> 293-tiles track\n1/1 [==============================] - 0s 9ms/step - loss: 0.0739 - mean_squared_error: 0.2259\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0867 - mean_squared_error: 0.2727\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 67\nReplay buffer size: 2061\nTotal frame count: 2061\nEpsilon: 1.0\nTotal reward for episode: 21.145205479452045\nRunning average rewards: 10.680859884291795 \n\nEpisode: 28\nTrack generation: 994..1246 -> 252-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0540 - mean_squared_error: 0.1325\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 71\nReplay buffer size: 2132\nTotal frame count: 2132\nEpsilon: 0.9905\nTotal reward for episode: 23.392828685259452\nRunning average rewards: 11.119203636049303 \n\nEpisode: 29\nTrack generation: 1206..1512 -> 306-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0595 - mean_squared_error: 0.1749\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0675 - mean_squared_error: 0.1601\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 79\nReplay buffer size: 2211\nTotal frame count: 2211\nEpsilon: 0.9810000000000001\nTotal reward for episode: 7.7442622950815405\nRunning average rewards: 11.006705591350377 \n\nEpisode: 30\nTrack generation: 984..1234 -> 250-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0848 - mean_squared_error: 0.2077\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 63\nReplay buffer size: 2274\nTotal frame count: 2274\nEpsilon: 0.9715000000000001\nTotal reward for episode: 35.04096385542297\nRunning average rewards: 11.782004245030139 \n\nEpisode: 31\nTrack generation: 1293..1620 -> 327-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0602 - mean_squared_error: 0.1458\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1008 - mean_squared_error: 0.3025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 81\nReplay buffer size: 2355\nTotal frame count: 2355\nEpsilon: 0.9620000000000002\nTotal reward for episode: 7.477300613496496\nRunning average rewards: 11.647482256544713 \n\nEpisode: 32\nTrack generation: 1212..1517 -> 305-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0799 - mean_squared_error: 0.2190\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1026 - mean_squared_error: 0.3537\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 110\nReplay buffer size: 2465\nTotal frame count: 2465\nEpsilon: 0.9525000000000002\nTotal reward for episode: -4.526315789474296\nRunning average rewards: 11.157367164241105 \n\nEpisode: 33\nTrack generation: 1114..1405 -> 291-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0580 - mean_squared_error: 0.1483\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 60\nReplay buffer size: 2525\nTotal frame count: 2525\nEpsilon: 0.9430000000000003\nTotal reward for episode: 7.0344827586203635\nRunning average rewards: 11.036105858193437 \n\nEpisode: 34\nTrack generation: 1139..1428 -> 289-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0665 - mean_squared_error: 0.2201\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0642 - mean_squared_error: 0.1638\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 81\nReplay buffer size: 2606\nTotal frame count: 2606\nEpsilon: 0.9335000000000003\nTotal reward for episode: 5.794444444443979\nRunning average rewards: 10.88634410351488 \n\nEpisode: 35\nTrack generation: 1036..1299 -> 263-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0841 - mean_squared_error: 0.3180\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0855 - mean_squared_error: 0.3054\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 104\nReplay buffer size: 2710\nTotal frame count: 2710\nEpsilon: 0.9240000000000004\nTotal reward for episode: 15.65190839694609\nRunning average rewards: 11.018720889443525 \n\nEpisode: 36\nTrack generation: 1162..1456 -> 294-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.1273 - mean_squared_error: 0.3600\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 89\nReplay buffer size: 2799\nTotal frame count: 2799\nEpsilon: 0.9145000000000004\nTotal reward for episode: 15.594539249146287\nRunning average rewards: 11.142391655921978 \n\nEpisode: 37\nTrack generation: 1063..1335 -> 272-tiles track\nretry to generate track (normal if there are not manyinstances of this message)\nTrack generation: 1190..1492 -> 302-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0556 - mean_squared_error: 0.1525\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0543 - mean_squared_error: 0.1287\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 89\nReplay buffer size: 2888\nTotal frame count: 2888\nEpsilon: 0.9050000000000005\nTotal reward for episode: 4.26710963455097\nRunning average rewards: 10.961463181675374 \n\nEpisode: 38\nTrack generation: 1221..1530 -> 309-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0596 - mean_squared_error: 0.2228\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0878 - mean_squared_error: 0.2707\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 64\nReplay buffer size: 2952\nTotal frame count: 2952\nEpsilon: 0.8955000000000005\nTotal reward for episode: 13.361038961038567\nRunning average rewards: 11.022990765761609 \n\nEpisode: 39\nTrack generation: 1084..1359 -> 275-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.1390 - mean_squared_error: 0.4968\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 95\nReplay buffer size: 3047\nTotal frame count: 3047\nEpsilon: 0.8860000000000006\nTotal reward for episode: 20.394160583941726\nRunning average rewards: 11.257270011216113 \n\nEpisode: 40\nTrack generation: 1106..1387 -> 281-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0452 - mean_squared_error: 0.1280\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1085 - mean_squared_error: 0.3450\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 67\nReplay buffer size: 3114\nTotal frame count: 3114\nEpsilon: 0.8765000000000006\nTotal reward for episode: -1.800000000000388\nRunning average rewards: 10.93880001094254 \n\nEpisode: 41\nTrack generation: 1244..1559 -> 315-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0893 - mean_squared_error: 0.4335\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 64\nReplay buffer size: 3178\nTotal frame count: 3178\nEpsilon: 0.8670000000000007\nTotal reward for episode: 9.4318471337576\nRunning average rewards: 10.902920180533375 \n\nEpisode: 42\nTrack generation: 1049..1315 -> 266-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0915 - mean_squared_error: 0.3486\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0651 - mean_squared_error: 0.1565\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 116\nReplay buffer size: 3294\nTotal frame count: 3294\nEpsilon: 0.8575000000000007\nTotal reward for episode: -1.1169811320761198\nRunning average rewards: 10.623387591868036 \n\nEpisode: 43\nTrack generation: 1088..1364 -> 276-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0628 - mean_squared_error: 0.1727\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0547 - mean_squared_error: 0.1506\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 58\nReplay buffer size: 3352\nTotal frame count: 3352\nEpsilon: 0.8480000000000008\nTotal reward for episode: -5.018181818182157\nRunning average rewards: 10.26789737800326 \n\nEpisode: 44\nTrack generation: 1118..1402 -> 284-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0273 - mean_squared_error: 0.0605\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 84\nReplay buffer size: 3436\nTotal frame count: 3436\nEpsilon: 0.8385000000000008\nTotal reward for episode: 1.7356890459358922\nRunning average rewards: 10.078292748401763 \n\nEpisode: 45\nTrack generation: 1175..1473 -> 298-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0663 - mean_squared_error: 0.1784\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0684 - mean_squared_error: 0.2058\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 88\nReplay buffer size: 3524\nTotal frame count: 3524\nEpsilon: 0.8290000000000008\nTotal reward for episode: 8.571043771043303\nRunning average rewards: 10.045526466285276 \n\nEpisode: 46\nTrack generation: 1132..1419 -> 287-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0530 - mean_squared_error: 0.1188\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 55\nReplay buffer size: 3579\nTotal frame count: 3579\nEpsilon: 0.8195000000000009\nTotal reward for episode: -8.01398601398633\nRunning average rewards: 9.661281519896518 \n\nEpisode: 47\nTrack generation: 1311..1653 -> 342-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0766 - mean_squared_error: 0.1989\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 59\nReplay buffer size: 3638\nTotal frame count: 3638\nEpsilon: 0.8100000000000009\nTotal reward for episode: 5.725513196480595\nRunning average rewards: 9.579286346492017 \n\nEpisode: 48\nTrack generation: 1272..1594 -> 322-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.1016 - mean_squared_error: 0.3092\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0895 - mean_squared_error: 0.2630\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0642 - mean_squared_error: 0.1543\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0847 - mean_squared_error: 0.2203\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0946 - mean_squared_error: 0.3034\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 219\nReplay buffer size: 3857\nTotal frame count: 3857\nEpsilon: 0.800500000000001\nTotal reward for episode: 68.163239875394\nRunning average rewards: 10.774877234836957 \n\nEpisode: 49\nTrack generation: 1035..1306 -> 271-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0690 - mean_squared_error: 0.2472\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0957 - mean_squared_error: 0.3765\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 119\nReplay buffer size: 3976\nTotal frame count: 3976\nEpsilon: 0.791000000000001\nTotal reward for episode: 52.40000000000228\nRunning average rewards: 11.607379690140263 \n\nEpisode: 50\nTrack generation: 1027..1293 -> 266-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0728 - mean_squared_error: 0.1820\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 59\nReplay buffer size: 4035\nTotal frame count: 4035\nEpsilon: 0.7815000000000011\nTotal reward for episode: 6.588679245282691\nRunning average rewards: 11.508973799064625 \n\nEpisode: 51\nTrack generation: 1167..1463 -> 296-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0958 - mean_squared_error: 0.3064\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 60\nReplay buffer size: 4095\nTotal frame count: 4095\nEpsilon: 0.7720000000000011\nTotal reward for episode: 13.288135593219977\nRunning average rewards: 11.543188448952227 \n\nEpisode: 52\nTrack generation: 1256..1574 -> 318-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.1045 - mean_squared_error: 0.3398\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0446 - mean_squared_error: 0.0955\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0812 - mean_squared_error: 0.2623\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 123\nReplay buffer size: 4218\nTotal frame count: 4218\nEpsilon: 0.7625000000000012\nTotal reward for episode: -8.190536277603186\nRunning average rewards: 11.170854020149294 \n\nEpisode: 53\nTrack generation: 1215..1531 -> 316-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0820 - mean_squared_error: 0.2524\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0542 - mean_squared_error: 0.1762\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 116\nReplay buffer size: 4334\nTotal frame count: 4334\nEpsilon: 0.7530000000000012\nTotal reward for episode: 23.441269841270383\nRunning average rewards: 11.398083942762648 \n\nEpisode: 54\nTrack generation: 1259..1578 -> 319-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0535 - mean_squared_error: 0.1250\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 65\nReplay buffer size: 4399\nTotal frame count: 4399\nEpsilon: 0.7435000000000013\nTotal reward for episode: 14.880503144653744\nRunning average rewards: 11.461400655524304 \n\nEpisode: 55\nTrack generation: 1244..1559 -> 315-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0389 - mean_squared_error: 0.0868\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0916 - mean_squared_error: 0.2496\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 55\nReplay buffer size: 4454\nTotal frame count: 4454\nEpsilon: 0.7340000000000013\nTotal reward for episode: -9.26114649681557\nRunning average rewards: 11.091355170661092 \n\nEpisode: 56\nTrack generation: 1051..1327 -> 276-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0747 - mean_squared_error: 0.2186\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 56\nReplay buffer size: 4510\nTotal frame count: 4510\nEpsilon: 0.7245000000000014\nTotal reward for episode: -4.2181818181821455\nRunning average rewards: 10.822766802435773 \n\nEpisode: 57\nTrack generation: 1320..1654 -> 334-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0973 - mean_squared_error: 0.2506\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 57\nReplay buffer size: 4567\nTotal frame count: 4567\nEpsilon: 0.7150000000000014\nTotal reward for episode: -4.781981981982312\nRunning average rewards: 10.553719409600978 \n\nEpisode: 58\nTrack generation: 1268..1589 -> 321-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0587 - mean_squared_error: 0.2179\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1015 - mean_squared_error: 0.3818\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 131\nReplay buffer size: 4698\nTotal frame count: 4698\nEpsilon: 0.7055000000000015\nTotal reward for episode: -5.525000000000745\nRunning average rewards: 10.281198741641626 \n\nEpisode: 59\nTrack generation: 1131..1418 -> 287-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0720 - mean_squared_error: 0.1801\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0870 - mean_squared_error: 0.2825\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 69\nReplay buffer size: 4767\nTotal frame count: 4767\nEpsilon: 0.6960000000000015\nTotal reward for episode: 14.358041958041568\nRunning average rewards: 10.349146128581625 \n\nEpisode: 60\nTrack generation: 1104..1384 -> 280-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0807 - mean_squared_error: 0.2185\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0254 - mean_squared_error: 0.0522\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 83\nReplay buffer size: 4850\nTotal frame count: 4850\nEpsilon: 0.6865000000000016\nTotal reward for episode: 2.6422939068095594\nRunning average rewards: 10.222804288880443 \n\nEpisode: 61\nTrack generation: 953..1197 -> 244-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0595 - mean_squared_error: 0.1400\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 85\nReplay buffer size: 4935\nTotal frame count: 4935\nEpsilon: 0.6770000000000016\nTotal reward for episode: 19.497942386831944\nRunning average rewards: 10.372403290460305 \n\nEpisode: 62\nTrack generation: 1167..1463 -> 296-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0949 - mean_squared_error: 0.3364\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 63\nReplay buffer size: 4998\nTotal frame count: 4998\nEpsilon: 0.6675000000000016\nTotal reward for episode: 15.477966101694534\nRunning average rewards: 10.453443970003706 \n\nEpisode: 63\nTrack generation: 1100..1380 -> 280-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0844 - mean_squared_error: 0.1917\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0504 - mean_squared_error: 0.1979\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 63\nReplay buffer size: 5061\nTotal frame count: 5061\nEpsilon: 0.6580000000000017\nTotal reward for episode: 24.979211469534384\nRunning average rewards: 10.680409087183875 \n\nEpisode: 64\nTrack generation: 1291..1618 -> 327-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.1308 - mean_squared_error: 0.6302\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 57\nReplay buffer size: 5118\nTotal frame count: 5118\nEpsilon: 0.6485000000000017\nTotal reward for episode: -7.462576687116863\nRunning average rewards: 10.40128622911771 \n\nEpisode: 65\nTrack generation: 1096..1380 -> 284-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0825 - mean_squared_error: 0.2285\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0448 - mean_squared_error: 0.1162\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 102\nReplay buffer size: 5220\nTotal frame count: 5220\nEpsilon: 0.6390000000000018\nTotal reward for episode: 47.539222614842686\nRunning average rewards: 10.963982234962028 \n\nEpisode: 66\nTrack generation: 1128..1414 -> 286-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0664 - mean_squared_error: 0.2068\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 56\nReplay buffer size: 5276\nTotal frame count: 5276\nEpsilon: 0.6295000000000018\nTotal reward for episode: -4.856140350877514\nRunning average rewards: 10.727861002337558 \n\nEpisode: 67\nTrack generation: 1415..1773 -> 358-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0730 - mean_squared_error: 0.1954\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 68\nReplay buffer size: 5344\nTotal frame count: 5344\nEpsilon: 0.6200000000000019\nTotal reward for episode: 14.816806722688668\nRunning average rewards: 10.787992557048604 \n\nEpisode: 68\nTrack generation: 1224..1534 -> 310-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0787 - mean_squared_error: 0.2288\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0354 - mean_squared_error: 0.0861\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0918 - mean_squared_error: 0.2639\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 116\nReplay buffer size: 5460\nTotal frame count: 5460\nEpsilon: 0.6105000000000019\nTotal reward for episode: 5.379935275080246\nRunning average rewards: 10.709614915280946 \n\nEpisode: 69\nTrack generation: 1196..1499 -> 303-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.1041 - mean_squared_error: 0.2756\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 55\nReplay buffer size: 5515\nTotal frame count: 5515\nEpsilon: 0.601000000000002\nTotal reward for episode: -8.754966887417538\nRunning average rewards: 10.431549460956681 \n\nEpisode: 70\nTrack generation: 1026..1289 -> 263-tiles track\nretry to generate track (normal if there are not manyinstances of this message)\nTrack generation: 980..1231 -> 251-tiles track\nretry to generate track (normal if there are not manyinstances of this message)\nTrack generation: 956..1199 -> 243-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0507 - mean_squared_error: 0.1535\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 72\nReplay buffer size: 5587\nTotal frame count: 5587\nEpsilon: 0.591500000000002\nTotal reward for episode: 20.78677685950465\nRunning average rewards: 10.577397734175667 \n\nEpisode: 71\nTrack generation: 1080..1363 -> 283-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0721 - mean_squared_error: 0.2671\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0435 - mean_squared_error: 0.0983\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 71\nReplay buffer size: 5658\nTotal frame count: 5658\nEpsilon: 0.5820000000000021\nTotal reward for episode: -0.031205673759274077\nRunning average rewards: 10.43005602017657 \n\nEpisode: 72\nTrack generation: 1238..1560 -> 322-tiles track\n1/1 [==============================] - 0s 9ms/step - loss: 0.1008 - mean_squared_error: 0.2579\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 82\nReplay buffer size: 5740\nTotal frame count: 5740\nEpsilon: 0.5725000000000021\nTotal reward for episode: 1.4679127725852226\nRunning average rewards: 10.307286934593126 \n\nEpisode: 73\nTrack generation: 1148..1439 -> 291-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0815 - mean_squared_error: 0.2452\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0679 - mean_squared_error: 0.2421\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 73\nReplay buffer size: 5813\nTotal frame count: 5813\nEpsilon: 0.5630000000000022\nTotal reward for episode: 8.731034482758226\nRunning average rewards: 10.285986225784546 \n\nEpisode: 74\nTrack generation: 1100..1379 -> 279-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0903 - mean_squared_error: 0.2544\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0800 - mean_squared_error: 0.2409\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 91\nReplay buffer size: 5904\nTotal frame count: 5904\nEpsilon: 0.5535000000000022\nTotal reward for episode: -0.4287769784177655\nRunning average rewards: 10.143122716395183 \n\nEpisode: 75\nTrack generation: 1244..1559 -> 315-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0348 - mean_squared_error: 0.0859\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 68\nReplay buffer size: 5972\nTotal frame count: 5972\nEpsilon: 0.5440000000000023\nTotal reward for episode: -4.907006369427137\nRunning average rewards: 9.945094702108047 \n\nEpisode: 76\nTrack generation: 1128..1414 -> 286-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0624 - mean_squared_error: 0.1951\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0629 - mean_squared_error: 0.1592\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 121\nReplay buffer size: 6093\nTotal frame count: 6093\nEpsilon: 0.5345000000000023\nTotal reward for episode: -2.78596491228139\nRunning average rewards: 9.779756265557534 \n\nEpisode: 77\nTrack generation: 1166..1461 -> 295-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0897 - mean_squared_error: 0.2173\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0459 - mean_squared_error: 0.1213\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 94\nReplay buffer size: 6187\nTotal frame count: 6187\nEpsilon: 0.5250000000000024\nTotal reward for episode: -0.18503401360596783\nRunning average rewards: 9.652002544029797 \n\nEpisode: 78\nTrack generation: 1068..1339 -> 271-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0333 - mean_squared_error: 0.0687\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0649 - mean_squared_error: 0.1408\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 82\nReplay buffer size: 6269\nTotal frame count: 6269\nEpsilon: 0.5155000000000024\nTotal reward for episode: -3.170370370370847\nRunning average rewards: 9.48969402612599 \n\nEpisode: 79\nTrack generation: 1183..1483 -> 300-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0380 - mean_squared_error: 0.0862\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0735 - mean_squared_error: 0.2782\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 99\nReplay buffer size: 6368\nTotal frame count: 6368\nEpsilon: 0.5060000000000024\nTotal reward for episode: -6.155183946488862\nRunning average rewards: 9.294133051468306 \n\nEpisode: 80\nTrack generation: 1188..1489 -> 301-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0839 - mean_squared_error: 0.2508\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0424 - mean_squared_error: 0.0992\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 88\nReplay buffer size: 6456\nTotal frame count: 6456\nEpsilon: 0.49650000000000244\nTotal reward for episode: 1.4666666666661818\nRunning average rewards: 9.197497664001613 \n\nEpisode: 81\nTrack generation: 1152..1448 -> 296-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0775 - mean_squared_error: 0.4135\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 78\nReplay buffer size: 6534\nTotal frame count: 6534\nEpsilon: 0.48700000000000243\nTotal reward for episode: 36.59661016949284\nRunning average rewards: 9.531633182361261 \n\nEpisode: 82\nTrack generation: 1174..1472 -> 298-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0735 - mean_squared_error: 0.1837\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0545 - mean_squared_error: 0.1646\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 80\nReplay buffer size: 6614\nTotal frame count: 6614\nEpsilon: 0.4775000000000024\nTotal reward for episode: 8.404040404039979\nRunning average rewards: 9.518047727200763 \n\nEpisode: 83\nTrack generation: 1088..1364 -> 276-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0268 - mean_squared_error: 0.0613\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 60\nReplay buffer size: 6674\nTotal frame count: 6674\nEpsilon: 0.4680000000000024\nTotal reward for episode: 8.727272727272364\nRunning average rewards: 9.508633739106378 \n\nEpisode: 84\nTrack generation: 1095..1380 -> 285-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0723 - mean_squared_error: 0.2162\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 9ms/step - loss: 0.0358 - mean_squared_error: 0.0844\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0886 - mean_squared_error: 0.2139\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 138\nReplay buffer size: 6812\nTotal frame count: 6812\nEpsilon: 0.4585000000000024\nTotal reward for episode: 36.34929577464926\nRunning average rewards: 9.824406233642177 \n\nEpisode: 85\nTrack generation: 1172..1469 -> 297-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0342 - mean_squared_error: 0.0892\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0482 - mean_squared_error: 0.1387\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 89\nReplay buffer size: 6901\nTotal frame count: 6901\nEpsilon: 0.4490000000000024\nTotal reward for episode: 1.562162162161659\nRunning average rewards: 9.728333628159845 \n\nEpisode: 86\nTrack generation: 1083..1358 -> 275-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0592 - mean_squared_error: 0.2072\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 70\nReplay buffer size: 6971\nTotal frame count: 6971\nEpsilon: 0.4395000000000024\nTotal reward for episode: -9.751824817518653\nRunning average rewards: 9.50442376096814 \n\nEpisode: 87\nTrack generation: 1135..1423 -> 288-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0360 - mean_squared_error: 0.0757\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0530 - mean_squared_error: 0.1459\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 92\nReplay buffer size: 7063\nTotal frame count: 7063\nEpsilon: 0.4300000000000024\nTotal reward for episode: 8.49616724738621\nRunning average rewards: 9.492966300586527 \n\nEpisode: 88\nTrack generation: 1145..1436 -> 291-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0249 - mean_squared_error: 0.0644\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0876 - mean_squared_error: 0.3953\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 94\nReplay buffer size: 7157\nTotal frame count: 7157\nEpsilon: 0.42050000000000237\nTotal reward for episode: 3.779310344827074\nRunning average rewards: 9.42876791906114 \n\nEpisode: 89\nTrack generation: 1064..1334 -> 270-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0442 - mean_squared_error: 0.1285\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0538 - mean_squared_error: 0.1642\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 94\nReplay buffer size: 7251\nTotal frame count: 7251\nEpsilon: 0.41100000000000236\nTotal reward for episode: -11.57769516728678\nRunning average rewards: 9.195362773657273 \n\nEpisode: 90\nTrack generation: 1182..1487 -> 305-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0745 - mean_squared_error: 0.2155\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 72\nReplay buffer size: 7323\nTotal frame count: 7323\nEpsilon: 0.40150000000000236\nTotal reward for episode: 20.542105263157637\nRunning average rewards: 9.32005225156387 \n\nEpisode: 91\nTrack generation: 1131..1418 -> 287-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0671 - mean_squared_error: 0.1551\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 69\nReplay buffer size: 7392\nTotal frame count: 7392\nEpsilon: 0.39200000000000235\nTotal reward for episode: 10.861538461538078\nRunning average rewards: 9.336807536454895 \n\nEpisode: 92\nTrack generation: 966..1212 -> 246-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0287 - mean_squared_error: 0.0692\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1124 - mean_squared_error: 0.3156\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 81\nReplay buffer size: 7473\nTotal frame count: 7473\nEpsilon: 0.38250000000000234\nTotal reward for episode: 20.661224489796247\nRunning average rewards: 9.458575460684372 \n\nEpisode: 93\nTrack generation: 1124..1409 -> 285-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0791 - mean_squared_error: 0.2307\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0244 - mean_squared_error: 0.0506\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0670 - mean_squared_error: 0.2515\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0380 - mean_squared_error: 0.1007\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 185\nReplay buffer size: 7658\nTotal frame count: 7658\nEpsilon: 0.37300000000000233\nTotal reward for episode: -0.05633802816999989\nRunning average rewards: 9.357352976760389 \n\nEpisode: 94\nTrack generation: 1243..1558 -> 315-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0949 - mean_squared_error: 0.2821\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0407 - mean_squared_error: 0.1115\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 139\nReplay buffer size: 7797\nTotal frame count: 7797\nEpsilon: 0.3635000000000023\nTotal reward for episode: -20.568152866242677\nRunning average rewards: 9.042347652097199 \n\nEpisode: 95\nTrack generation: 1087..1367 -> 280-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0782 - mean_squared_error: 0.1823\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0685 - mean_squared_error: 0.1960\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 57\nReplay buffer size: 7854\nTotal frame count: 7854\nEpsilon: 0.3540000000000023\nTotal reward for episode: -1.2946236559143038\nRunning average rewards: 8.934670867638745 \n\nEpisode: 96\nTrack generation: 1222..1532 -> 310-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0692 - mean_squared_error: 0.2975\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 60\nReplay buffer size: 7914\nTotal frame count: 7914\nEpsilon: 0.3445000000000023\nTotal reward for episode: 8.362459546925226\nRunning average rewards: 8.928771781858195 \n\nEpisode: 97\nTrack generation: 1054..1328 -> 274-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0424 - mean_squared_error: 0.0947\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1044 - mean_squared_error: 0.3466\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 127\nReplay buffer size: 8041\nTotal frame count: 8041\nEpsilon: 0.3350000000000023\nTotal reward for episode: -6.843956043956755\nRunning average rewards: 8.76782557955396 \n\nEpisode: 98\nTrack generation: 1104..1384 -> 280-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0489 - mean_squared_error: 0.1027\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0699 - mean_squared_error: 0.1965\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 92\nReplay buffer size: 8133\nTotal frame count: 8133\nEpsilon: 0.3255000000000023\nTotal reward for episode: -0.9577060931904917\nRunning average rewards: 8.669587885889875 \n\nEpisode: 99\nTrack generation: 1076..1349 -> 273-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0386 - mean_squared_error: 0.0861\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0546 - mean_squared_error: 0.1666\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0412 - mean_squared_error: 0.0931\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 129\nReplay buffer size: 8262\nTotal frame count: 8262\nEpsilon: 0.3160000000000023\nTotal reward for episode: 7.223529411764016\nRunning average rewards: 8.655127301148617 \n\nEpisode: 100\nTrack generation: 998..1252 -> 254-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0312 - mean_squared_error: 0.0708\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0288 - mean_squared_error: 0.0633\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 103\nReplay buffer size: 8365\nTotal frame count: 8365\nEpsilon: 0.30650000000000227\nTotal reward for episode: 14.135968379446176\nRunning average rewards: 8.826467182962883 \n\nEpisode: 101\nTrack generation: 1125..1417 -> 292-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.1155 - mean_squared_error: 0.3084\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 57\nReplay buffer size: 8422\nTotal frame count: 8422\nEpsilon: 0.29700000000000226\nTotal reward for episode: -2.1814432989693877\nRunning average rewards: 8.716783897514174 \n\nEpisode: 102\nTrack generation: 1188..1489 -> 301-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0517 - mean_squared_error: 0.1381\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 62\nReplay buffer size: 8484\nTotal frame count: 8484\nEpsilon: 0.28750000000000225\nTotal reward for episode: -1.4666666666670132\nRunning average rewards: 8.422147882188495 \n\nEpisode: 103\nTrack generation: 1055..1323 -> 268-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0886 - mean_squared_error: 0.2225\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0416 - mean_squared_error: 0.1075\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 68\nReplay buffer size: 8552\nTotal frame count: 8552\nEpsilon: 0.27800000000000225\nTotal reward for episode: -0.9827715355809126\nRunning average rewards: 8.342573687959451 \n\nEpisode: 104\nTrack generation: 1180..1479 -> 299-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0138 - mean_squared_error: 0.0284\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 61\nReplay buffer size: 8613\nTotal frame count: 8613\nEpsilon: 0.26850000000000224\nTotal reward for episode: -4.265771812080889\nRunning average rewards: 8.305378753010167 \n\nEpisode: 105\nTrack generation: 1152..1444 -> 292-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.1106 - mean_squared_error: 0.3016\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 70\nReplay buffer size: 8683\nTotal frame count: 8683\nEpsilon: 0.25900000000000223\nTotal reward for episode: 13.237113402061482\nRunning average rewards: 8.354424585825965 \n\nEpisode: 106\nTrack generation: 1431..1793 -> 362-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0264 - mean_squared_error: 0.0572\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0416 - mean_squared_error: 0.1503\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 71\nReplay buffer size: 8754\nTotal frame count: 8754\nEpsilon: 0.24950000000000222\nTotal reward for episode: 7.611080332409571\nRunning average rewards: 8.295986493251013 \n\nEpisode: 107\nTrack generation: 1122..1416 -> 294-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0438 - mean_squared_error: 0.1356\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 56\nReplay buffer size: 8810\nTotal frame count: 8810\nEpsilon: 0.2400000000000022\nTotal reward for episode: -1.9221843003416055\nRunning average rewards: 8.310650581806534 \n\nEpisode: 108\nTrack generation: 1163..1458 -> 295-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0372 - mean_squared_error: 0.0881\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0978 - mean_squared_error: 0.2521\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0841 - mean_squared_error: 0.2740\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0662 - mean_squared_error: 0.1922\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 4\nTotal frames in episode: 238\nReplay buffer size: 9048\nTotal frame count: 9048\nEpsilon: 0.2305000000000022\nTotal reward for episode: -20.17006802721204\nRunning average rewards: 7.989369481953999 \n\nEpisode: 109\nTrack generation: 1132..1419 -> 287-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0235 - mean_squared_error: 0.0598\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0285 - mean_squared_error: 0.0643\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0396 - mean_squared_error: 0.1011\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 102\nReplay buffer size: 9150\nTotal frame count: 9150\nEpsilon: 0.2210000000000022\nTotal reward for episode: 1.1580419580413839\nRunning average rewards: 7.940962846518235 \n\nEpisode: 110\nTrack generation: 1112..1397 -> 285-tiles track\nretry to generate track (normal if there are not manyinstances of this message)\nTrack generation: 1131..1418 -> 287-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0229 - mean_squared_error: 0.0499\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 78\nReplay buffer size: 9228\nTotal frame count: 9228\nEpsilon: 0.2115000000000022\nTotal reward for episode: -6.724475524475981\nRunning average rewards: 7.744161777280306 \n\nEpisode: 111\nTrack generation: 1065..1335 -> 270-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0394 - mean_squared_error: 0.1015\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 59\nReplay buffer size: 9287\nTotal frame count: 9287\nEpsilon: 0.20200000000000218\nTotal reward for episode: -1.2951672862456896\nRunning average rewards: 7.634509767717516 \n\nEpisode: 112\nTrack generation: 1211..1518 -> 307-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0449 - mean_squared_error: 0.1075\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0512 - mean_squared_error: 0.1248\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 83\nReplay buffer size: 9370\nTotal frame count: 9370\nEpsilon: 0.19250000000000217\nTotal reward for episode: -10.32418300653638\nRunning average rewards: 7.447526930457911 \n\nEpisode: 113\nTrack generation: 982..1235 -> 253-tiles track\nretry to generate track (normal if there are not manyinstances of this message)\nTrack generation: 1199..1503 -> 304-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0427 - mean_squared_error: 0.1073\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0671 - mean_squared_error: 0.1802\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 80\nReplay buffer size: 9450\nTotal frame count: 9450\nEpsilon: 0.18300000000000216\nTotal reward for episode: 17.504950495049023\nRunning average rewards: 7.390152192984154 \n\nEpisode: 114\nTrack generation: 1148..1441 -> 293-tiles track\nretry to generate track (normal if there are not manyinstances of this message)\nTrack generation: 1101..1380 -> 279-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0280 - mean_squared_error: 0.0685\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0459 - mean_squared_error: 0.1263\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 101\nReplay buffer size: 9551\nTotal frame count: 9551\nEpsilon: 0.17350000000000215\nTotal reward for episode: 2.7654676258987294\nRunning average rewards: 7.261806869243145 \n\nEpisode: 115\nTrack generation: 1208..1514 -> 306-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0450 - mean_squared_error: 0.1398\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 64\nReplay buffer size: 9615\nTotal frame count: 9615\nEpsilon: 0.16400000000000214\nTotal reward for episode: -2.649180327869203\nRunning average rewards: 7.146405318672038 \n\nEpisode: 116\nTrack generation: 1297..1635 -> 338-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0851 - mean_squared_error: 0.2423\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 60\nReplay buffer size: 9675\nTotal frame count: 9675\nEpsilon: 0.15450000000000214\nTotal reward for episode: 11.608308605340909\nRunning average rewards: 7.141435773146503 \n\nEpisode: 117\nTrack generation: 980..1234 -> 254-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0760 - mean_squared_error: 0.1947\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 9ms/step - loss: 0.0851 - mean_squared_error: 0.2839\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0793 - mean_squared_error: 0.2286\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0560 - mean_squared_error: 0.1464\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 183\nReplay buffer size: 9858\nTotal frame count: 9858\nEpsilon: 0.14500000000000213\nTotal reward for episode: 88.85533596838279\nRunning average rewards: 7.99343185728854 \n\nEpisode: 118\nTrack generation: 1047..1317 -> 270-tiles track\n1/1 [==============================] - 0s 9ms/step - loss: 0.0515 - mean_squared_error: 0.1540\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0596 - mean_squared_error: 0.1762\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 107\nReplay buffer size: 9965\nTotal frame count: 9965\nEpsilon: 0.13550000000000212\nTotal reward for episode: 42.70185873606086\nRunning average rewards: 8.325225531154343 \n\nEpisode: 119\nTrack generation: 1110..1391 -> 281-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0437 - mean_squared_error: 0.1055\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 55\nReplay buffer size: 10020\nTotal frame count: 10020\nEpsilon: 0.1260000000000021\nTotal reward for episode: -7.714285714286028\nRunning average rewards: 8.066903186832002 \n\nEpisode: 120\nTrack generation: 1172..1469 -> 297-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0632 - mean_squared_error: 0.1909\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0604 - mean_squared_error: 0.2020\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 117\nReplay buffer size: 10137\nTotal frame count: 10137\nEpsilon: 0.11650000000000212\nTotal reward for episode: 10.63243243243177\nRunning average rewards: 8.183529761960186 \n\nEpisode: 121\nTrack generation: 1047..1313 -> 266-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0965 - mean_squared_error: 0.3259\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0673 - mean_squared_error: 0.2163\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 66\nReplay buffer size: 10203\nTotal frame count: 10203\nEpsilon: 0.10700000000000212\nTotal reward for episode: 11.335849056603408\nRunning average rewards: 8.190796202317019 \n\nEpisode: 122\nTrack generation: 1075..1348 -> 273-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0625 - mean_squared_error: 0.1972\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 69\nReplay buffer size: 10272\nTotal frame count: 10272\nEpsilon: 0.09750000000000213\nTotal reward for episode: 1.8117647058819806\nRunning average rewards: 8.107580516042509 \n\nEpisode: 123\nTrack generation: 1224..1534 -> 310-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0381 - mean_squared_error: 0.0887\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0618 - mean_squared_error: 0.2253\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 83\nReplay buffer size: 10355\nTotal frame count: 10355\nEpsilon: 0.08800000000000213\nTotal reward for episode: 12.107443365695318\nRunning average rewards: 8.022339160225778 \n\nEpisode: 124\nTrack generation: 1167..1463 -> 296-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0487 - mean_squared_error: 0.1520\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0616 - mean_squared_error: 0.1465\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 109\nReplay buffer size: 10464\nTotal frame count: 10464\nEpsilon: 0.07850000000000214\nTotal reward for episode: -2.9220338983057275\nRunning average rewards: 7.946987159800717 \n\nEpisode: 125\nTrack generation: 1124..1409 -> 285-tiles track\n1/1 [==============================] - 0s 9ms/step - loss: 0.0770 - mean_squared_error: 0.2429\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0402 - mean_squared_error: 0.1057\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 117\nReplay buffer size: 10581\nTotal frame count: 10581\nEpsilon: 0.06900000000000214\nTotal reward for episode: 2.4957746478867016\nRunning average rewards: 7.721239023926639 \n\nEpisode: 126\nTrack generation: 1224..1534 -> 310-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0800 - mean_squared_error: 0.2169\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0794 - mean_squared_error: 0.2344\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0458 - mean_squared_error: 0.1267\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 124\nReplay buffer size: 10705\nTotal frame count: 10705\nEpsilon: 0.05950000000000214\nTotal reward for episode: 11.888673139158236\nRunning average rewards: 7.748256902859209 \n\nEpisode: 127\nTrack generation: 1113..1395 -> 282-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0640 - mean_squared_error: 0.2042\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 59\nReplay buffer size: 10764\nTotal frame count: 10764\nEpsilon: 0.05000000000000214\nTotal reward for episode: 11.987188612099295\nRunning average rewards: 7.656676734185681 \n\nEpisode: 128\nTrack generation: 1214..1521 -> 307-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0830 - mean_squared_error: 0.2899\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 61\nReplay buffer size: 10825\nTotal frame count: 10825\nEpsilon: 0.05\nTotal reward for episode: 14.815686274509481\nRunning average rewards: 7.570905310078182 \n\nEpisode: 129\nTrack generation: 1266..1585 -> 319-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0443 - mean_squared_error: 0.1000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 55\nReplay buffer size: 10880\nTotal frame count: 10880\nEpsilon: 0.05\nTotal reward for episode: -9.421383647799008\nRunning average rewards: 7.399248850649376 \n\nEpisode: 130\nTrack generation: 1147..1440 -> 293-tiles track\nretry to generate track (normal if there are not manyinstances of this message)\nTrack generation: 1119..1411 -> 292-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0976 - mean_squared_error: 0.3644\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0949 - mean_squared_error: 0.2914\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 78\nReplay buffer size: 10958\nTotal frame count: 10958\nEpsilon: 0.05\nTotal reward for episode: 27.21924398625474\nRunning average rewards: 7.321031651957693 \n\nEpisode: 131\nTrack generation: 1175..1473 -> 298-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0574 - mean_squared_error: 0.1634\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 64\nReplay buffer size: 11022\nTotal frame count: 11022\nEpsilon: 0.05\nTotal reward for episode: 14.804040404040073\nRunning average rewards: 7.394299049863129 \n\nEpisode: 132\nTrack generation: 1108..1389 -> 281-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0463 - mean_squared_error: 0.1275\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 60\nReplay buffer size: 11082\nTotal frame count: 11082\nEpsilon: 0.05\nTotal reward for episode: 11.71428571428536\nRunning average rewards: 7.556705064900725 \n\nEpisode: 133\nTrack generation: 1108..1389 -> 281-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0406 - mean_squared_error: 0.1022\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 60\nReplay buffer size: 11142\nTotal frame count: 11142\nEpsilon: 0.05\nTotal reward for episode: 18.857142857142676\nRunning average rewards: 7.674931665885948 \n\nEpisode: 134\nTrack generation: 1075..1353 -> 278-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0436 - mean_squared_error: 0.1220\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0302 - mean_squared_error: 0.0645\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 62\nReplay buffer size: 11204\nTotal frame count: 11204\nEpsilon: 0.05\nTotal reward for episode: 25.74151624548776\nRunning average rewards: 7.874402383896386 \n\nEpisode: 135\nTrack generation: 1322..1666 -> 344-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0928 - mean_squared_error: 0.2430\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 57\nReplay buffer size: 11261\nTotal frame count: 11261\nEpsilon: 0.05\nTotal reward for episode: -2.391836734694209\nRunning average rewards: 7.693964932579984 \n\nEpisode: 136\nTrack generation: 1184..1484 -> 300-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0649 - mean_squared_error: 0.2114\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 62\nReplay buffer size: 11323\nTotal frame count: 11323\nEpsilon: 0.05\nTotal reward for episode: 18.6782608695649\nRunning average rewards: 7.724802148784171 \n\nEpisode: 137\nTrack generation: 1028..1289 -> 261-tiles track\n1/1 [==============================] - 0s 13ms/step - loss: 0.1495 - mean_squared_error: 0.3875\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 60\nReplay buffer size: 11383\nTotal frame count: 11383\nEpsilon: 0.05\nTotal reward for episode: 18.307692307692314\nRunning average rewards: 7.865207975515585 \n\nEpisode: 138\nTrack generation: 922..1162 -> 240-tiles track\n1/1 [==============================] - 0s 10ms/step - loss: 0.0886 - mean_squared_error: 0.4222\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 57\nReplay buffer size: 11440\nTotal frame count: 11440\nEpsilon: 0.05\nTotal reward for episode: -1.8794979079501246\nRunning average rewards: 7.712802606825695 \n\nEpisode: 139\nTrack generation: 1136..1424 -> 288-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0794 - mean_squared_error: 0.2885\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 9ms/step - loss: 0.0473 - mean_squared_error: 0.1938\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 60\nReplay buffer size: 11500\nTotal frame count: 11500\nEpsilon: 0.05\nTotal reward for episode: 14.327526132403818\nRunning average rewards: 7.652136262310316 \n\nEpisode: 140\nTrack generation: 1127..1413 -> 286-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0693 - mean_squared_error: 0.2568\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 61\nReplay buffer size: 11561\nTotal frame count: 11561\nEpsilon: 0.05\nTotal reward for episode: 14.196491228069824\nRunning average rewards: 7.812101174591018 \n\nEpisode: 141\nTrack generation: 1039..1304 -> 265-tiles track\nretry to generate track (normal if there are not manyinstances of this message)\nTrack generation: 1239..1553 -> 314-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0879 - mean_squared_error: 0.3274\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 60\nReplay buffer size: 11621\nTotal frame count: 11621\nEpsilon: 0.05\nTotal reward for episode: 11.143769968050762\nRunning average rewards: 7.8292204029339505 \n\nEpisode: 142\nTrack generation: 1092..1374 -> 282-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0646 - mean_squared_error: 0.2217\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 57\nReplay buffer size: 11678\nTotal frame count: 11678\nEpsilon: 0.05\nTotal reward for episode: -5.006405693950494\nRunning average rewards: 7.790326157315207 \n\nEpisode: 143\nTrack generation: 1211..1518 -> 307-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0501 - mean_squared_error: 0.1454\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 9ms/step - loss: 0.0442 - mean_squared_error: 0.1375\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 120\nReplay buffer size: 11798\nTotal frame count: 11798\nEpsilon: 0.05\nTotal reward for episode: -5.516339869281701\nRunning average rewards: 7.78534457680421 \n\nEpisode: 144\nTrack generation: 1142..1431 -> 289-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0252 - mean_squared_error: 0.0560\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0256 - mean_squared_error: 0.0565\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 96\nReplay buffer size: 11894\nTotal frame count: 11894\nEpsilon: 0.05\nTotal reward for episode: -3.677777777778328\nRunning average rewards: 7.7312099085670685 \n\nEpisode: 145\nTrack generation: 1217..1527 -> 310-tiles track\nretry to generate track (normal if there are not manyinstances of this message)\nTrack generation: 1012..1269 -> 257-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0384 - mean_squared_error: 0.0928\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0602 - mean_squared_error: 0.1625\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 70\nReplay buffer size: 11964\nTotal frame count: 11964\nEpsilon: 0.05\nTotal reward for episode: 11.062499999999602\nRunning average rewards: 7.756124470856633 \n\nEpisode: 146\nTrack generation: 1076..1350 -> 274-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0491 - mean_squared_error: 0.1594\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 61\nReplay buffer size: 12025\nTotal frame count: 12025\nEpsilon: 0.05\nTotal reward for episode: 26.88205128205182\nRunning average rewards: 8.105084843817014 \n\nEpisode: 147\nTrack generation: 930..1171 -> 241-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0437 - mean_squared_error: 0.1020\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 56\nReplay buffer size: 12081\nTotal frame count: 12081\nEpsilon: 0.05\nTotal reward for episode: -1.5666666666669968\nRunning average rewards: 8.032163045185538 \n\nEpisode: 148\nTrack generation: 1023..1290 -> 267-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0371 - mean_squared_error: 0.0907\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0717 - mean_squared_error: 0.2123\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 73\nReplay buffer size: 12154\nTotal frame count: 12154\nEpsilon: 0.05\nTotal reward for episode: 53.5067669172947\nRunning average rewards: 7.885598315604547 \n\nEpisode: 149\nTrack generation: 1255..1573 -> 318-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0408 - mean_squared_error: 0.1000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 57\nReplay buffer size: 12211\nTotal frame count: 12211\nEpsilon: 0.05\nTotal reward for episode: -7.027129337539748\nRunning average rewards: 7.291327022229127 \n\nEpisode: 150\nTrack generation: 1032..1303 -> 271-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.1096 - mean_squared_error: 0.3909\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 84\nReplay buffer size: 12295\nTotal frame count: 12295\nEpsilon: 0.05\nTotal reward for episode: 33.066666666668134\nRunning average rewards: 7.556106896442978 \n\nEpisode: 151\nTrack generation: 1193..1491 -> 298-tiles track\nretry to generate track (normal if there are not manyinstances of this message)\nTrack generation: 1003..1266 -> 263-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0340 - mean_squared_error: 0.0758\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0284 - mean_squared_error: 0.0694\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 9ms/step - loss: 0.0413 - mean_squared_error: 0.1371\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 110\nReplay buffer size: 12405\nTotal frame count: 12405\nEpsilon: 0.05\nTotal reward for episode: 43.78625954198614\nRunning average rewards: 7.861088135930641 \n\nEpisode: 152\nTrack generation: 1186..1487 -> 301-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0348 - mean_squared_error: 0.1042\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 56\nReplay buffer size: 12461\nTotal frame count: 12461\nEpsilon: 0.05\nTotal reward for episode: -5.7333333333336505\nRunning average rewards: 7.885660165373337 \n\nEpisode: 153\nTrack generation: 1158..1452 -> 294-tiles track\n1/1 [==============================] - 0s 10ms/step - loss: 0.0609 - mean_squared_error: 0.1788\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0789 - mean_squared_error: 0.2530\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 91\nReplay buffer size: 12552\nTotal frame count: 12552\nEpsilon: 0.05\nTotal reward for episode: 42.09829351535965\nRunning average rewards: 8.072230402114227 \n\nEpisode: 154\nTrack generation: 1096..1374 -> 278-tiles track\nEnding episode: done True, consecutive negative rewards 31\nTotal frames in episode: 40\nReplay buffer size: 12592\nTotal frame count: 12592\nEpsilon: 0.05\nTotal reward for episode: -79.49891696750923\nRunning average rewards: 7.128436200992598 \n\nEpisode: 155\nTrack generation: 1234..1547 -> 313-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0594 - mean_squared_error: 0.1531\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0354 - mean_squared_error: 0.0794\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 62\nReplay buffer size: 12654\nTotal frame count: 12654\nEpsilon: 0.05\nTotal reward for episode: -8.774358974359313\nRunning average rewards: 7.1333040762171604 \n\nEpisode: 156\nTrack generation: 1138..1427 -> 289-tiles track\n1/1 [==============================] - 0s 9ms/step - loss: 0.0686 - mean_squared_error: 0.2197\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 79\nReplay buffer size: 12733\nTotal frame count: 12733\nEpsilon: 0.05\nTotal reward for episode: -14.238888888889267\nRunning average rewards: 7.033097005510091 \n\nEpisode: 157\nTrack generation: 1118..1402 -> 284-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0351 - mean_squared_error: 0.0862\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0371 - mean_squared_error: 0.0902\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 74\nReplay buffer size: 12807\nTotal frame count: 12807\nEpsilon: 0.05\nTotal reward for episode: 16.336395759716858\nRunning average rewards: 7.244280782927083 \n\nEpisode: 158\nTrack generation: 1271..1593 -> 322-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0731 - mean_squared_error: 0.2791\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 60\nReplay buffer size: 12867\nTotal frame count: 12867\nEpsilon: 0.05\nTotal reward for episode: 10.267912772585348\nRunning average rewards: 7.402209910652943 \n\nEpisode: 159\nTrack generation: 1096..1374 -> 278-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0737 - mean_squared_error: 0.2784\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 55\nReplay buffer size: 12922\nTotal frame count: 12922\nEpsilon: 0.05\nTotal reward for episode: -7.5595667870039165\nRunning average rewards: 7.183033823202488 \n\nEpisode: 160\nTrack generation: 1207..1513 -> 306-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0210 - mean_squared_error: 0.0464\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 61\nReplay buffer size: 12983\nTotal frame count: 12983\nEpsilon: 0.05\nTotal reward for episode: 14.944262295081643\nRunning average rewards: 7.30605350708521 \n\nEpisode: 161\nTrack generation: 1016..1274 -> 258-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.1042 - mean_squared_error: 0.3495\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 55\nReplay buffer size: 13038\nTotal frame count: 13038\nEpsilon: 0.05\nTotal reward for episode: -6.435797665369961\nRunning average rewards: 7.046716106563191 \n\nEpisode: 162\nTrack generation: 1284..1609 -> 325-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0370 - mean_squared_error: 0.1150\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 61\nReplay buffer size: 13099\nTotal frame count: 13099\nEpsilon: 0.05\nTotal reward for episode: 15.723456790123095\nRunning average rewards: 7.049171013447476 \n\nEpisode: 163\nTrack generation: 1243..1564 -> 321-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0333 - mean_squared_error: 0.0998\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0199 - mean_squared_error: 0.0425\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 60\nReplay buffer size: 13159\nTotal frame count: 13159\nEpsilon: 0.05\nTotal reward for episode: 0.9999999999996589\nRunning average rewards: 6.809378898752129 \n\nEpisode: 164\nTrack generation: 1122..1409 -> 287-tiles track\nretry to generate track (normal if there are not manyinstances of this message)\nTrack generation: 1187..1488 -> 301-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0684 - mean_squared_error: 0.2289\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0861 - mean_squared_error: 0.3096\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 123\nReplay buffer size: 13282\nTotal frame count: 13282\nEpsilon: 0.05\nTotal reward for episode: -9.200000000000697\nRunning average rewards: 6.79200466562329 \n\nEpisode: 165\nTrack generation: 1175..1473 -> 298-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0384 - mean_squared_error: 0.0950\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 55\nReplay buffer size: 13337\nTotal frame count: 13337\nEpsilon: 0.05\nTotal reward for episode: -8.531986531986842\nRunning average rewards: 6.231292574154995 \n\nEpisode: 166\nTrack generation: 1121..1410 -> 289-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0825 - mean_squared_error: 0.2480\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0712 - mean_squared_error: 0.2618\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0398 - mean_squared_error: 0.0887\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 143\nReplay buffer size: 13480\nTotal frame count: 13480\nEpsilon: 0.05\nTotal reward for episode: 99.05000000000321\nRunning average rewards: 7.270353977663802 \n\nEpisode: 167\nTrack generation: 1225..1535 -> 310-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0951 - mean_squared_error: 0.3502\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0332 - mean_squared_error: 0.0736\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 82\nReplay buffer size: 13562\nTotal frame count: 13562\nEpsilon: 0.05\nTotal reward for episode: 28.68867313915944\nRunning average rewards: 7.40907264182851 \n\nEpisode: 168\nTrack generation: 1277..1600 -> 323-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0467 - mean_squared_error: 0.1174\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 73\nReplay buffer size: 13635\nTotal frame count: 13635\nEpsilon: 0.05\nTotal reward for episode: 1.8559006211175983\nRunning average rewards: 7.373832295288883 \n\nEpisode: 169\nTrack generation: 1136..1432 -> 296-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0277 - mean_squared_error: 0.0728\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0623 - mean_squared_error: 0.2191\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 75\nReplay buffer size: 13710\nTotal frame count: 13710\nEpsilon: 0.05\nTotal reward for episode: 31.01694915254307\nRunning average rewards: 7.77155145568849 \n\nEpisode: 170\nTrack generation: 1096..1374 -> 278-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0586 - mean_squared_error: 0.1791\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 59\nReplay buffer size: 13769\nTotal frame count: 13769\nEpsilon: 0.05\nTotal reward for episode: 12.501083032490655\nRunning average rewards: 7.688694517418348 \n\nEpisode: 171\nTrack generation: 1188..1489 -> 301-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0398 - mean_squared_error: 0.0968\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 60\nReplay buffer size: 13829\nTotal frame count: 13829\nEpsilon: 0.05\nTotal reward for episode: 15.99999999999968\nRunning average rewards: 7.849006574155939 \n\nEpisode: 172\nTrack generation: 1022..1286 -> 264-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0340 - mean_squared_error: 0.0828\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0574 - mean_squared_error: 0.1480\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 99\nReplay buffer size: 13928\nTotal frame count: 13928\nEpsilon: 0.05\nTotal reward for episode: 2.2250950570336343\nRunning average rewards: 7.856578397000423 \n\nEpisode: 173\nTrack generation: 1224..1534 -> 310-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0431 - mean_squared_error: 0.1040\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 61\nReplay buffer size: 13989\nTotal frame count: 13989\nEpsilon: 0.05\nTotal reward for episode: 11.198705501617777\nRunning average rewards: 7.881255107189017 \n\nEpisode: 174\nTrack generation: 1247..1563 -> 316-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0479 - mean_squared_error: 0.1532\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0582 - mean_squared_error: 0.1694\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 75\nReplay buffer size: 14064\nTotal frame count: 14064\nEpsilon: 0.05\nTotal reward for episode: -1.4285714285718427\nRunning average rewards: 7.871257162687478 \n\nEpisode: 175\nTrack generation: 1157..1450 -> 293-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0237 - mean_squared_error: 0.0573\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 76\nReplay buffer size: 14140\nTotal frame count: 14140\nEpsilon: 0.05\nTotal reward for episode: 3.8465753424653393\nRunning average rewards: 7.958792979806402 \n\nEpisode: 176\nTrack generation: 1135..1423 -> 288-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0231 - mean_squared_error: 0.0502\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0386 - mean_squared_error: 0.1156\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 61\nReplay buffer size: 14201\nTotal frame count: 14201\nEpsilon: 0.05\nTotal reward for episode: 10.443205574912525\nRunning average rewards: 8.091084684678343 \n\nEpisode: 177\nTrack generation: 1135..1423 -> 288-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0509 - mean_squared_error: 0.1368\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 98\nReplay buffer size: 14299\nTotal frame count: 14299\nEpsilon: 0.05\nTotal reward for episode: 9.5804878048775\nRunning average rewards: 8.188739902863178 \n\nEpisode: 178\nTrack generation: 1196..1499 -> 303-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.1045 - mean_squared_error: 0.5422\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0768 - mean_squared_error: 0.2260\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 73\nReplay buffer size: 14372\nTotal frame count: 14372\nEpsilon: 0.05\nTotal reward for episode: 7.223841059602215\nRunning average rewards: 8.292682017162909 \n\nEpisode: 179\nTrack generation: 1120..1404 -> 284-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0684 - mean_squared_error: 0.1989\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 61\nReplay buffer size: 14433\nTotal frame count: 14433\nEpsilon: 0.05\nTotal reward for episode: 18.002826855123395\nRunning average rewards: 8.534262125179032 \n\nEpisode: 180\nTrack generation: 1079..1358 -> 279-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0287 - mean_squared_error: 0.0683\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0515 - mean_squared_error: 0.1749\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 70\nReplay buffer size: 14503\nTotal frame count: 14503\nEpsilon: 0.05\nTotal reward for episode: 40.34532374100853\nRunning average rewards: 8.923048695922454 \n\nEpisode: 181\nTrack generation: 1108..1389 -> 281-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0388 - mean_squared_error: 0.0923\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 62\nReplay buffer size: 14565\nTotal frame count: 14565\nEpsilon: 0.05\nTotal reward for episode: 18.057142857142637\nRunning average rewards: 8.737654022798951 \n\nEpisode: 182\nTrack generation: 984..1234 -> 250-tiles track\n1/1 [==============================] - 0s 9ms/step - loss: 0.0378 - mean_squared_error: 0.0960\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 44\nTotal frames in episode: 50\nReplay buffer size: 14615\nTotal frame count: 14615\nEpsilon: 0.05\nTotal reward for episode: -95.8036144578316\nRunning average rewards: 7.6955774741802365 \n\nEpisode: 183\nTrack generation: 1198..1508 -> 310-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0435 - mean_squared_error: 0.0963\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0755 - mean_squared_error: 0.2115\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 117\nReplay buffer size: 14732\nTotal frame count: 14732\nEpsilon: 0.05\nTotal reward for episode: -4.728802588997429\nRunning average rewards: 7.5610167210175385 \n\nEpisode: 184\nTrack generation: 1237..1551 -> 314-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0427 - mean_squared_error: 0.1187\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0374 - mean_squared_error: 0.0955\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0363 - mean_squared_error: 0.0951\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 125\nReplay buffer size: 14857\nTotal frame count: 14857\nEpsilon: 0.05\nTotal reward for episode: -11.661341853035786\nRunning average rewards: 7.080910344740687 \n\nEpisode: 185\nTrack generation: 1203..1508 -> 305-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0600 - mean_squared_error: 0.1425\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 87\nReplay buffer size: 14944\nTotal frame count: 14944\nEpsilon: 0.05\nTotal reward for episode: 4.673684210525835\nRunning average rewards: 7.11202556522433 \n\nEpisode: 186\nTrack generation: 1128..1422 -> 294-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0783 - mean_squared_error: 0.2403\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0405 - mean_squared_error: 0.1068\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 73\nReplay buffer size: 15017\nTotal frame count: 15017\nEpsilon: 0.05\nTotal reward for episode: 28.820477815700343\nRunning average rewards: 7.497748591556519 \n\nEpisode: 187\nTrack generation: 1030..1297 -> 267-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.1072 - mean_squared_error: 0.3299\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 56\nReplay buffer size: 15073\nTotal frame count: 15073\nEpsilon: 0.05\nTotal reward for episode: -3.6030075187973196\nRunning average rewards: 7.376756843894683 \n\nEpisode: 188\nTrack generation: 1241..1555 -> 314-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0964 - mean_squared_error: 0.3760\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 59\nReplay buffer size: 15132\nTotal frame count: 15132\nEpsilon: 0.05\nTotal reward for episode: 8.348881789137032\nRunning average rewards: 7.422452558337783 \n\nEpisode: 189\nTrack generation: 1176..1479 -> 303-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.1241 - mean_squared_error: 0.4047\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 60\nReplay buffer size: 15192\nTotal frame count: 15192\nEpsilon: 0.05\nTotal reward for episode: 12.423841059602289\nRunning average rewards: 7.662467920606674 \n\nEpisode: 190\nTrack generation: 1259..1578 -> 319-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0896 - mean_squared_error: 0.3132\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 55\nReplay buffer size: 15247\nTotal frame count: 15247\nEpsilon: 0.05\nTotal reward for episode: -9.421383647799008\nRunning average rewards: 7.362833031497108 \n\nEpisode: 191\nTrack generation: 1231..1543 -> 312-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0755 - mean_squared_error: 0.4243\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0442 - mean_squared_error: 0.1101\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 55\nReplay buffer size: 15302\nTotal frame count: 15302\nEpsilon: 0.05\nTotal reward for episode: -9.13826366559514\nRunning average rewards: 7.162835010225776 \n\nEpisode: 192\nTrack generation: 1194..1496 -> 302-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0528 - mean_squared_error: 0.1780\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 55\nReplay buffer size: 15357\nTotal frame count: 15357\nEpsilon: 0.05\nTotal reward for episode: -8.710963455149816\nRunning average rewards: 6.869113130776315 \n\nEpisode: 193\nTrack generation: 904..1139 -> 235-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0776 - mean_squared_error: 0.2833\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 58\nReplay buffer size: 15415\nTotal frame count: 15415\nEpsilon: 0.05\nTotal reward for episode: 2.4410256410253055\nRunning average rewards: 6.894086767468268 \n\nEpisode: 194\nTrack generation: 1378..1726 -> 348-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0800 - mean_squared_error: 0.2487\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 63\nReplay buffer size: 15478\nTotal frame count: 15478\nEpsilon: 0.05\nTotal reward for episode: 0.7365994236307571\nRunning average rewards: 7.107134290367002 \n\nEpisode: 195\nTrack generation: 1139..1428 -> 289-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0523 - mean_squared_error: 0.1299\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 58\nReplay buffer size: 15536\nTotal frame count: 15536\nEpsilon: 0.05\nTotal reward for episode: -5.838888888889219\nRunning average rewards: 7.061691638037254 \n\nEpisode: 196\nTrack generation: 904..1137 -> 233-tiles track\nretry to generate track (normal if there are not manyinstances of this message)\nTrack generation: 1255..1572 -> 317-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0607 - mean_squared_error: 0.1908\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0831 - mean_squared_error: 0.3218\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 73\nReplay buffer size: 15609\nTotal frame count: 15609\nEpsilon: 0.05\nTotal reward for episode: -0.718987341772575\nRunning average rewards: 6.970877169150275 \n\nEpisode: 197\nTrack generation: 1176..1474 -> 298-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0357 - mean_squared_error: 0.1118\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 74\nReplay buffer size: 15683\nTotal frame count: 15683\nEpsilon: 0.05\nTotal reward for episode: 44.474074074075475\nRunning average rewards: 7.484057470330597 \n\nEpisode: 198\nTrack generation: 1059..1328 -> 269-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0591 - mean_squared_error: 0.1745\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0566 - mean_squared_error: 0.1725\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 75\nReplay buffer size: 15758\nTotal frame count: 15758\nEpsilon: 0.05\nTotal reward for episode: 3.582089552238397\nRunning average rewards: 7.529455426784885 \n\nEpisode: 199\nTrack generation: 1179..1478 -> 299-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0490 - mean_squared_error: 0.1395\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 59\nReplay buffer size: 15817\nTotal frame count: 15817\nEpsilon: 0.05\nTotal reward for episode: -6.821476510067452\nRunning average rewards: 7.389005367566571 \n\nEpisode: 200\nTrack generation: 1224..1541 -> 317-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0633 - mean_squared_error: 0.2049\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 56\nReplay buffer size: 15873\nTotal frame count: 15873\nEpsilon: 0.05\nTotal reward for episode: -6.5772151898737405\nRunning average rewards: 7.181873531873371 \n\nEpisode: 201\nTrack generation: 1183..1482 -> 299-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0997 - mean_squared_error: 0.2868\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 59\nReplay buffer size: 15932\nTotal frame count: 15932\nEpsilon: 0.05\nTotal reward for episode: -6.821476510067452\nRunning average rewards: 7.13547319976239 \n\nEpisode: 202\nTrack generation: 1037..1302 -> 265-tiles track\nretry to generate track (normal if there are not manyinstances of this message)\nTrack generation: 1111..1401 -> 290-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0511 - mean_squared_error: 0.1336\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 56\nReplay buffer size: 15988\nTotal frame count: 15988\nEpsilon: 0.05\nTotal reward for episode: -5.098961937716577\nRunning average rewards: 7.099150247051896 \n\nEpisode: 203\nTrack generation: 1199..1503 -> 304-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0324 - mean_squared_error: 0.0852\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 55\nReplay buffer size: 16043\nTotal frame count: 16043\nEpsilon: 0.05\nTotal reward for episode: -8.798679867987117\nRunning average rewards: 7.0209911637278335 \n\nEpisode: 204\nTrack generation: 1160..1454 -> 294-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0887 - mean_squared_error: 0.3239\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0295 - mean_squared_error: 0.0667\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 57\nReplay buffer size: 16100\nTotal frame count: 16100\nEpsilon: 0.05\nTotal reward for episode: -2.322184300341611\nRunning average rewards: 7.040427038845227 \n\nEpisode: 205\nTrack generation: 1126..1420 -> 294-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0483 - mean_squared_error: 0.1758\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 56\nReplay buffer size: 16156\nTotal frame count: 16156\nEpsilon: 0.05\nTotal reward for episode: -5.335153583618059\nRunning average rewards: 6.854704368988431 \n\nEpisode: 206\nTrack generation: 965..1218 -> 253-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0884 - mean_squared_error: 0.6611\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 56\nReplay buffer size: 16212\nTotal frame count: 16212\nEpsilon: 0.05\nTotal reward for episode: -2.5587301587304765\nRunning average rewards: 6.7530062640770305 \n\nEpisode: 207\nTrack generation: 1103..1383 -> 280-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0128 - mean_squared_error: 0.0256\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 55\nReplay buffer size: 16267\nTotal frame count: 16267\nEpsilon: 0.05\nTotal reward for episode: -7.663082437276298\nRunning average rewards: 6.695597282707683 \n\nEpisode: 208\nTrack generation: 1037..1300 -> 263-tiles track\n1/1 [==============================] - 0s 9ms/step - loss: 0.0489 - mean_squared_error: 0.1331\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 55\nReplay buffer size: 16322\nTotal frame count: 16322\nEpsilon: 0.05\nTotal reward for episode: -6.73282442748123\nRunning average rewards: 6.829969718704991 \n\nEpisode: 209\nTrack generation: 1042..1314 -> 272-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0398 - mean_squared_error: 0.0806\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0535 - mean_squared_error: 0.2172\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 96\nReplay buffer size: 16418\nTotal frame count: 16418\nEpsilon: 0.05\nTotal reward for episode: 39.09077490775082\nRunning average rewards: 7.209297048202086 \n\nEpisode: 210\nTrack generation: 1156..1459 -> 303-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0842 - mean_squared_error: 0.3370\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0867 - mean_squared_error: 0.2674\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 87\nReplay buffer size: 16505\nTotal frame count: 16505\nEpsilon: 0.05\nTotal reward for episode: 11.557615894039216\nRunning average rewards: 7.392117962387239 \n\nEpisode: 211\nTrack generation: 1335..1673 -> 338-tiles track\n1/1 [==============================] - 0s 10ms/step - loss: 0.1170 - mean_squared_error: 0.5413\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 93\nReplay buffer size: 16598\nTotal frame count: 16598\nEpsilon: 0.05\nTotal reward for episode: 10.277744807121135\nRunning average rewards: 7.5078470833209074 \n\nEpisode: 212\nTrack generation: 1246..1562 -> 316-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0803 - mean_squared_error: 0.4141\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0368 - mean_squared_error: 0.1045\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 55\nReplay buffer size: 16653\nTotal frame count: 16653\nEpsilon: 0.05\nTotal reward for episode: -9.301587301587578\nRunning average rewards: 7.518073040370395 \n\nEpisode: 213\nTrack generation: 966..1216 -> 250-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0420 - mean_squared_error: 0.1479\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 56\nReplay buffer size: 16709\nTotal frame count: 16709\nEpsilon: 0.05\nTotal reward for episode: -2.319678714859755\nRunning average rewards: 7.319826748271307 \n\nEpisode: 214\nTrack generation: 1011..1271 -> 260-tiles track\nretry to generate track (normal if there are not manyinstances of this message)\nTrack generation: 1268..1589 -> 321-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0298 - mean_squared_error: 0.0904\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 55\nReplay buffer size: 16764\nTotal frame count: 16764\nEpsilon: 0.05\nTotal reward for episode: -9.50000000000027\nRunning average rewards: 7.197172072012318 \n\nEpisode: 215\nTrack generation: 1071..1343 -> 272-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0688 - mean_squared_error: 0.2315\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 80\nReplay buffer size: 16844\nTotal frame count: 16844\nEpsilon: 0.05\nTotal reward for episode: 12.280442804427572\nRunning average rewards: 7.3464683033352856 \n\nEpisode: 216\nTrack generation: 1077..1351 -> 274-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0534 - mean_squared_error: 0.1220\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0495 - mean_squared_error: 0.1508\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 59\nReplay buffer size: 16903\nTotal frame count: 16903\nEpsilon: 0.05\nTotal reward for episode: -5.284981684982018\nRunning average rewards: 7.177535400432056 \n\nEpisode: 217\nTrack generation: 1178..1477 -> 299-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0460 - mean_squared_error: 0.1366\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 60\nReplay buffer size: 16963\nTotal frame count: 16963\nEpsilon: 0.05\nTotal reward for episode: -7.221476510067458\nRunning average rewards: 6.2167672756475545 \n\nEpisode: 218\nTrack generation: 1016..1273 -> 257-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0266 - mean_squared_error: 0.0640\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 58\nReplay buffer size: 17021\nTotal frame count: 17021\nEpsilon: 0.05\nTotal reward for episode: -3.6687500000003297\nRunning average rewards: 5.753061188286942 \n\nEpisode: 219\nTrack generation: 1096..1374 -> 278-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0696 - mean_squared_error: 0.2779\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 29\nTotal frames in episode: 38\nReplay buffer size: 17059\nTotal frame count: 17059\nEpsilon: 0.05\nTotal reward for episode: -82.60902527075832\nRunning average rewards: 5.00411379272222 \n\nEpisode: 220\nTrack generation: 1049..1315 -> 266-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.1084 - mean_squared_error: 0.5731\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0506 - mean_squared_error: 0.1188\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 103\nReplay buffer size: 17162\nTotal frame count: 17162\nEpsilon: 0.05\nTotal reward for episode: -14.784905660377904\nRunning average rewards: 4.749940411794122 \n\nEpisode: 221\nTrack generation: 1269..1593 -> 324-tiles track\nretry to generate track (normal if there are not manyinstances of this message)\nTrack generation: 1062..1338 -> 276-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0632 - mean_squared_error: 0.1972\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 69\nReplay buffer size: 17231\nTotal frame count: 17231\nEpsilon: 0.05\nTotal reward for episode: 12.39999999999958\nRunning average rewards: 4.760581921228084 \n\nEpisode: 222\nTrack generation: 1070..1342 -> 272-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0468 - mean_squared_error: 0.1648\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 57\nReplay buffer size: 17288\nTotal frame count: 17288\nEpsilon: 0.05\nTotal reward for episode: -4.3498154981553085\nRunning average rewards: 4.698966119187711 \n\nEpisode: 223\nTrack generation: 1087..1363 -> 276-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0288 - mean_squared_error: 0.0796\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0785 - mean_squared_error: 0.2358\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0253 - mean_squared_error: 0.0601\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 138\nReplay buffer size: 17426\nTotal frame count: 17426\nEpsilon: 0.05\nTotal reward for episode: 46.61818181818312\nRunning average rewards: 5.044073503712589 \n\nEpisode: 224\nTrack generation: 1191..1493 -> 302-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0635 - mean_squared_error: 0.2636\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 10ms/step - loss: 0.0921 - mean_squared_error: 0.3284\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 106\nReplay buffer size: 17532\nTotal frame count: 17532\nEpsilon: 0.05\nTotal reward for episode: 43.97873754152974\nRunning average rewards: 5.513081218110943 \n\nEpisode: 225\nTrack generation: 1179..1478 -> 299-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.1031 - mean_squared_error: 0.4172\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 58\nReplay buffer size: 17590\nTotal frame count: 17590\nEpsilon: 0.05\nTotal reward for episode: -6.421476510067446\nRunning average rewards: 5.423908706531401 \n\nEpisode: 226\nTrack generation: 1231..1543 -> 312-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0319 - mean_squared_error: 0.0801\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0395 - mean_squared_error: 0.1058\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 9ms/step - loss: 0.0311 - mean_squared_error: 0.0740\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 112\nReplay buffer size: 17702\nTotal frame count: 17702\nEpsilon: 0.05\nTotal reward for episode: -9.430225080386444\nRunning average rewards: 5.210719724335956 \n\nEpisode: 227\nTrack generation: 1053..1325 -> 272-tiles track\n1/1 [==============================] - 0s 9ms/step - loss: 0.0165 - mean_squared_error: 0.0347\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0252 - mean_squared_error: 0.0653\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 123\nReplay buffer size: 17825\nTotal frame count: 17825\nEpsilon: 0.05\nTotal reward for episode: 28.29077490775088\nRunning average rewards: 5.373755587292472 \n\nEpisode: 228\nTrack generation: 1223..1533 -> 310-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0309 - mean_squared_error: 0.0829\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0794 - mean_squared_error: 0.3536\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0362 - mean_squared_error: 0.1268\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 151\nReplay buffer size: 17976\nTotal frame count: 17976\nEpsilon: 0.05\nTotal reward for episode: 17.269902912620502\nRunning average rewards: 5.398297753673582 \n\nEpisode: 229\nTrack generation: 1199..1503 -> 304-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0559 - mean_squared_error: 0.1611\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 62\nReplay buffer size: 18038\nTotal frame count: 18038\nEpsilon: 0.05\nTotal reward for episode: -8.29834983498386\nRunning average rewards: 5.409528091801734 \n\nEpisode: 230\nTrack generation: 1017..1282 -> 265-tiles track\n1/1 [==============================] - 0s 9ms/step - loss: 0.0326 - mean_squared_error: 0.0745\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 56\nReplay buffer size: 18094\nTotal frame count: 18094\nEpsilon: 0.05\nTotal reward for episode: -3.4606060606063735\nRunning average rewards: 5.102729591333121 \n\nEpisode: 231\nTrack generation: 1210..1516 -> 306-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0426 - mean_squared_error: 0.1320\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0399 - mean_squared_error: 0.1229\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 57\nReplay buffer size: 18151\nTotal frame count: 18151\nEpsilon: 0.05\nTotal reward for episode: -6.406557377049495\nRunning average rewards: 4.8906236135222265 \n\nEpisode: 232\nTrack generation: 1187..1488 -> 301-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0454 - mean_squared_error: 0.1331\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 55\nReplay buffer size: 18206\nTotal frame count: 18206\nEpsilon: 0.05\nTotal reward for episode: -8.66666666666698\nRunning average rewards: 4.686814089712702 \n\nEpisode: 233\nTrack generation: 1148..1439 -> 291-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0463 - mean_squared_error: 0.1789\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 57\nReplay buffer size: 18263\nTotal frame count: 18263\nEpsilon: 0.05\nTotal reward for episode: -2.1103448275865233\nRunning average rewards: 4.477139212865411 \n\nEpisode: 234\nTrack generation: 1247..1563 -> 316-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0530 - mean_squared_error: 0.1425\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 58\nReplay buffer size: 18321\nTotal frame count: 18321\nEpsilon: 0.05\nTotal reward for episode: -7.326984126984449\nRunning average rewards: 4.146454209140688 \n\nEpisode: 235\nTrack generation: 1187..1488 -> 301-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0667 - mean_squared_error: 0.2046\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 60\nReplay buffer size: 18381\nTotal frame count: 18381\nEpsilon: 0.05\nTotal reward for episode: 9.333333333333005\nRunning average rewards: 4.26370590982096 \n\nEpisode: 236\nTrack generation: 1110..1400 -> 290-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0573 - mean_squared_error: 0.1448\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 60\nReplay buffer size: 18441\nTotal frame count: 18441\nEpsilon: 0.05\nTotal reward for episode: 14.06228373702389\nRunning average rewards: 4.21754613849555 \n\nEpisode: 237\nTrack generation: 1274..1597 -> 323-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0164 - mean_squared_error: 0.0348\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 55\nReplay buffer size: 18496\nTotal frame count: 18496\nEpsilon: 0.05\nTotal reward for episode: -9.57763975155306\nRunning average rewards: 3.9386928179030956 \n\nEpisode: 238\nTrack generation: 1128..1414 -> 286-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0411 - mean_squared_error: 0.1202\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0191 - mean_squared_error: 0.0409\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 67\nReplay buffer size: 18563\nTotal frame count: 18563\nEpsilon: 0.05\nTotal reward for episode: 15.305263157894359\nRunning average rewards: 4.11054042856154 \n\nEpisode: 239\nTrack generation: 1260..1579 -> 319-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0787 - mean_squared_error: 0.2328\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 64\nReplay buffer size: 18627\nTotal frame count: 18627\nEpsilon: 0.05\nTotal reward for episode: 15.28050314465375\nRunning average rewards: 4.120070198684038 \n\nEpisode: 240\nTrack generation: 1247..1563 -> 316-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0233 - mean_squared_error: 0.0569\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 55\nReplay buffer size: 18682\nTotal frame count: 18682\nEpsilon: 0.05\nTotal reward for episode: -9.301587301587578\nRunning average rewards: 3.885089413387466 \n\nEpisode: 241\nTrack generation: 1219..1528 -> 309-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0614 - mean_squared_error: 0.2081\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 57\nReplay buffer size: 18739\nTotal frame count: 18739\nEpsilon: 0.05\nTotal reward for episode: -6.566233766234099\nRunning average rewards: 3.7079893760446163 \n\nEpisode: 242\nTrack generation: 1088..1364 -> 276-tiles track\n1/1 [==============================] - 0s 9ms/step - loss: 0.0651 - mean_squared_error: 0.2686\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0575 - mean_squared_error: 0.2020\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 88\nReplay buffer size: 18827\nTotal frame count: 18827\nEpsilon: 0.05\nTotal reward for episode: 15.709090909090378\nRunning average rewards: 3.915144342075026 \n\nEpisode: 243\nTrack generation: 1179..1478 -> 299-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0159 - mean_squared_error: 0.0324\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0429 - mean_squared_error: 0.1027\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0503 - mean_squared_error: 0.1479\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 158\nReplay buffer size: 18985\nTotal frame count: 18985\nEpsilon: 0.05\nTotal reward for episode: 81.09530201342507\nRunning average rewards: 4.781260760902093 \n\nEpisode: 244\nTrack generation: 1219..1528 -> 309-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0544 - mean_squared_error: 0.1867\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0412 - mean_squared_error: 0.1120\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0307 - mean_squared_error: 0.0759\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 132\nReplay buffer size: 19117\nTotal frame count: 19117\nEpsilon: 0.05\nTotal reward for episode: 5.641558441557642\nRunning average rewards: 4.874454123095454 \n\nEpisode: 245\nTrack generation: 1140..1429 -> 289-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0651 - mean_squared_error: 0.1935\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 55\nReplay buffer size: 19172\nTotal frame count: 19172\nEpsilon: 0.05\nTotal reward for episode: -8.111111111111423\nRunning average rewards: 4.682718011984344 \n\nEpisode: 246\nTrack generation: 1167..1468 -> 301-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0768 - mean_squared_error: 0.3948\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0479 - mean_squared_error: 0.1194\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 108\nReplay buffer size: 19280\nTotal frame count: 19280\nEpsilon: 0.05\nTotal reward for episode: 16.79999999999942\nRunning average rewards: 4.581897499163819 \n\nEpisode: 247\nTrack generation: 1155..1448 -> 293-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0391 - mean_squared_error: 0.0859\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 61\nReplay buffer size: 19341\nTotal frame count: 19341\nEpsilon: 0.05\nTotal reward for episode: 20.12054794520533\nRunning average rewards: 4.798769645282543 \n\nEpisode: 248\nTrack generation: 1093..1376 -> 283-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0646 - mean_squared_error: 0.2167\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 56\nReplay buffer size: 19397\nTotal frame count: 19397\nEpsilon: 0.05\nTotal reward for episode: -4.669503546099612\nRunning average rewards: 4.2170069406485995 \n\nEpisode: 249\nTrack generation: 1227..1538 -> 311-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0350 - mean_squared_error: 0.0888\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0669 - mean_squared_error: 0.2234\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 85\nReplay buffer size: 19482\nTotal frame count: 19482\nEpsilon: 0.05\nTotal reward for episode: 14.387096774193076\nRunning average rewards: 4.431149201765928 \n\nEpisode: 250\nTrack generation: 1125..1418 -> 293-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.1174 - mean_squared_error: 0.3077\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 60\nReplay buffer size: 19542\nTotal frame count: 19542\nEpsilon: 0.05\nTotal reward for episode: 13.671232876712004\nRunning average rewards: 4.237194863866367 \n\nEpisode: 251\nTrack generation: 1182..1482 -> 300-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0684 - mean_squared_error: 0.2799\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 9ms/step - loss: 0.0533 - mean_squared_error: 0.2230\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0686 - mean_squared_error: 0.3392\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0302 - mean_squared_error: 0.0805\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 10ms/step - loss: 0.0768 - mean_squared_error: 0.3129\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 215\nReplay buffer size: 19757\nTotal frame count: 19757\nEpsilon: 0.05\nTotal reward for episode: 71.19063545150932\nRunning average rewards: 4.511238622961597 \n\nEpisode: 252\nTrack generation: 1091..1376 -> 285-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0359 - mean_squared_error: 0.0894\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 80\nReplay buffer size: 19837\nTotal frame count: 19837\nEpsilon: 0.05\nTotal reward for episode: 17.29577464788725\nRunning average rewards: 4.741529702773806 \n\nEpisode: 253\nTrack generation: 1102..1385 -> 283-tiles track\nretry to generate track (normal if there are not manyinstances of this message)\nTrack generation: 1035..1302 -> 267-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0594 - mean_squared_error: 0.1998\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 56\nReplay buffer size: 19893\nTotal frame count: 19893\nEpsilon: 0.05\nTotal reward for episode: -3.6030075187973196\nRunning average rewards: 4.284516692432237 \n\nEpisode: 254\nTrack generation: 1088..1371 -> 283-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0507 - mean_squared_error: 0.3187\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0530 - mean_squared_error: 0.1446\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0566 - mean_squared_error: 0.2197\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 130\nReplay buffer size: 20023\nTotal frame count: 20023\nEpsilon: 0.05\nTotal reward for episode: 50.836879432626375\nRunning average rewards: 5.587874656433593 \n\nEpisode: 255\nTrack generation: 1083..1358 -> 275-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0596 - mean_squared_error: 0.1492\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0382 - mean_squared_error: 0.1352\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0503 - mean_squared_error: 0.1701\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 143\nReplay buffer size: 20166\nTotal frame count: 20166\nEpsilon: 0.05\nTotal reward for episode: 74.1868613138714\nRunning average rewards: 6.417486859315901 \n\nEpisode: 256\nTrack generation: 1192..1503 -> 311-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0695 - mean_squared_error: 0.3161\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 60\nReplay buffer size: 20226\nTotal frame count: 20226\nEpsilon: 0.05\nTotal reward for episode: 8.258064516128698\nRunning average rewards: 6.642456393366079 \n\nEpisode: 257\nTrack generation: 1245..1560 -> 315-tiles track\n1/1 [==============================] - 0s 9ms/step - loss: 0.0389 - mean_squared_error: 0.0934\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1169 - mean_squared_error: 0.3742\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0539 - mean_squared_error: 0.1650\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 129\nReplay buffer size: 20355\nTotal frame count: 20355\nEpsilon: 0.05\nTotal reward for episode: 91.7121019108306\nRunning average rewards: 7.396213454877218 \n\nEpisode: 258\nTrack generation: 1319..1653 -> 334-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0498 - mean_squared_error: 0.1522\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 94\nReplay buffer size: 20449\nTotal frame count: 20449\nEpsilon: 0.05\nTotal reward for episode: 10.448048048047497\nRunning average rewards: 7.3980148076318395 \n\nEpisode: 259\nTrack generation: 1224..1534 -> 310-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.1351 - mean_squared_error: 0.9061\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0973 - mean_squared_error: 0.2872\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 73\nReplay buffer size: 20522\nTotal frame count: 20522\nEpsilon: 0.05\nTotal reward for episode: -6.546278317152517\nRunning average rewards: 7.408147692330353 \n\nEpisode: 260\nTrack generation: 1260..1579 -> 319-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0819 - mean_squared_error: 0.3666\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0739 - mean_squared_error: 0.2622\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 87\nReplay buffer size: 20609\nTotal frame count: 20609\nEpsilon: 0.05\nTotal reward for episode: 6.080503144653619\nRunning average rewards: 7.319510100826071 \n\nEpisode: 261\nTrack generation: 1073..1354 -> 281-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0658 - mean_squared_error: 0.1787\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0750 - mean_squared_error: 0.2524\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 97\nReplay buffer size: 20706\nTotal frame count: 20706\nEpsilon: 0.05\nTotal reward for episode: 46.91428571428705\nRunning average rewards: 7.853010934622643 \n\nEpisode: 262\nTrack generation: 1140..1429 -> 289-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0516 - mean_squared_error: 0.1502\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0424 - mean_squared_error: 0.0962\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 102\nReplay buffer size: 20808\nTotal frame count: 20808\nEpsilon: 0.05\nTotal reward for episode: 32.11666666666758\nRunning average rewards: 8.016943033388088 \n\nEpisode: 263\nTrack generation: 1259..1578 -> 319-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0734 - mean_squared_error: 0.2397\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 63\nReplay buffer size: 20871\nTotal frame count: 20871\nEpsilon: 0.05\nTotal reward for episode: -3.187421383648143\nRunning average rewards: 7.975068819551609 \n\nEpisode: 264\nTrack generation: 1151..1443 -> 292-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0888 - mean_squared_error: 0.4311\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0498 - mean_squared_error: 0.1017\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0735 - mean_squared_error: 0.3229\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1038 - mean_squared_error: 0.5227\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 193\nReplay buffer size: 21064\nTotal frame count: 21064\nEpsilon: 0.05\nTotal reward for episode: 187.4048109965673\nRunning average rewards: 9.941116929517289 \n\nEpisode: 265\nTrack generation: 1071..1346 -> 275-tiles track\nretry to generate track (normal if there are not manyinstances of this message)\nTrack generation: 1168..1464 -> 296-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0792 - mean_squared_error: 0.2827\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0348 - mean_squared_error: 0.0931\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 113\nReplay buffer size: 21177\nTotal frame count: 21177\nEpsilon: 0.05\nTotal reward for episode: -7.9118644067803245\nRunning average rewards: 9.947318150769355 \n\nEpisode: 266\nTrack generation: 1141..1436 -> 295-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0476 - mean_squared_error: 0.1367\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0483 - mean_squared_error: 0.1439\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 90\nReplay buffer size: 21267\nTotal frame count: 21267\nEpsilon: 0.05\nTotal reward for episode: 49.034013605443675\nRunning average rewards: 9.44715828682376 \n\nEpisode: 267\nTrack generation: 1093..1378 -> 285-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0131 - mean_squared_error: 0.0263\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 79\nReplay buffer size: 21346\nTotal frame count: 21346\nEpsilon: 0.05\nTotal reward for episode: 66.99154929577601\nRunning average rewards: 9.830187048389925 \n\nEpisode: 268\nTrack generation: 1318..1653 -> 335-tiles track\n1/1 [==============================] - 0s 9ms/step - loss: 0.0472 - mean_squared_error: 0.1630\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0476 - mean_squared_error: 0.1519\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0647 - mean_squared_error: 0.2314\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0861 - mean_squared_error: 0.3388\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0479 - mean_squared_error: 0.1380\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 17\nTotal frames in episode: 238\nReplay buffer size: 21584\nTotal frame count: 21584\nEpsilon: 0.05\nTotal reward for episode: 33.74251497005857\nRunning average rewards: 10.149053191879336 \n\nEpisode: 269\nTrack generation: 1036..1299 -> 263-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0165 - mean_squared_error: 0.0342\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0422 - mean_squared_error: 0.1060\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 66\nReplay buffer size: 21650\nTotal frame count: 21650\nEpsilon: 0.05\nTotal reward for episode: 30.85190839694758\nRunning average rewards: 10.14740278432338 \n\nEpisode: 270\nTrack generation: 1115..1398 -> 283-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0335 - mean_squared_error: 0.0873\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0691 - mean_squared_error: 0.2914\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0770 - mean_squared_error: 0.2132\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0625 - mean_squared_error: 0.1869\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 229\nReplay buffer size: 21879\nTotal frame count: 21879\nEpsilon: 0.05\nTotal reward for episode: 28.96737588652927\nRunning average rewards: 10.312065712863767 \n\nEpisode: 271\nTrack generation: 1066..1343 -> 277-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0843 - mean_squared_error: 0.2714\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 58\nReplay buffer size: 21937\nTotal frame count: 21937\nEpsilon: 0.05\nTotal reward for episode: -5.084057971014822\nRunning average rewards: 10.10122513315362 \n\nEpisode: 272\nTrack generation: 1069..1340 -> 271-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0614 - mean_squared_error: 0.2628\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 59\nReplay buffer size: 21996\nTotal frame count: 21996\nEpsilon: 0.05\nTotal reward for episode: 13.437037037036689\nRunning average rewards: 10.213344552953652 \n\nEpisode: 273\nTrack generation: 919..1162 -> 243-tiles track\nretry to generate track (normal if there are not manyinstances of this message)\nTrack generation: 1227..1538 -> 311-tiles track\n1/1 [==============================] - 0s 9ms/step - loss: 0.1234 - mean_squared_error: 1.1835\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 14ms/step - loss: 0.0579 - mean_squared_error: 0.1571\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 65\nReplay buffer size: 22061\nTotal frame count: 22061\nEpsilon: 0.05\nTotal reward for episode: -0.19354838709713817\nRunning average rewards: 10.099422014066503 \n\nEpisode: 274\nTrack generation: 1311..1643 -> 332-tiles track\n1/1 [==============================] - 0s 9ms/step - loss: 0.0530 - mean_squared_error: 0.1436\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 61\nReplay buffer size: 22122\nTotal frame count: 22122\nEpsilon: 0.05\nTotal reward for episode: 8.832628398791197\nRunning average rewards: 10.202034012340134 \n\nEpisode: 275\nTrack generation: 1372..1719 -> 347-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0397 - mean_squared_error: 0.1168\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 66\nReplay buffer size: 22188\nTotal frame count: 22188\nEpsilon: 0.05\nTotal reward for episode: -3.278612716763387\nRunning average rewards: 10.130782131747843 \n\nEpisode: 276\nTrack generation: 1083..1358 -> 275-tiles track\n1/1 [==============================] - 0s 9ms/step - loss: 0.0572 - mean_squared_error: 0.1765\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0442 - mean_squared_error: 0.1066\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 62\nReplay buffer size: 22250\nTotal frame count: 22250\nEpsilon: 0.05\nTotal reward for episode: 18.995620437956134\nRunning average rewards: 10.21630628037828 \n\nEpisode: 277\nTrack generation: 1153..1445 -> 292-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0430 - mean_squared_error: 0.1184\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1059 - mean_squared_error: 0.3151\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 115\nReplay buffer size: 22365\nTotal frame count: 22365\nEpsilon: 0.05\nTotal reward for episode: 60.52920962199488\nRunning average rewards: 10.725793498549455 \n\nEpisode: 278\nTrack generation: 1222..1532 -> 310-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0640 - mean_squared_error: 0.1485\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 62\nReplay buffer size: 22427\nTotal frame count: 22427\nEpsilon: 0.05\nTotal reward for episode: 14.034951456310324\nRunning average rewards: 10.79390460251654 \n\nEpisode: 279\nTrack generation: 1171..1468 -> 297-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0680 - mean_squared_error: 0.1876\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 58\nReplay buffer size: 22485\nTotal frame count: 22485\nEpsilon: 0.05\nTotal reward for episode: 3.8270270270266984\nRunning average rewards: 10.65214660423557 \n\nEpisode: 280\nTrack generation: 1344..1684 -> 340-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0269 - mean_squared_error: 0.0751\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 62\nReplay buffer size: 22547\nTotal frame count: 22547\nEpsilon: 0.05\nTotal reward for episode: 7.64837758112057\nRunning average rewards: 10.32517714263669 \n\nEpisode: 281\nTrack generation: 1173..1478 -> 305-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0326 - mean_squared_error: 0.0781\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0748 - mean_squared_error: 0.2415\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 56\nReplay buffer size: 22603\nTotal frame count: 22603\nEpsilon: 0.05\nTotal reward for episode: -5.952631578947681\nRunning average rewards: 10.085079398275786 \n\nEpisode: 282\nTrack generation: 1290..1620 -> 330-tiles track\nretry to generate track (normal if there are not manyinstances of this message)\nTrack generation: 1139..1428 -> 289-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0441 - mean_squared_error: 0.1180\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 61\nReplay buffer size: 22664\nTotal frame count: 22664\nEpsilon: 0.05\nTotal reward for episode: 20.73888888888883\nRunning average rewards: 11.250504431742991 \n\nEpisode: 283\nTrack generation: 1157..1450 -> 293-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0470 - mean_squared_error: 0.1224\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 62\nReplay buffer size: 22726\nTotal frame count: 22726\nEpsilon: 0.05\nTotal reward for episode: 23.145205479452173\nRunning average rewards: 11.529244512427487 \n\nEpisode: 284\nTrack generation: 1026..1287 -> 261-tiles track\nretry to generate track (normal if there are not manyinstances of this message)\nTrack generation: 1030..1300 -> 270-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0431 - mean_squared_error: 0.1066\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 66\nReplay buffer size: 22792\nTotal frame count: 22792\nEpsilon: 0.05\nTotal reward for episode: 10.774721189590704\nRunning average rewards: 11.753605142853756 \n\nEpisode: 285\nTrack generation: 1022..1282 -> 260-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0484 - mean_squared_error: 0.1704\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0653 - mean_squared_error: 0.1799\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 66\nReplay buffer size: 22858\nTotal frame count: 22858\nEpsilon: 0.05\nTotal reward for episode: 50.82007722007853\nRunning average rewards: 12.21506907294928 \n\nEpisode: 286\nTrack generation: 1082..1356 -> 274-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0500 - mean_squared_error: 0.1261\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 62\nReplay buffer size: 22920\nTotal frame count: 22920\nEpsilon: 0.05\nTotal reward for episode: 26.482051282051806\nRunning average rewards: 12.191684807612795 \n\nEpisode: 287\nTrack generation: 1093..1370 -> 277-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0800 - mean_squared_error: 0.3027\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 68\nReplay buffer size: 22988\nTotal frame count: 22988\nEpsilon: 0.05\nTotal reward for episode: 27.14782608695716\nRunning average rewards: 12.499193143670338 \n\nEpisode: 288\nTrack generation: 1149..1440 -> 291-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0215 - mean_squared_error: 0.0530\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 60\nReplay buffer size: 23048\nTotal frame count: 23048\nEpsilon: 0.05\nTotal reward for episode: 10.482758620689332\nRunning average rewards: 12.520531911985861 \n\nEpisode: 289\nTrack generation: 1164..1459 -> 295-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0618 - mean_squared_error: 0.1617\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0722 - mean_squared_error: 0.2646\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 89\nReplay buffer size: 23137\nTotal frame count: 23137\nEpsilon: 0.05\nTotal reward for episode: 90.25034013605601\nRunning average rewards: 13.298796902750398 \n\nEpisode: 290\nTrack generation: 1202..1516 -> 314-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0601 - mean_squared_error: 0.2400\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0724 - mean_squared_error: 0.2719\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0943 - mean_squared_error: 0.5561\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 151\nReplay buffer size: 23288\nTotal frame count: 23288\nEpsilon: 0.05\nTotal reward for episode: 57.81086261981066\nRunning average rewards: 13.971119365426496 \n\nEpisode: 291\nTrack generation: 1017..1280 -> 263-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0611 - mean_squared_error: 0.1744\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 56\nReplay buffer size: 23344\nTotal frame count: 23344\nEpsilon: 0.05\nTotal reward for episode: -3.3160305343514658\nRunning average rewards: 14.029341696738932 \n\nEpisode: 292\nTrack generation: 1264..1584 -> 320-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0571 - mean_squared_error: 0.1835\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0768 - mean_squared_error: 0.2415\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0368 - mean_squared_error: 0.0977\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0808 - mean_squared_error: 0.3511\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 189\nReplay buffer size: 23533\nTotal frame count: 23533\nEpsilon: 0.05\nTotal reward for episode: 59.196238244516806\nRunning average rewards: 14.708413713735597 \n\nEpisode: 293\nTrack generation: 1265..1585 -> 320-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0504 - mean_squared_error: 0.1496\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 9ms/step - loss: 0.0691 - mean_squared_error: 0.1976\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0739 - mean_squared_error: 0.2620\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0537 - mean_squared_error: 0.1681\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 174\nReplay buffer size: 23707\nTotal frame count: 23707\nEpsilon: 0.05\nTotal reward for episode: 168.6445141065869\nRunning average rewards: 16.370448598391214 \n\nEpisode: 294\nTrack generation: 1107..1388 -> 281-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0376 - mean_squared_error: 0.1011\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 62\nReplay buffer size: 23769\nTotal frame count: 23769\nEpsilon: 0.05\nTotal reward for episode: 18.057142857142637\nRunning average rewards: 16.543654032726334 \n\nEpisode: 295\nTrack generation: 1228..1539 -> 311-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0727 - mean_squared_error: 0.2784\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0461 - mean_squared_error: 0.1376\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0552 - mean_squared_error: 0.2027\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0191 - mean_squared_error: 0.0399\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0661 - mean_squared_error: 0.1876\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 30\nTotal frames in episode: 238\nReplay buffer size: 24007\nTotal frame count: 24007\nEpsilon: 0.05\nTotal reward for episode: 208.2258064516172\nRunning average rewards: 18.6843009861314 \n\nEpisode: 296\nTrack generation: 1096..1374 -> 278-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0485 - mean_squared_error: 0.1766\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 72\nReplay buffer size: 24079\nTotal frame count: 24079\nEpsilon: 0.05\nTotal reward for episode: 28.961732851986355\nRunning average rewards: 18.981108188068987 \n\nEpisode: 297\nTrack generation: 1031..1293 -> 262-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0630 - mean_squared_error: 0.2602\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 67\nReplay buffer size: 24146\nTotal frame count: 24146\nEpsilon: 0.05\nTotal reward for episode: 45.99693486590161\nRunning average rewards: 18.99633679598725 \n\nEpisode: 298\nTrack generation: 1203..1508 -> 305-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0632 - mean_squared_error: 0.3237\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0292 - mean_squared_error: 0.0635\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 91\nReplay buffer size: 24237\nTotal frame count: 24237\nEpsilon: 0.05\nTotal reward for episode: 3.073684210525812\nRunning average rewards: 18.991252742570122 \n\nEpisode: 299\nTrack generation: 1048..1320 -> 272-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0706 - mean_squared_error: 0.1857\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0940 - mean_squared_error: 0.3908\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 99\nReplay buffer size: 24336\nTotal frame count: 24336\nEpsilon: 0.05\nTotal reward for episode: 60.03099630996478\nRunning average rewards: 19.659777470770447 \n\nEpisode: 300\nTrack generation: 1033..1303 -> 270-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0377 - mean_squared_error: 0.0962\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 56\nReplay buffer size: 24392\nTotal frame count: 24392\nEpsilon: 0.05\nTotal reward for episode: -3.8126394052047807\nRunning average rewards: 19.687423228617135 \n\nEpisode: 301\nTrack generation: 1196..1499 -> 303-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0415 - mean_squared_error: 0.1232\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0471 - mean_squared_error: 0.1392\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 64\nReplay buffer size: 24456\nTotal frame count: 24456\nEpsilon: 0.05\nTotal reward for episode: 10.823841059602266\nRunning average rewards: 19.86387640431383 \n\nEpisode: 302\nTrack generation: 1180..1479 -> 299-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0515 - mean_squared_error: 0.1579\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 60\nReplay buffer size: 24516\nTotal frame count: 24516\nEpsilon: 0.05\nTotal reward for episode: 9.557046979865415\nRunning average rewards: 20.010436493489653 \n\nEpisode: 303\nTrack generation: 1248..1564 -> 316-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0529 - mean_squared_error: 0.1389\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0306 - mean_squared_error: 0.0815\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 92\nReplay buffer size: 24608\nTotal frame count: 24608\nEpsilon: 0.05\nTotal reward for episode: -8.228571428571927\nRunning average rewards: 20.016137577883804 \n\nEpisode: 304\nTrack generation: 1016..1274 -> 258-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0461 - mean_squared_error: 0.1305\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 62\nReplay buffer size: 24670\nTotal frame count: 24670\nEpsilon: 0.05\nTotal reward for episode: 25.783657587549236\nRunning average rewards: 20.29719599676271 \n\nEpisode: 305\nTrack generation: 1261..1580 -> 319-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0340 - mean_squared_error: 0.0718\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 69\nReplay buffer size: 24739\nTotal frame count: 24739\nEpsilon: 0.05\nTotal reward for episode: 10.135849056603405\nRunning average rewards: 20.451906023164923 \n\nEpisode: 306\nTrack generation: 1205..1510 -> 305-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0366 - mean_squared_error: 0.1271\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0486 - mean_squared_error: 0.1379\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 68\nReplay buffer size: 24807\nTotal frame count: 24807\nEpsilon: 0.05\nTotal reward for episode: 18.852631578947005\nRunning average rewards: 20.6660196405417 \n\nEpisode: 307\nTrack generation: 1033..1301 -> 268-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0252 - mean_squared_error: 0.0589\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 56\nReplay buffer size: 24863\nTotal frame count: 24863\nEpsilon: 0.05\nTotal reward for episode: -3.673408239700695\nRunning average rewards: 20.705916382517458 \n\nEpisode: 308\nTrack generation: 1068..1341 -> 273-tiles track\nretry to generate track (normal if there are not manyinstances of this message)\nTrack generation: 1245..1560 -> 315-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0838 - mean_squared_error: 0.4246\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 62\nReplay buffer size: 24925\nTotal frame count: 24925\nEpsilon: 0.05\nTotal reward for episode: 22.970700636942567\nRunning average rewards: 21.002951633161697 \n\nEpisode: 309\nTrack generation: 1186..1487 -> 301-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0457 - mean_squared_error: 0.1024\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 65\nReplay buffer size: 24990\nTotal frame count: 24990\nEpsilon: 0.05\nTotal reward for episode: 13.999999999999652\nRunning average rewards: 20.752043884084184 \n\nEpisode: 310\nTrack generation: 1196..1502 -> 306-tiles track\nretry to generate track (normal if there are not manyinstances of this message)\nTrack generation: 1171..1468 -> 297-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0689 - mean_squared_error: 0.2117\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 55\nReplay buffer size: 25045\nTotal frame count: 25045\nEpsilon: 0.05\nTotal reward for episode: -8.4864864864868\nRunning average rewards: 20.551602860278923 \n\nEpisode: 311\nTrack generation: 1245..1561 -> 316-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0698 - mean_squared_error: 0.2035\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0551 - mean_squared_error: 0.1458\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 64\nReplay buffer size: 25109\nTotal frame count: 25109\nEpsilon: 0.05\nTotal reward for episode: 22.01904761904745\nRunning average rewards: 20.669015888398185 \n\nEpisode: 312\nTrack generation: 1071..1349 -> 278-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0922 - mean_squared_error: 0.5340\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0600 - mean_squared_error: 0.1613\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 108\nReplay buffer size: 25217\nTotal frame count: 25217\nEpsilon: 0.05\nTotal reward for episode: 61.49314079422564\nRunning average rewards: 21.37696316935632 \n\nEpisode: 313\nTrack generation: 996..1254 -> 258-tiles track\n1/1 [==============================] - 0s 9ms/step - loss: 0.0386 - mean_squared_error: 0.1302\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0781 - mean_squared_error: 0.2439\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 93\nReplay buffer size: 25310\nTotal frame count: 25310\nEpsilon: 0.05\nTotal reward for episode: 56.18521400778353\nRunning average rewards: 21.962012096582757 \n\nEpisode: 314\nTrack generation: 1128..1414 -> 286-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0928 - mean_squared_error: 0.4685\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 69\nReplay buffer size: 25379\nTotal frame count: 25379\nEpsilon: 0.05\nTotal reward for episode: 28.540350877193525\nRunning average rewards: 22.34241560535469 \n\nEpisode: 315\nTrack generation: 1057..1333 -> 276-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0569 - mean_squared_error: 0.2013\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0514 - mean_squared_error: 0.1387\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 117\nReplay buffer size: 25496\nTotal frame count: 25496\nEpsilon: 0.05\nTotal reward for episode: 51.38181818182022\nRunning average rewards: 22.733429359128618 \n\nEpisode: 316\nTrack generation: 1287..1613 -> 326-tiles track\n1/1 [==============================] - 0s 10ms/step - loss: 0.0717 - mean_squared_error: 0.1943\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0869 - mean_squared_error: 0.3777\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 68\nReplay buffer size: 25564\nTotal frame count: 25564\nEpsilon: 0.05\nTotal reward for episode: 31.26153846153897\nRunning average rewards: 23.09889456059382 \n\nEpisode: 317\nTrack generation: 1120..1404 -> 284-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0585 - mean_squared_error: 0.1566\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1123 - mean_squared_error: 0.3331\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 94\nReplay buffer size: 25658\nTotal frame count: 25658\nEpsilon: 0.05\nTotal reward for episode: 40.13851590106159\nRunning average rewards: 23.57249448470511 \n\nEpisode: 318\nTrack generation: 1108..1389 -> 281-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0454 - mean_squared_error: 0.1381\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 62\nReplay buffer size: 25720\nTotal frame count: 25720\nEpsilon: 0.05\nTotal reward for episode: 18.057142857142637\nRunning average rewards: 23.789753413276543 \n\nEpisode: 319\nTrack generation: 1170..1466 -> 296-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0494 - mean_squared_error: 0.1190\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0335 - mean_squared_error: 0.0863\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0628 - mean_squared_error: 0.2057\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 160\nReplay buffer size: 25880\nTotal frame count: 25880\nEpsilon: 0.05\nTotal reward for episode: 169.89830508474878\nRunning average rewards: 26.314826716831618 \n\nEpisode: 320\nTrack generation: 1252..1569 -> 317-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0573 - mean_squared_error: 0.1653\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0801 - mean_squared_error: 0.2909\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 78\nReplay buffer size: 25958\nTotal frame count: 25958\nEpsilon: 0.05\nTotal reward for episode: 13.103797468353974\nRunning average rewards: 26.593713748118933 \n\nEpisode: 321\nTrack generation: 1184..1484 -> 300-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0533 - mean_squared_error: 0.1454\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 78\nReplay buffer size: 26036\nTotal frame count: 26036\nEpsilon: 0.05\nTotal reward for episode: 42.3785953177273\nRunning average rewards: 26.89349970129621 \n\nEpisode: 322\nTrack generation: 1040..1312 -> 272-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0400 - mean_squared_error: 0.1021\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0717 - mean_squared_error: 0.2043\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 106\nReplay buffer size: 26142\nTotal frame count: 26142\nEpsilon: 0.05\nTotal reward for episode: 112.58154981549998\nRunning average rewards: 28.062813354432766 \n\nEpisode: 323\nTrack generation: 1084..1363 -> 279-tiles track\nretry to generate track (normal if there are not manyinstances of this message)\nTrack generation: 1190..1492 -> 302-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0338 - mean_squared_error: 0.1019\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0320 - mean_squared_error: 0.0710\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 68\nReplay buffer size: 26210\nTotal frame count: 26210\nEpsilon: 0.05\nTotal reward for episode: 45.88970099667898\nRunning average rewards: 28.05552854621772 \n\nEpisode: 324\nTrack generation: 1259..1578 -> 319-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0691 - mean_squared_error: 0.3464\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1030 - mean_squared_error: 0.3849\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 130\nReplay buffer size: 26340\nTotal frame count: 26340\nEpsilon: 0.05\nTotal reward for episode: 120.95597484276959\nRunning average rewards: 28.825300919230116 \n\nEpisode: 325\nTrack generation: 1128..1414 -> 286-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0552 - mean_squared_error: 0.1509\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0520 - mean_squared_error: 0.1472\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0647 - mean_squared_error: 0.1894\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0401 - mean_squared_error: 0.1337\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0845 - mean_squared_error: 0.5419\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 47\nTotal frames in episode: 238\nReplay buffer size: 26578\nTotal frame count: 26578\nEpsilon: 0.05\nTotal reward for episode: 217.28070175438825\nRunning average rewards: 31.062322701874677 \n\nEpisode: 326\nTrack generation: 1092..1369 -> 277-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0328 - mean_squared_error: 0.1066\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 67\nReplay buffer size: 26645\nTotal frame count: 26645\nEpsilon: 0.05\nTotal reward for episode: 42.04057971014615\nRunning average rewards: 31.57703074978 \n\nEpisode: 327\nTrack generation: 1215..1530 -> 315-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0466 - mean_squared_error: 0.1192\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0751 - mean_squared_error: 0.2291\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 79\nReplay buffer size: 26724\nTotal frame count: 26724\nEpsilon: 0.05\nTotal reward for episode: 44.83312101910971\nRunning average rewards: 31.742454210893587 \n\nEpisode: 328\nTrack generation: 1062..1337 -> 275-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0630 - mean_squared_error: 0.1819\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0849 - mean_squared_error: 0.2500\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 79\nReplay buffer size: 26803\nTotal frame count: 26803\nEpsilon: 0.05\nTotal reward for episode: 74.23941605839563\nRunning average rewards: 32.31214934235135 \n\nEpisode: 329\nTrack generation: 1119..1403 -> 284-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0680 - mean_squared_error: 0.2103\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 10ms/step - loss: 0.0422 - mean_squared_error: 0.1108\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 102\nReplay buffer size: 26905\nTotal frame count: 26905\nEpsilon: 0.05\nTotal reward for episode: 100.5427561837471\nRunning average rewards: 33.40056040253866 \n\nEpisode: 330\nTrack generation: 1042..1306 -> 264-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0753 - mean_squared_error: 0.2804\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 68\nReplay buffer size: 26973\nTotal frame count: 26973\nEpsilon: 0.05\nTotal reward for episode: 60.25247148289111\nRunning average rewards: 34.03769117797363 \n\nEpisode: 331\nTrack generation: 1145..1443 -> 298-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0493 - mean_squared_error: 0.1244\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0788 - mean_squared_error: 0.3040\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 89\nReplay buffer size: 27062\nTotal frame count: 27062\nEpsilon: 0.05\nTotal reward for episode: 68.77710437710593\nRunning average rewards: 34.789527795515184 \n\nEpisode: 332\nTrack generation: 1189..1492 -> 303-tiles track\nretry to generate track (normal if there are not manyinstances of this message)\nTrack generation: 1268..1589 -> 321-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0266 - mean_squared_error: 0.0582\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0604 - mean_squared_error: 0.2093\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0804 - mean_squared_error: 0.2332\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1085 - mean_squared_error: 0.4664\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1150 - mean_squared_error: 0.5929\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 22\nTotal frames in episode: 238\nReplay buffer size: 27300\nTotal frame count: 27300\nEpsilon: 0.05\nTotal reward for episode: 173.75000000000483\nRunning average rewards: 36.613694462181904 \n\nEpisode: 333\nTrack generation: 1149..1440 -> 291-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.1073 - mean_squared_error: 0.7085\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0655 - mean_squared_error: 0.2178\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 146\nReplay buffer size: 27446\nTotal frame count: 27446\nEpsilon: 0.05\nTotal reward for episode: 110.56551724138228\nRunning average rewards: 37.74045308287159 \n\nEpisode: 334\nTrack generation: 1125..1410 -> 285-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0526 - mean_squared_error: 0.2678\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0676 - mean_squared_error: 0.1851\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 66\nReplay buffer size: 27512\nTotal frame count: 27512\nEpsilon: 0.05\nTotal reward for episode: 15.85352112676022\nRunning average rewards: 37.972258135409035 \n\nEpisode: 335\nTrack generation: 1164..1466 -> 302-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0559 - mean_squared_error: 0.1591\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 22\nTotal frames in episode: 56\nReplay buffer size: 27568\nTotal frame count: 27568\nEpsilon: 0.05\nTotal reward for episode: -5.720930232557393\nRunning average rewards: 37.82171549975014 \n\nEpisode: 336\nTrack generation: 1252..1569 -> 317-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0753 - mean_squared_error: 0.2047\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1121 - mean_squared_error: 0.4072\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 130\nReplay buffer size: 27698\nTotal frame count: 27698\nEpsilon: 0.05\nTotal reward for episode: 137.8734177215216\nRunning average rewards: 39.05982683959511 \n\nEpisode: 337\nTrack generation: 1146..1436 -> 290-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0640 - mean_squared_error: 0.2262\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0945 - mean_squared_error: 0.3657\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1097 - mean_squared_error: 0.3217\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0627 - mean_squared_error: 0.1840\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 160\nReplay buffer size: 27858\nTotal frame count: 27858\nEpsilon: 0.05\nTotal reward for episode: 164.37370242214794\nRunning average rewards: 40.79934026133212 \n\nEpisode: 338\nTrack generation: 984..1234 -> 250-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.1026 - mean_squared_error: 0.3662\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 72\nReplay buffer size: 27930\nTotal frame count: 27930\nEpsilon: 0.05\nTotal reward for episode: 87.66586345381685\nRunning average rewards: 41.52294626429135 \n\nEpisode: 339\nTrack generation: 1256..1574 -> 318-tiles track\n1/1 [==============================] - 0s 9ms/step - loss: 0.0745 - mean_squared_error: 0.2039\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1042 - mean_squared_error: 0.4866\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0795 - mean_squared_error: 0.2627\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 121\nReplay buffer size: 28051\nTotal frame count: 28051\nEpsilon: 0.05\nTotal reward for episode: 109.32870662460815\nRunning average rewards: 42.46342829909089 \n\nEpisode: 340\nTrack generation: 1062..1332 -> 270-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0617 - mean_squared_error: 0.1968\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0268 - mean_squared_error: 0.0705\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0652 - mean_squared_error: 0.1993\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0763 - mean_squared_error: 0.3959\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 34\nTotal frames in episode: 238\nReplay buffer size: 28289\nTotal frame count: 28289\nEpsilon: 0.05\nTotal reward for episode: 124.33085501859048\nRunning average rewards: 43.799752722292666 \n\nEpisode: 341\nTrack generation: 1140..1429 -> 289-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0882 - mean_squared_error: 0.3047\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1805 - mean_squared_error: 1.5858\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0272 - mean_squared_error: 0.0590\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 117\nReplay buffer size: 28406\nTotal frame count: 28406\nEpsilon: 0.05\nTotal reward for episode: 29.588888888889706\nRunning average rewards: 44.16130394884391 \n\nEpisode: 342\nTrack generation: 1267..1588 -> 321-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0293 - mean_squared_error: 0.0660\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0773 - mean_squared_error: 0.2225\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 128\nReplay buffer size: 28534\nTotal frame count: 28534\nEpsilon: 0.05\nTotal reward for episode: 92.55000000000257\nRunning average rewards: 44.929713039753025 \n\nEpisode: 343\nTrack generation: 1133..1421 -> 288-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.1045 - mean_squared_error: 0.5438\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0637 - mean_squared_error: 0.2962\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0686 - mean_squared_error: 0.2364\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 122\nReplay buffer size: 28656\nTotal frame count: 28656\nEpsilon: 0.05\nTotal reward for episode: 73.15121951219753\nRunning average rewards: 44.850272214740755 \n\nEpisode: 344\nTrack generation: 1148..1438 -> 290-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0601 - mean_squared_error: 0.2381\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0643 - mean_squared_error: 0.2109\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 132\nReplay buffer size: 28788\nTotal frame count: 28788\nEpsilon: 0.05\nTotal reward for episode: 85.60830449827252\nRunning average rewards: 45.649939675307905 \n\nEpisode: 345\nTrack generation: 1048..1319 -> 271-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.1026 - mean_squared_error: 0.3334\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0691 - mean_squared_error: 0.2104\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 69\nReplay buffer size: 28857\nTotal frame count: 28857\nEpsilon: 0.05\nTotal reward for episode: 64.99259259259398\nRunning average rewards: 46.38097671234496 \n\nEpisode: 346\nTrack generation: 1313..1649 -> 336-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0712 - mean_squared_error: 0.2506\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 62\nReplay buffer size: 28919\nTotal frame count: 28919\nEpsilon: 0.05\nTotal reward for episode: 14.005970149253407\nRunning average rewards: 46.353036413837486 \n\nEpisode: 347\nTrack generation: 1237..1550 -> 313-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0844 - mean_squared_error: 0.3977\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1010 - mean_squared_error: 0.3533\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0901 - mean_squared_error: 0.2749\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 159\nReplay buffer size: 29078\nTotal frame count: 29078\nEpsilon: 0.05\nTotal reward for episode: 192.8102564102594\nRunning average rewards: 48.07993349848803 \n\nEpisode: 348\nTrack generation: 1111..1393 -> 282-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0946 - mean_squared_error: 0.4279\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 9ms/step - loss: 0.0596 - mean_squared_error: 0.1923\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 9ms/step - loss: 0.0708 - mean_squared_error: 0.2594\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 150\nReplay buffer size: 29228\nTotal frame count: 29228\nEpsilon: 0.05\nTotal reward for episode: 178.43416370107033\nRunning average rewards: 49.910970170959736 \n\nEpisode: 349\nTrack generation: 1085..1362 -> 277-tiles track\n1/1 [==============================] - 0s 9ms/step - loss: 0.0797 - mean_squared_error: 0.2364\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0571 - mean_squared_error: 0.1967\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0579 - mean_squared_error: 0.1766\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 141\nReplay buffer size: 29369\nTotal frame count: 29369\nEpsilon: 0.05\nTotal reward for episode: 121.13623188405921\nRunning average rewards: 50.9784615220584 \n\nEpisode: 350\nTrack generation: 1164..1460 -> 296-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0656 - mean_squared_error: 0.1984\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0679 - mean_squared_error: 0.2843\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0725 - mean_squared_error: 0.2730\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0448 - mean_squared_error: 0.1639\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 203\nReplay buffer size: 29572\nTotal frame count: 29572\nEpsilon: 0.05\nTotal reward for episode: 81.51186440678222\nRunning average rewards: 51.656867837359094 \n\nEpisode: 351\nTrack generation: 1073..1345 -> 272-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0370 - mean_squared_error: 0.0978\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 57\nReplay buffer size: 29629\nTotal frame count: 29629\nEpsilon: 0.05\nTotal reward for episode: -11.729889298893312\nRunning average rewards: 50.82766258985508 \n\nEpisode: 352\nTrack generation: 1279..1603 -> 324-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.1094 - mean_squared_error: 0.5130\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 60\nReplay buffer size: 29689\nTotal frame count: 29689\nEpsilon: 0.05\nTotal reward for episode: 10.055727554179228\nRunning average rewards: 50.75526211891801 \n\nEpisode: 353\nTrack generation: 1178..1477 -> 299-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0514 - mean_squared_error: 0.1572\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0157 - mean_squared_error: 0.0347\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 62\nReplay buffer size: 29751\nTotal frame count: 29751\nEpsilon: 0.05\nTotal reward for episode: 15.468456375838556\nRunning average rewards: 50.945976757864365 \n\nEpisode: 354\nTrack generation: 1283..1608 -> 325-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0684 - mean_squared_error: 0.2376\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0479 - mean_squared_error: 0.1397\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 129\nReplay buffer size: 29880\nTotal frame count: 29880\nEpsilon: 0.05\nTotal reward for episode: 96.54814814814961\nRunning average rewards: 51.40308944501959 \n\nEpisode: 355\nTrack generation: 1107..1388 -> 281-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0468 - mean_squared_error: 0.1466\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0718 - mean_squared_error: 0.1817\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 110\nReplay buffer size: 29990\nTotal frame count: 29990\nEpsilon: 0.05\nTotal reward for episode: 2.4285714285708124\nRunning average rewards: 50.68550654616658 \n\nEpisode: 356\nTrack generation: 990..1242 -> 252-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0446 - mean_squared_error: 0.1085\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 55\nReplay buffer size: 30045\nTotal frame count: 30045\nEpsilon: 0.05\nTotal reward for episode: -14.031872509960472\nRunning average rewards: 50.462607175905674 \n\nEpisode: 357\nTrack generation: 1050..1323 -> 273-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0853 - mean_squared_error: 0.3676\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0572 - mean_squared_error: 0.1516\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 96\nReplay buffer size: 30141\nTotal frame count: 30141\nEpsilon: 0.05\nTotal reward for episode: 86.60000000000154\nRunning average rewards: 50.411486156797395 \n\nEpisode: 358\nTrack generation: 1206..1516 -> 310-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.1068 - mean_squared_error: 0.3847\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0649 - mean_squared_error: 0.2393\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 101\nReplay buffer size: 30242\nTotal frame count: 30242\nEpsilon: 0.05\nTotal reward for episode: 43.742394822007554\nRunning average rewards: 50.74442962453699 \n\nEpisode: 359\nTrack generation: 1071..1343 -> 272-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0565 - mean_squared_error: 0.1588\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1417 - mean_squared_error: 0.6132\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0682 - mean_squared_error: 0.2572\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0845 - mean_squared_error: 0.2570\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0603 - mean_squared_error: 0.1700\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 1\nTotal frames in episode: 238\nReplay buffer size: 30480\nTotal frame count: 30480\nEpsilon: 0.05\nTotal reward for episode: 547.0664206641978\nRunning average rewards: 56.28055661435049 \n\nEpisode: 360\nTrack generation: 1032..1294 -> 262-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0870 - mean_squared_error: 0.3847\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0900 - mean_squared_error: 0.2971\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0940 - mean_squared_error: 0.4331\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0850 - mean_squared_error: 0.3204\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 177\nReplay buffer size: 30657\nTotal frame count: 30657\nEpsilon: 0.05\nTotal reward for episode: 289.3532567049758\nRunning average rewards: 59.11328414995373 \n\nEpisode: 361\nTrack generation: 1088..1364 -> 276-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0560 - mean_squared_error: 0.1488\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1299 - mean_squared_error: 0.4955\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1036 - mean_squared_error: 0.2953\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 159\nReplay buffer size: 30816\nTotal frame count: 30816\nEpsilon: 0.05\nTotal reward for episode: 176.4000000000031\nRunning average rewards: 60.40814129281089 \n\nEpisode: 362\nTrack generation: 1110..1392 -> 282-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0514 - mean_squared_error: 0.2797\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 11ms/step - loss: 0.0838 - mean_squared_error: 0.2800\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1155 - mean_squared_error: 0.3699\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 134\nReplay buffer size: 30950\nTotal frame count: 30950\nEpsilon: 0.05\nTotal reward for episode: 191.9516014234899\nRunning average rewards: 62.006490640379106 \n\nEpisode: 363\nTrack generation: 1166..1462 -> 296-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0701 - mean_squared_error: 0.2106\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0648 - mean_squared_error: 0.2003\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1096 - mean_squared_error: 0.3745\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 11ms/step - loss: 0.0752 - mean_squared_error: 0.2753\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 42\nTotal frames in episode: 238\nReplay buffer size: 31188\nTotal frame count: 31188\nEpsilon: 0.05\nTotal reward for episode: 325.33898305084034\nRunning average rewards: 65.291754684724 \n\nEpisode: 364\nTrack generation: 1152..1444 -> 292-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0846 - mean_squared_error: 0.2535\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0609 - mean_squared_error: 0.1810\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 100\nReplay buffer size: 31288\nTotal frame count: 31288\nEpsilon: 0.05\nTotal reward for episode: 83.71134020618764\nRunning average rewards: 64.25481997682019 \n\nEpisode: 365\nTrack generation: 1006..1267 -> 261-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0531 - mean_squared_error: 0.1562\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0244 - mean_squared_error: 0.0526\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0681 - mean_squared_error: 0.2372\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1213 - mean_squared_error: 0.5214\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 173\nReplay buffer size: 31461\nTotal frame count: 31461\nEpsilon: 0.05\nTotal reward for episode: 369.26153846153096\nRunning average rewards: 68.0265540055033 \n\nEpisode: 366\nTrack generation: 1108..1397 -> 289-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0730 - mean_squared_error: 0.3163\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 81\nReplay buffer size: 31542\nTotal frame count: 31542\nEpsilon: 0.05\nTotal reward for episode: 103.01666666666834\nRunning average rewards: 68.56638053611556 \n\nEpisode: 367\nTrack generation: 942..1192 -> 250-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0648 - mean_squared_error: 0.2109\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0652 - mean_squared_error: 0.2681\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 103\nReplay buffer size: 31645\nTotal frame count: 31645\nEpsilon: 0.05\nTotal reward for episode: 115.42650602409876\nRunning average rewards: 69.05073010339878 \n\nEpisode: 368\nTrack generation: 1140..1429 -> 289-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0778 - mean_squared_error: 0.2969\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0555 - mean_squared_error: 0.1564\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0929 - mean_squared_error: 0.3220\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0757 - mean_squared_error: 0.2202\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0606 - mean_squared_error: 0.1798\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 209\nReplay buffer size: 31854\nTotal frame count: 31854\nEpsilon: 0.05\nTotal reward for episode: 270.56666666666393\nRunning average rewards: 71.41897162036484 \n\nEpisode: 369\nTrack generation: 1211..1518 -> 307-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0714 - mean_squared_error: 0.2271\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 70\nReplay buffer size: 31924\nTotal frame count: 31924\nEpsilon: 0.05\nTotal reward for episode: 17.75163398692773\nRunning average rewards: 71.28796887626464 \n\nEpisode: 370\nTrack generation: 1116..1399 -> 283-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.1218 - mean_squared_error: 0.6604\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 61\nReplay buffer size: 31985\nTotal frame count: 31985\nEpsilon: 0.05\nTotal reward for episode: 14.607092198581206\nRunning average rewards: 71.14436603938515 \n\nEpisode: 371\nTrack generation: 1114..1403 -> 289-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0993 - mean_squared_error: 0.4620\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0571 - mean_squared_error: 0.1348\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 77\nReplay buffer size: 32062\nTotal frame count: 32062\nEpsilon: 0.05\nTotal reward for episode: 80.31111111111265\nRunning average rewards: 71.99831773020644 \n\nEpisode: 372\nTrack generation: 1320..1654 -> 334-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0746 - mean_squared_error: 0.2502\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 9ms/step - loss: 0.1164 - mean_squared_error: 0.8358\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0685 - mean_squared_error: 0.2440\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0642 - mean_squared_error: 0.2169\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1063 - mean_squared_error: 0.3543\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 3\nTotal frames in episode: 238\nReplay buffer size: 32300\nTotal frame count: 32300\nEpsilon: 0.05\nTotal reward for episode: 478.57357357356943\nRunning average rewards: 76.64968309557176 \n\nEpisode: 373\nTrack generation: 1064..1330 -> 266-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0788 - mean_squared_error: 0.4421\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 75\nReplay buffer size: 32375\nTotal frame count: 32375\nEpsilon: 0.05\nTotal reward for episode: 34.150943396227774\nRunning average rewards: 76.993128013405 \n\nEpisode: 374\nTrack generation: 1053..1320 -> 267-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0903 - mean_squared_error: 0.2709\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 62\nReplay buffer size: 32437\nTotal frame count: 32437\nEpsilon: 0.05\nTotal reward for episode: 24.07218045112822\nRunning average rewards: 77.14552353392838 \n\nEpisode: 375\nTrack generation: 1112..1394 -> 282-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0766 - mean_squared_error: 0.2603\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0967 - mean_squared_error: 0.2922\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 101\nReplay buffer size: 32538\nTotal frame count: 32538\nEpsilon: 0.05\nTotal reward for episode: 59.24412811388086\nRunning average rewards: 77.77075094223483 \n\nEpisode: 376\nTrack generation: 967..1220 -> 253-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0600 - mean_squared_error: 0.1462\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1214 - mean_squared_error: 0.5152\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 80\nReplay buffer size: 32618\nTotal frame count: 32618\nEpsilon: 0.05\nTotal reward for episode: 114.82539682539857\nRunning average rewards: 78.72904870610924 \n\nEpisode: 377\nTrack generation: 1280..1604 -> 324-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0723 - mean_squared_error: 0.3002\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1095 - mean_squared_error: 0.7052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 97\nReplay buffer size: 32715\nTotal frame count: 32715\nEpsilon: 0.05\nTotal reward for episode: 54.079256965945675\nRunning average rewards: 78.66454917954876 \n\nEpisode: 378\nTrack generation: 922..1161 -> 239-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0868 - mean_squared_error: 0.3230\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 71\nReplay buffer size: 32786\nTotal frame count: 32786\nEpsilon: 0.05\nTotal reward for episode: 72.44033613445515\nRunning average rewards: 79.24860302633019 \n\nEpisode: 379\nTrack generation: 1033..1303 -> 270-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0684 - mean_squared_error: 0.2374\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0728 - mean_squared_error: 0.2184\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 80\nReplay buffer size: 32866\nTotal frame count: 32866\nEpsilon: 0.05\nTotal reward for episode: 101.82899628252942\nRunning average rewards: 80.22862271888523 \n\nEpisode: 380\nTrack generation: 1179..1478 -> 299-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0326 - mean_squared_error: 0.1263\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 62\nReplay buffer size: 32928\nTotal frame count: 32928\nEpsilon: 0.05\nTotal reward for episode: 12.112751677851975\nRunning average rewards: 80.27326645985254 \n\nEpisode: 381\nTrack generation: 1009..1265 -> 256-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.1622 - mean_squared_error: 0.8321\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0315 - mean_squared_error: 0.0856\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0849 - mean_squared_error: 0.3241\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0805 - mean_squared_error: 0.2792\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0724 - mean_squared_error: 0.2636\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 1\nTotal frames in episode: 238\nReplay buffer size: 33166\nTotal frame count: 33166\nEpsilon: 0.05\nTotal reward for episode: 603.0392156862628\nRunning average rewards: 86.36318493250465 \n\nEpisode: 382\nTrack generation: 1152..1444 -> 292-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0512 - mean_squared_error: 0.1465\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0742 - mean_squared_error: 0.2480\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 110\nReplay buffer size: 33276\nTotal frame count: 33276\nEpsilon: 0.05\nTotal reward for episode: 100.32989690721868\nRunning average rewards: 87.15909501268794 \n\nEpisode: 383\nTrack generation: 1065..1339 -> 274-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.1104 - mean_squared_error: 0.3463\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0580 - mean_squared_error: 0.2797\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0622 - mean_squared_error: 0.2123\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 133\nReplay buffer size: 33409\nTotal frame count: 33409\nEpsilon: 0.05\nTotal reward for episode: 27.386080586080773\nRunning average rewards: 87.20150376375425 \n\nEpisode: 384\nTrack generation: 1150..1442 -> 292-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.1105 - mean_squared_error: 0.5056\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 61\nReplay buffer size: 33470\nTotal frame count: 33470\nEpsilon: 0.05\nTotal reward for episode: 13.400687285223036\nRunning average rewards: 87.22776342471053 \n\nEpisode: 385\nTrack generation: 1367..1713 -> 346-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0990 - mean_squared_error: 0.5324\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0949 - mean_squared_error: 0.3240\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0761 - mean_squared_error: 0.4232\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0953 - mean_squared_error: 0.3452\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 218\nReplay buffer size: 33688\nTotal frame count: 33688\nEpsilon: 0.05\nTotal reward for episode: 133.08985507246643\nRunning average rewards: 88.05046120323442 \n\nEpisode: 386\nTrack generation: 1092..1369 -> 277-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0837 - mean_squared_error: 0.2755\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.6609 - mean_squared_error: 67.7748\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0808 - mean_squared_error: 0.3302\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1121 - mean_squared_error: 0.4117\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0718 - mean_squared_error: 0.2312\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 14\nTotal frames in episode: 238\nReplay buffer size: 33926\nTotal frame count: 33926\nEpsilon: 0.05\nTotal reward for episode: 336.1594202898482\nRunning average rewards: 91.1472348933124 \n\nEpisode: 387\nTrack generation: 1079..1353 -> 274-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0727 - mean_squared_error: 0.2269\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1167 - mean_squared_error: 0.3897\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0678 - mean_squared_error: 0.1932\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0886 - mean_squared_error: 0.3962\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0638 - mean_squared_error: 0.2092\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 235\nReplay buffer size: 34161\nTotal frame count: 34161\nEpsilon: 0.05\nTotal reward for episode: 290.6153846153733\nRunning average rewards: 93.78191047859656 \n\nEpisode: 388\nTrack generation: 1140..1429 -> 289-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.1045 - mean_squared_error: 0.3643\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0544 - mean_squared_error: 0.1328\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 123\nReplay buffer size: 34284\nTotal frame count: 34284\nEpsilon: 0.05\nTotal reward for episode: 141.77222222222503\nRunning average rewards: 95.09480511461193 \n\nEpisode: 389\nTrack generation: 952..1201 -> 249-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0925 - mean_squared_error: 0.4011\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0673 - mean_squared_error: 0.2032\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 84\nReplay buffer size: 34368\nTotal frame count: 34368\nEpsilon: 0.05\nTotal reward for episode: 107.52903225806621\nRunning average rewards: 95.26759203583204 \n\nEpisode: 390\nTrack generation: 1336..1674 -> 338-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0881 - mean_squared_error: 0.3331\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0406 - mean_squared_error: 0.0988\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0808 - mean_squared_error: 0.3712\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0548 - mean_squared_error: 0.2014\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 9ms/step - loss: 0.0888 - mean_squared_error: 0.2812\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 232\nReplay buffer size: 34600\nTotal frame count: 34600\nEpsilon: 0.05\nTotal reward for episode: 376.0427299703178\nRunning average rewards: 98.44991070933709 \n\nEpisode: 391\nTrack generation: 1024..1284 -> 260-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0684 - mean_squared_error: 0.2998\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 11ms/step - loss: 0.1159 - mean_squared_error: 0.4293\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1332 - mean_squared_error: 0.6386\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0803 - mean_squared_error: 0.2825\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 0\nTotal frames in episode: 238\nReplay buffer size: 34838\nTotal frame count: 34838\nEpsilon: 0.05\nTotal reward for episode: 314.2664092663987\nRunning average rewards: 101.62573510734457 \n\nEpisode: 392\nTrack generation: 1191..1493 -> 302-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0785 - mean_squared_error: 0.2451\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0763 - mean_squared_error: 0.2597\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 104\nReplay buffer size: 34942\nTotal frame count: 34942\nEpsilon: 0.05\nTotal reward for episode: 54.745514950167305\nRunning average rewards: 101.58122787440108 \n\nEpisode: 393\nTrack generation: 1159..1453 -> 294-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0744 - mean_squared_error: 0.2596\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1293 - mean_squared_error: 0.5275\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1054 - mean_squared_error: 0.4327\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0638 - mean_squared_error: 0.2806\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 179\nReplay buffer size: 35121\nTotal frame count: 35121\nEpsilon: 0.05\nTotal reward for episode: 259.45802047781154\nRunning average rewards: 102.48936293811333 \n\nEpisode: 394\nTrack generation: 1174..1489 -> 315-tiles track\nretry to generate track (normal if there are not manyinstances of this message)\nTrack generation: 1118..1402 -> 284-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0643 - mean_squared_error: 0.1780\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1154 - mean_squared_error: 0.4267\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1219 - mean_squared_error: 0.4793\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 144\nReplay buffer size: 35265\nTotal frame count: 35265\nEpsilon: 0.05\nTotal reward for episode: 210.95123674911878\nRunning average rewards: 104.41830387703311 \n\nEpisode: 395\nTrack generation: 1064..1334 -> 270-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.1307 - mean_squared_error: 0.5882\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 67\nReplay buffer size: 35332\nTotal frame count: 35332\nEpsilon: 0.05\nTotal reward for episode: 54.98438661710168\nRunning average rewards: 102.88588967868795 \n\nEpisode: 396\nTrack generation: 1199..1509 -> 310-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0718 - mean_squared_error: 0.2468\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1203 - mean_squared_error: 0.6251\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 36\nTotal frames in episode: 69\nReplay buffer size: 35401\nTotal frame count: 35401\nEpsilon: 0.05\nTotal reward for episode: -33.54886731391457\nRunning average rewards: 102.26078367702894 \n\nEpisode: 397\nTrack generation: 1334..1672 -> 338-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0876 - mean_squared_error: 0.3243\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 71\nReplay buffer size: 35472\nTotal frame count: 35472\nEpsilon: 0.05\nTotal reward for episode: 19.077744807121256\nRunning average rewards: 101.99159177644113 \n\nEpisode: 398\nTrack generation: 1028..1288 -> 260-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0407 - mean_squared_error: 0.1026\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1548 - mean_squared_error: 0.6561\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 98\nReplay buffer size: 35570\nTotal frame count: 35570\nEpsilon: 0.05\nTotal reward for episode: 142.26718146718363\nRunning average rewards: 103.3835267490077 \n\nEpisode: 399\nTrack generation: 1023..1283 -> 260-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0584 - mean_squared_error: 0.2086\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0916 - mean_squared_error: 0.4202\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.5967 - mean_squared_error: 59.0098\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1405 - mean_squared_error: 0.8381\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1170 - mean_squared_error: 0.3812\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 0\nTotal frames in episode: 238\nReplay buffer size: 35808\nTotal frame count: 35808\nEpsilon: 0.05\nTotal reward for episode: 383.7644787644688\nRunning average rewards: 106.62086157355277 \n\nEpisode: 400\nTrack generation: 1055..1323 -> 268-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0740 - mean_squared_error: 0.2864\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 9ms/step - loss: 0.0567 - mean_squared_error: 0.1626\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 98\nReplay buffer size: 35906\nTotal frame count: 35906\nEpsilon: 0.05\nTotal reward for episode: 91.88614232209909\nRunning average rewards: 107.57784939082582 \n\nEpisode: 401\nTrack generation: 1396..1749 -> 353-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0461 - mean_squared_error: 0.1133\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0903 - mean_squared_error: 0.3262\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 138\nReplay buffer size: 36044\nTotal frame count: 36044\nEpsilon: 0.05\nTotal reward for episode: 64.11818181818418\nRunning average rewards: 108.11079279841162 \n\nEpisode: 402\nTrack generation: 1203..1508 -> 305-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0914 - mean_squared_error: 0.2806\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1880 - mean_squared_error: 1.2552\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 9ms/step - loss: 0.1081 - mean_squared_error: 0.4800\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0698 - mean_squared_error: 0.2501\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1339 - mean_squared_error: 0.7019\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 1\nTotal frames in episode: 238\nReplay buffer size: 36282\nTotal frame count: 36282\nEpsilon: 0.05\nTotal reward for episode: 434.60526315788525\nRunning average rewards: 112.36127496019182 \n\nEpisode: 403\nTrack generation: 1168..1464 -> 296-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0276 - mean_squared_error: 0.0689\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0436 - mean_squared_error: 0.1459\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0479 - mean_squared_error: 0.1384\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1133 - mean_squared_error: 0.4003\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0824 - mean_squared_error: 0.2918\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 15\nTotal frames in episode: 238\nReplay buffer size: 36520\nTotal frame count: 36520\nEpsilon: 0.05\nTotal reward for episode: 410.08474576270174\nRunning average rewards: 116.54440813210456 \n\nEpisode: 404\nTrack generation: 1283..1608 -> 325-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.1491 - mean_squared_error: 0.8303\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0955 - mean_squared_error: 0.4537\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1072 - mean_squared_error: 0.4547\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1422 - mean_squared_error: 0.5468\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1064 - mean_squared_error: 0.5238\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 1\nTotal frames in episode: 238\nReplay buffer size: 36758\nTotal frame count: 36758\nEpsilon: 0.05\nTotal reward for episode: 398.8271604938226\nRunning average rewards: 120.2748431611673 \n\nEpisode: 405\nTrack generation: 1220..1529 -> 309-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0707 - mean_squared_error: 0.2296\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0562 - mean_squared_error: 0.1676\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0713 - mean_squared_error: 0.2372\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 149\nReplay buffer size: 36907\nTotal frame count: 36907\nEpsilon: 0.05\nTotal reward for episode: 141.6987012987042\nRunning average rewards: 121.5904716835883 \n\nEpisode: 406\nTrack generation: 1374..1721 -> 347-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.1126 - mean_squared_error: 0.5585\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 9ms/step - loss: 0.0606 - mean_squared_error: 0.2079\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 115\nReplay buffer size: 37022\nTotal frame count: 37022\nEpsilon: 0.05\nTotal reward for episode: 110.06936416185201\nRunning average rewards: 122.50263900941735 \n\nEpisode: 407\nTrack generation: 1060..1336 -> 276-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.1173 - mean_squared_error: 0.4956\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0723 - mean_squared_error: 0.2559\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1045 - mean_squared_error: 0.4186\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1141 - mean_squared_error: 0.4676\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0644 - mean_squared_error: 0.2583\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 2\nTotal frames in episode: 238\nReplay buffer size: 37260\nTotal frame count: 37260\nEpsilon: 0.05\nTotal reward for episode: 417.727272727265\nRunning average rewards: 126.71664581908699 \n\nEpisode: 408\nTrack generation: 1247..1563 -> 316-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0994 - mean_squared_error: 0.3963\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0732 - mean_squared_error: 0.2419\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0632 - mean_squared_error: 0.1970\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1316 - mean_squared_error: 0.6879\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 9\nTotal frames in episode: 238\nReplay buffer size: 37498\nTotal frame count: 37498\nEpsilon: 0.05\nTotal reward for episode: 149.44444444444585\nRunning average rewards: 127.98138325716204 \n\nEpisode: 409\nTrack generation: 1196..1499 -> 303-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0972 - mean_squared_error: 0.3227\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0798 - mean_squared_error: 0.2440\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1289 - mean_squared_error: 0.6033\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 107\nReplay buffer size: 37605\nTotal frame count: 37605\nEpsilon: 0.05\nTotal reward for episode: 69.7827814569558\nRunning average rewards: 128.5392110717316 \n\nEpisode: 410\nTrack generation: 1118..1401 -> 283-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.1002 - mean_squared_error: 0.3454\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1840 - mean_squared_error: 1.4648\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 137\nReplay buffer size: 37742\nTotal frame count: 37742\nEpsilon: 0.05\nTotal reward for episode: 193.42695035461313\nRunning average rewards: 130.55834544014257 \n\nEpisode: 411\nTrack generation: 1124..1409 -> 285-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.1072 - mean_squared_error: 0.4719\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0719 - mean_squared_error: 0.2214\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0721 - mean_squared_error: 0.2037\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0920 - mean_squared_error: 0.2913\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 170\nReplay buffer size: 37912\nTotal frame count: 37912\nEpsilon: 0.05\nTotal reward for episode: 174.95774647887683\nRunning average rewards: 132.08773242874085 \n\nEpisode: 412\nTrack generation: 1164..1459 -> 295-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.1368 - mean_squared_error: 0.7828\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 66\nReplay buffer size: 37978\nTotal frame count: 37978\nEpsilon: 0.05\nTotal reward for episode: 45.02857142857263\nRunning average rewards: 131.92308673508435 \n\nEpisode: 413\nTrack generation: 1167..1467 -> 300-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0830 - mean_squared_error: 0.3602\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0595 - mean_squared_error: 0.1743\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 92\nReplay buffer size: 38070\nTotal frame count: 38070\nEpsilon: 0.05\nTotal reward for episode: 50.156521739132316\nRunning average rewards: 131.86279981239784 \n\nEpisode: 414\nTrack generation: 1127..1413 -> 286-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0997 - mean_squared_error: 0.3905\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0825 - mean_squared_error: 0.2661\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0820 - mean_squared_error: 0.2895\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1101 - mean_squared_error: 0.4504\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 182\nReplay buffer size: 38252\nTotal frame count: 38252\nEpsilon: 0.05\nTotal reward for episode: 369.3052631578862\nRunning average rewards: 135.27044893520477 \n\nEpisode: 415\nTrack generation: 1052..1319 -> 267-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0339 - mean_squared_error: 0.0860\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0799 - mean_squared_error: 0.3045\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2153 - mean_squared_error: 1.3550\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0754 - mean_squared_error: 0.2608\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 212\nReplay buffer size: 38464\nTotal frame count: 38464\nEpsilon: 0.05\nTotal reward for episode: 351.29022556389793\nRunning average rewards: 138.26953300902557 \n\nEpisode: 416\nTrack generation: 1161..1455 -> 294-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.1198 - mean_squared_error: 0.5564\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0987 - mean_squared_error: 0.3736\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0966 - mean_squared_error: 0.3490\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0695 - mean_squared_error: 0.2654\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0625 - mean_squared_error: 0.1859\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 8\nTotal frames in episode: 238\nReplay buffer size: 38702\nTotal frame count: 38702\nEpsilon: 0.05\nTotal reward for episode: 372.57679180886356\nRunning average rewards: 141.6826855424988 \n\nEpisode: 417\nTrack generation: 1310..1649 -> 339-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0563 - mean_squared_error: 0.1592\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0731 - mean_squared_error: 0.2408\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0583 - mean_squared_error: 0.1702\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0749 - mean_squared_error: 0.2713\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 1\nTotal frames in episode: 238\nReplay buffer size: 38940\nTotal frame count: 38940\nEpsilon: 0.05\nTotal reward for episode: 254.11242603550534\nRunning average rewards: 143.82242464384325 \n\nEpisode: 418\nTrack generation: 1130..1416 -> 286-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0687 - mean_squared_error: 0.2639\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0740 - mean_squared_error: 0.2151\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 10ms/step - loss: 0.0634 - mean_squared_error: 0.1953\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 9ms/step - loss: 0.0977 - mean_squared_error: 0.3396\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0941 - mean_squared_error: 0.3350\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 228\nReplay buffer size: 39168\nTotal frame count: 39168\nEpsilon: 0.05\nTotal reward for episode: 389.50175438595204\nRunning average rewards: 147.53687075913132 \n\nEpisode: 419\nTrack generation: 1068..1339 -> 271-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0751 - mean_squared_error: 0.2382\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 69\nReplay buffer size: 39237\nTotal frame count: 39237\nEpsilon: 0.05\nTotal reward for episode: 57.58518518518659\nRunning average rewards: 146.41373956013567 \n\nEpisode: 420\nTrack generation: 1164..1459 -> 295-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2170 - mean_squared_error: 2.7231\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0599 - mean_squared_error: 0.2291\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1365 - mean_squared_error: 0.5120\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0628 - mean_squared_error: 0.1805\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 210\nReplay buffer size: 39447\nTotal frame count: 39447\nEpsilon: 0.05\nTotal reward for episode: 273.1428571428512\nRunning average rewards: 149.01413015688067 \n\nEpisode: 421\nTrack generation: 1042..1312 -> 270-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0843 - mean_squared_error: 0.2941\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 9ms/step - loss: 0.0862 - mean_squared_error: 0.3700\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1074 - mean_squared_error: 0.4654\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1242 - mean_squared_error: 0.5574\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1129 - mean_squared_error: 0.4773\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 205\nReplay buffer size: 39652\nTotal frame count: 39652\nEpsilon: 0.05\nTotal reward for episode: 341.79182156133004\nRunning average rewards: 152.00826241931668 \n\nEpisode: 422\nTrack generation: 1011..1268 -> 257-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0895 - mean_squared_error: 0.2641\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0692 - mean_squared_error: 0.1770\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 139\nReplay buffer size: 39791\nTotal frame count: 39791\nEpsilon: 0.05\nTotal reward for episode: 202.21250000000276\nRunning average rewards: 152.9045719211617 \n\nEpisode: 423\nTrack generation: 1088..1364 -> 276-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.1242 - mean_squared_error: 0.5062\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1571 - mean_squared_error: 1.1282\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 9ms/step - loss: 0.1230 - mean_squared_error: 0.5878\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 114\nReplay buffer size: 39905\nTotal frame count: 39905\nEpsilon: 0.05\nTotal reward for episode: 27.12727272727392\nRunning average rewards: 152.71694763846767 \n\nEpisode: 424\nTrack generation: 1139..1428 -> 289-tiles track\n1/1 [==============================] - 0s 9ms/step - loss: 0.1174 - mean_squared_error: 0.6412\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1271 - mean_squared_error: 0.4414\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0703 - mean_squared_error: 0.2482\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0979 - mean_squared_error: 0.3818\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 220\nReplay buffer size: 40125\nTotal frame count: 40125\nEpsilon: 0.05\nTotal reward for episode: 162.00000000000475\nRunning average rewards: 153.12738789004004 \n\nEpisode: 425\nTrack generation: 1109..1390 -> 281-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.1042 - mean_squared_error: 0.4179\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1328 - mean_squared_error: 0.5924\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0897 - mean_squared_error: 0.3084\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0903 - mean_squared_error: 0.3388\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 185\nReplay buffer size: 40310\nTotal frame count: 40310\nEpsilon: 0.05\nTotal reward for episode: 265.285714285705\nRunning average rewards: 153.6074380153532 \n\nEpisode: 426\nTrack generation: 1143..1433 -> 290-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0528 - mean_squared_error: 0.1525\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1927 - mean_squared_error: 0.9031\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1577 - mean_squared_error: 0.6636\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0851 - mean_squared_error: 0.2743\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 1\nTotal frames in episode: 238\nReplay buffer size: 40548\nTotal frame count: 40548\nEpsilon: 0.05\nTotal reward for episode: 403.2698961937647\nRunning average rewards: 157.21973118018937 \n\nEpisode: 427\nTrack generation: 1272..1601 -> 329-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0557 - mean_squared_error: 0.1258\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1903 - mean_squared_error: 1.1859\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1001 - mean_squared_error: 0.4060\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1784 - mean_squared_error: 0.7164\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 189\nReplay buffer size: 40737\nTotal frame count: 40737\nEpsilon: 0.05\nTotal reward for episode: 271.9609756097515\nRunning average rewards: 159.49100972609577 \n\nEpisode: 428\nTrack generation: 1083..1358 -> 275-tiles track\nretry to generate track (normal if there are not manyinstances of this message)\nTrack generation: 1120..1404 -> 284-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.1342 - mean_squared_error: 0.5734\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1057 - mean_squared_error: 0.3882\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 17ms/step - loss: 0.0766 - mean_squared_error: 0.2120\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1126 - mean_squared_error: 0.3680\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 212\nReplay buffer size: 40949\nTotal frame count: 40949\nEpsilon: 0.05\nTotal reward for episode: 296.8254416961092\nRunning average rewards: 161.71686998247293 \n\nEpisode: 429\nTrack generation: 1220..1529 -> 309-tiles track\n1/1 [==============================] - 0s 9ms/step - loss: 0.0737 - mean_squared_error: 0.3394\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1858 - mean_squared_error: 1.0751\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0666 - mean_squared_error: 0.1823\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1750 - mean_squared_error: 0.7521\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1650 - mean_squared_error: 0.9672\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 2\nTotal frames in episode: 238\nReplay buffer size: 41187\nTotal frame count: 41187\nEpsilon: 0.05\nTotal reward for episode: 330.3246753246766\nRunning average rewards: 164.0146891738822 \n\nEpisode: 430\nTrack generation: 1114..1398 -> 284-tiles track\nretry to generate track (normal if there are not manyinstances of this message)\nTrack generation: 1424..1783 -> 359-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.1798 - mean_squared_error: 1.5117\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1204 - mean_squared_error: 0.6765\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0595 - mean_squared_error: 0.1642\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0474 - mean_squared_error: 0.1261\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0879 - mean_squared_error: 0.3046\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 1\nTotal frames in episode: 238\nReplay buffer size: 41425\nTotal frame count: 41425\nEpsilon: 0.05\nTotal reward for episode: 371.48044692736954\nRunning average rewards: 167.12696892832702 \n\nEpisode: 431\nTrack generation: 1212..1519 -> 307-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.1394 - mean_squared_error: 0.7010\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1737 - mean_squared_error: 1.2609\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0816 - mean_squared_error: 0.2647\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0835 - mean_squared_error: 0.2744\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1075 - mean_squared_error: 0.4136\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 35\nTotal frames in episode: 238\nReplay buffer size: 41663\nTotal frame count: 41663\nEpsilon: 0.05\nTotal reward for episode: 355.9803921568552\nRunning average rewards: 169.99900180612454 \n\nEpisode: 432\nTrack generation: 1051..1318 -> 267-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.1404 - mean_squared_error: 0.6164\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0715 - mean_squared_error: 0.2203\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0866 - mean_squared_error: 0.3135\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1394 - mean_squared_error: 0.6731\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0786 - mean_squared_error: 0.2503\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 6\nTotal frames in episode: 238\nReplay buffer size: 41901\nTotal frame count: 41901\nEpsilon: 0.05\nTotal reward for episode: 589.2105263157757\nRunning average rewards: 174.15360706928223 \n\nEpisode: 433\nTrack generation: 1104..1384 -> 280-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0626 - mean_squared_error: 0.1998\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 71\nReplay buffer size: 41972\nTotal frame count: 41972\nEpsilon: 0.05\nTotal reward for episode: 46.86881720430243\nRunning average rewards: 173.51664006891144 \n\nEpisode: 434\nTrack generation: 1375..1723 -> 348-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.1530 - mean_squared_error: 0.5920\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1983 - mean_squared_error: 1.6340\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0968 - mean_squared_error: 0.3329\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 169\nReplay buffer size: 42141\nTotal frame count: 42141\nEpsilon: 0.05\nTotal reward for episode: 145.6564841498589\nRunning average rewards: 174.8146696991424 \n\nEpisode: 435\nTrack generation: 1173..1478 -> 305-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.1166 - mean_squared_error: 0.4131\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0546 - mean_squared_error: 0.1901\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0694 - mean_squared_error: 0.3057\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0585 - mean_squared_error: 0.1991\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1297 - mean_squared_error: 0.4628\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 237\nReplay buffer size: 42378\nTotal frame count: 42378\nEpsilon: 0.05\nTotal reward for episode: 293.3578947368345\nRunning average rewards: 177.8054579488363 \n\nEpisode: 436\nTrack generation: 1035..1299 -> 264-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.1694 - mean_squared_error: 0.9716\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1270 - mean_squared_error: 0.5033\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1290 - mean_squared_error: 0.5681\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 41\nTotal frames in episode: 137\nReplay buffer size: 42515\nTotal frame count: 42515\nEpsilon: 0.05\nTotal reward for episode: 107.65741444867231\nRunning average rewards: 177.50329791610784 \n\nEpisode: 437\nTrack generation: 993..1251 -> 258-tiles track\n1/1 [==============================] - 0s 9ms/step - loss: 0.1727 - mean_squared_error: 0.9887\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0699 - mean_squared_error: 0.2019\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1373 - mean_squared_error: 0.5003\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1563 - mean_squared_error: 0.6092\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 200\nReplay buffer size: 42715\nTotal frame count: 42715\nEpsilon: 0.05\nTotal reward for episode: 344.1245136186709\nRunning average rewards: 179.30080602807305 \n\nEpisode: 438\nTrack generation: 1059..1334 -> 275-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.1229 - mean_squared_error: 0.8183\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1203 - mean_squared_error: 0.5428\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0802 - mean_squared_error: 0.3721\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1405 - mean_squared_error: 0.4928\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1927 - mean_squared_error: 0.9904\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 2\nTotal frames in episode: 238\nReplay buffer size: 42953\nTotal frame count: 42953\nEpsilon: 0.05\nTotal reward for episode: 375.80291970802415\nRunning average rewards: 182.1821765906151 \n\nEpisode: 439\nTrack generation: 1268..1589 -> 321-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.1343 - mean_squared_error: 0.7133\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0603 - mean_squared_error: 0.2216\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 144\nReplay buffer size: 43097\nTotal frame count: 43097\nEpsilon: 0.05\nTotal reward for episode: 186.15000000000282\nRunning average rewards: 182.9503895243691 \n\nEpisode: 440\nTrack generation: 1104..1384 -> 280-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.1320 - mean_squared_error: 0.6870\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1018 - mean_squared_error: 0.3252\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0723 - mean_squared_error: 0.2324\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1317 - mean_squared_error: 0.5653\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0826 - mean_squared_error: 0.3311\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 1\nTotal frames in episode: 238\nReplay buffer size: 43335\nTotal frame count: 43335\nEpsilon: 0.05\nTotal reward for episode: 392.4551971326105\nRunning average rewards: 185.63163294550927 \n\nEpisode: 441\nTrack generation: 1245..1569 -> 324-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.1689 - mean_squared_error: 0.9266\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2018 - mean_squared_error: 1.3266\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1049 - mean_squared_error: 0.4529\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0989 - mean_squared_error: 0.3648\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0629 - mean_squared_error: 0.1745\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 31\nTotal frames in episode: 238\nReplay buffer size: 43573\nTotal frame count: 43573\nEpsilon: 0.05\nTotal reward for episode: 357.0123839009191\nRunning average rewards: 188.90586789562957 \n\nEpisode: 442\nTrack generation: 1183..1483 -> 300-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.1669 - mean_squared_error: 1.1665\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0713 - mean_squared_error: 0.2299\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1384 - mean_squared_error: 0.7855\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0780 - mean_squared_error: 0.2446\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1369 - mean_squared_error: 1.4216\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 1\nTotal frames in episode: 238\nReplay buffer size: 43811\nTotal frame count: 43811\nEpsilon: 0.05\nTotal reward for episode: 386.60535117056395\nRunning average rewards: 191.84642140733516 \n\nEpisode: 443\nTrack generation: 1180..1479 -> 299-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.1466 - mean_squared_error: 0.7116\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 79\nReplay buffer size: 43890\nTotal frame count: 43890\nEpsilon: 0.05\nTotal reward for episode: 32.158389261745995\nRunning average rewards: 191.43649310483067 \n\nEpisode: 444\nTrack generation: 1450..1819 -> 369-tiles track\nretry to generate track (normal if there are not manyinstances of this message)\nTrack generation: 1272..1594 -> 322-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.1394 - mean_squared_error: 0.6616\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1495 - mean_squared_error: 0.5062\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 10ms/step - loss: 0.0954 - mean_squared_error: 0.3851\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0868 - mean_squared_error: 0.3757\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0974 - mean_squared_error: 0.3321\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 49\nTotal frames in episode: 238\nReplay buffer size: 44128\nTotal frame count: 44128\nEpsilon: 0.05\nTotal reward for episode: 378.52024922117505\nRunning average rewards: 194.36561255205967 \n\nEpisode: 445\nTrack generation: 1097..1375 -> 278-tiles track\n1/1 [==============================] - 0s 9ms/step - loss: 0.0460 - mean_squared_error: 0.1721\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1505 - mean_squared_error: 0.7187\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1253 - mean_squared_error: 0.4476\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1341 - mean_squared_error: 0.4626\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0769 - mean_squared_error: 0.2926\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 32\nTotal frames in episode: 238\nReplay buffer size: 44366\nTotal frame count: 44366\nEpsilon: 0.05\nTotal reward for episode: 468.17689530684584\nRunning average rewards: 198.39745557920222 \n\nEpisode: 446\nTrack generation: 1119..1403 -> 284-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.1252 - mean_squared_error: 0.5908\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0693 - mean_squared_error: 0.2597\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1698 - mean_squared_error: 0.9154\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1060 - mean_squared_error: 0.3548\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1447 - mean_squared_error: 0.4972\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 0\nTotal frames in episode: 238\nReplay buffer size: 44604\nTotal frame count: 44604\nEpsilon: 0.05\nTotal reward for episode: 632.915194346275\nRunning average rewards: 204.58654782117242 \n\nEpisode: 447\nTrack generation: 1291..1618 -> 327-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.1218 - mean_squared_error: 0.5594\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1006 - mean_squared_error: 0.5910\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1388 - mean_squared_error: 0.5350\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 14ms/step - loss: 0.1771 - mean_squared_error: 0.8572\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 35\nTotal frames in episode: 238\nReplay buffer size: 44842\nTotal frame count: 44842\nEpsilon: 0.05\nTotal reward for episode: 346.71779141103957\nRunning average rewards: 206.12562317118022 \n\nEpisode: 448\nTrack generation: 1144..1434 -> 290-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.1292 - mean_squared_error: 0.5357\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2672 - mean_squared_error: 2.9325\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1814 - mean_squared_error: 0.9364\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 140\nReplay buffer size: 44982\nTotal frame count: 44982\nEpsilon: 0.05\nTotal reward for episode: 238.11764705881956\nRunning average rewards: 206.72245800475773 \n\nEpisode: 449\nTrack generation: 1220..1529 -> 309-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.1532 - mean_squared_error: 0.5506\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2512 - mean_squared_error: 4.5680\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1271 - mean_squared_error: 0.4569\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1773 - mean_squared_error: 0.8934\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 217\nReplay buffer size: 45199\nTotal frame count: 45199\nEpsilon: 0.05\nTotal reward for episode: 273.58961038960757\nRunning average rewards: 208.2469917898132 \n\nEpisode: 450\nTrack generation: 1179..1478 -> 299-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.2602 - mean_squared_error: 2.0662\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1004 - mean_squared_error: 0.3595\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1508 - mean_squared_error: 0.7762\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.2114 - mean_squared_error: 1.6833\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1673 - mean_squared_error: 1.1957\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 1\nTotal frames in episode: 238\nReplay buffer size: 45437\nTotal frame count: 45437\nEpsilon: 0.05\nTotal reward for episode: 509.02684563757407\nRunning average rewards: 212.5221416021211 \n\nEpisode: 451\nTrack generation: 1076..1349 -> 273-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2654 - mean_squared_error: 3.3329\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 60\nReplay buffer size: 45497\nTotal frame count: 45497\nEpsilon: 0.05\nTotal reward for episode: 20.11764705882358\nRunning average rewards: 212.84061696569833 \n\nEpisode: 452\nTrack generation: 1113..1395 -> 282-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.1359 - mean_squared_error: 0.7643\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.2741 - mean_squared_error: 1.8550\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1423 - mean_squared_error: 0.5786\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 152\nReplay buffer size: 45649\nTotal frame count: 45649\nEpsilon: 0.05\nTotal reward for episode: 295.07188612099196\nRunning average rewards: 215.69077855136646 \n\nEpisode: 453\nTrack generation: 1131..1419 -> 288-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.1778 - mean_squared_error: 1.3106\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1469 - mean_squared_error: 0.6329\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2124 - mean_squared_error: 1.4213\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2280 - mean_squared_error: 1.4184\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1204 - mean_squared_error: 0.4235\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 202\nReplay buffer size: 45851\nTotal frame count: 45851\nEpsilon: 0.05\nTotal reward for episode: 257.1790940766498\nRunning average rewards: 218.10788492837457 \n\nEpisode: 454\nTrack generation: 1254..1571 -> 317-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.1110 - mean_squared_error: 0.3949\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0692 - mean_squared_error: 0.1953\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 103\nReplay buffer size: 45954\nTotal frame count: 45954\nEpsilon: 0.05\nTotal reward for episode: 129.68607594936933\nRunning average rewards: 218.43926420638675 \n\nEpisode: 455\nTrack generation: 1059..1328 -> 269-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0848 - mean_squared_error: 0.2564\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1394 - mean_squared_error: 0.8369\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1522 - mean_squared_error: 0.6418\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1783 - mean_squared_error: 0.8375\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 1\nTotal frames in episode: 238\nReplay buffer size: 46192\nTotal frame count: 46192\nEpsilon: 0.05\nTotal reward for episode: 543.0597014925225\nRunning average rewards: 223.8455755070263 \n\nEpisode: 456\nTrack generation: 1253..1570 -> 317-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2481 - mean_squared_error: 1.3207\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2218 - mean_squared_error: 1.4284\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1148 - mean_squared_error: 0.4371\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1111 - mean_squared_error: 0.3820\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1648 - mean_squared_error: 0.8503\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 1\nTotal frames in episode: 238\nReplay buffer size: 46430\nTotal frame count: 46430\nEpsilon: 0.05\nTotal reward for episode: 401.83544303796185\nRunning average rewards: 228.0042486625055 \n\nEpisode: 457\nTrack generation: 1132..1426 -> 294-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.1427 - mean_squared_error: 0.7088\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1334 - mean_squared_error: 0.7038\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1340 - mean_squared_error: 0.5835\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1570 - mean_squared_error: 0.7577\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.2306 - mean_squared_error: 1.1604\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 0\nTotal frames in episode: 238\nReplay buffer size: 46668\nTotal frame count: 46668\nEpsilon: 0.05\nTotal reward for episode: 321.3822525597284\nRunning average rewards: 230.35207118810274 \n\nEpisode: 458\nTrack generation: 1314..1647 -> 333-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.1660 - mean_squared_error: 1.2421\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1989 - mean_squared_error: 1.3955\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1289 - mean_squared_error: 0.4957\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1450 - mean_squared_error: 0.7238\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2031 - mean_squared_error: 0.9763\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 14\nTotal frames in episode: 238\nReplay buffer size: 46906\nTotal frame count: 46906\nEpsilon: 0.05\nTotal reward for episode: 417.04819277107947\nRunning average rewards: 234.08512916759346 \n\nEpisode: 459\nTrack generation: 1116..1398 -> 282-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.1020 - mean_squared_error: 0.3879\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1118 - mean_squared_error: 0.3458\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1335 - mean_squared_error: 0.9636\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1519 - mean_squared_error: 0.9559\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 0\nTotal frames in episode: 238\nReplay buffer size: 47144\nTotal frame count: 47144\nEpsilon: 0.05\nTotal reward for episode: 467.2775800711586\nRunning average rewards: 233.287240761663 \n\nEpisode: 460\nTrack generation: 1084..1359 -> 275-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.1243 - mean_squared_error: 0.5834\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1047 - mean_squared_error: 0.3693\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1445 - mean_squared_error: 0.8678\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 10ms/step - loss: 0.1703 - mean_squared_error: 0.9110\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.2097 - mean_squared_error: 1.2783\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 226\nReplay buffer size: 47370\nTotal frame count: 47370\nEpsilon: 0.05\nTotal reward for episode: 267.2642335766405\nRunning average rewards: 233.06635053037968 \n\nEpisode: 461\nTrack generation: 1069..1340 -> 271-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0437 - mean_squared_error: 0.1043\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1899 - mean_squared_error: 1.0269\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 106\nReplay buffer size: 47476\nTotal frame count: 47476\nEpsilon: 0.05\nTotal reward for episode: 268.71111111110577\nRunning average rewards: 233.98946164149066 \n\nEpisode: 462\nTrack generation: 1141..1430 -> 289-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.1443 - mean_squared_error: 1.2913\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1326 - mean_squared_error: 0.5611\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1165 - mean_squared_error: 0.4528\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1486 - mean_squared_error: 0.8201\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1609 - mean_squared_error: 0.8326\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 7\nTotal frames in episode: 238\nReplay buffer size: 47714\nTotal frame count: 47714\nEpsilon: 0.05\nTotal reward for episode: 689.7222222222088\nRunning average rewards: 238.96716784947787 \n\nEpisode: 463\nTrack generation: 1180..1479 -> 299-tiles track\n1/1 [==============================] - 0s 9ms/step - loss: 0.1819 - mean_squared_error: 1.0843\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0946 - mean_squared_error: 0.3763\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1327 - mean_squared_error: 0.6491\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 162\nReplay buffer size: 47876\nTotal frame count: 47876\nEpsilon: 0.05\nTotal reward for episode: 314.3946308724782\nRunning average rewards: 238.85772432769426 \n\nEpisode: 464\nTrack generation: 1016..1274 -> 258-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0985 - mean_squared_error: 0.3423\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1456 - mean_squared_error: 0.5780\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1404 - mean_squared_error: 0.4922\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 124\nReplay buffer size: 48000\nTotal frame count: 48000\nEpsilon: 0.05\nTotal reward for episode: 191.6451361867726\nRunning average rewards: 239.9370622875001 \n\nEpisode: 465\nTrack generation: 1141..1430 -> 289-tiles track\n1/1 [==============================] - 0s 11ms/step - loss: 0.1467 - mean_squared_error: 1.1750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1421 - mean_squared_error: 0.6553\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 133\nReplay buffer size: 48133\nTotal frame count: 48133\nEpsilon: 0.05\nTotal reward for episode: 262.7722222222163\nRunning average rewards: 238.872169125107 \n\nEpisode: 466\nTrack generation: 1047..1320 -> 273-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.1931 - mean_squared_error: 0.7518\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1493 - mean_squared_error: 0.9675\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1442 - mean_squared_error: 0.6470\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 139\nReplay buffer size: 48272\nTotal frame count: 48272\nEpsilon: 0.05\nTotal reward for episode: 87.78235294117935\nRunning average rewards: 238.7198259878521 \n\nEpisode: 467\nTrack generation: 1048..1314 -> 266-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.1649 - mean_squared_error: 0.7609\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1461 - mean_squared_error: 1.1622\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1018 - mean_squared_error: 0.4107\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1696 - mean_squared_error: 0.7127\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1425 - mean_squared_error: 0.5471\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 1\nTotal frames in episode: 238\nReplay buffer size: 48510\nTotal frame count: 48510\nEpsilon: 0.05\nTotal reward for episode: 448.3962264150864\nRunning average rewards: 242.04952319176198 \n\nEpisode: 468\nTrack generation: 1247..1563 -> 316-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.1318 - mean_squared_error: 1.1254\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.2089 - mean_squared_error: 1.2798\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.2406 - mean_squared_error: 1.5778\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0929 - mean_squared_error: 0.3542\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 10\nTotal frames in episode: 238\nReplay buffer size: 48748\nTotal frame count: 48748\nEpsilon: 0.05\nTotal reward for episode: 371.66666666665816\nRunning average rewards: 243.06052319176194 \n\nEpisode: 469\nTrack generation: 1033..1304 -> 271-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0563 - mean_squared_error: 0.1673\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1551 - mean_squared_error: 0.7761\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 82\nReplay buffer size: 48830\nTotal frame count: 48830\nEpsilon: 0.05\nTotal reward for episode: 126.45925925926082\nRunning average rewards: 244.14759944448525 \n\nEpisode: 470\nTrack generation: 1159..1458 -> 299-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.1694 - mean_squared_error: 0.9557\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1429 - mean_squared_error: 0.7700\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 72\nReplay buffer size: 48902\nTotal frame count: 48902\nEpsilon: 0.05\nTotal reward for episode: 61.80402684563897\nRunning average rewards: 244.61956879095587 \n\nEpisode: 471\nTrack generation: 1191..1493 -> 302-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.1096 - mean_squared_error: 0.4832\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1369 - mean_squared_error: 0.6051\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1191 - mean_squared_error: 0.5376\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1473 - mean_squared_error: 0.6273\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 0\nTotal frames in episode: 238\nReplay buffer size: 49140\nTotal frame count: 49140\nEpsilon: 0.05\nTotal reward for episode: 569.4518272425146\nRunning average rewards: 249.51097595226983 \n\nEpisode: 472\nTrack generation: 980..1229 -> 249-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.1275 - mean_squared_error: 0.6645\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1627 - mean_squared_error: 1.1451\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1049 - mean_squared_error: 0.5245\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1430 - mean_squared_error: 0.6058\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1793 - mean_squared_error: 0.9643\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 5\nTotal frames in episode: 238\nReplay buffer size: 49378\nTotal frame count: 49378\nEpsilon: 0.05\nTotal reward for episode: 558.2258064515997\nRunning average rewards: 250.3074982810502 \n\nEpisode: 473\nTrack generation: 1002..1256 -> 254-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.1751 - mean_squared_error: 0.9995\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1529 - mean_squared_error: 0.6374\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1336 - mean_squared_error: 0.4905\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0985 - mean_squared_error: 0.4188\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 10ms/step - loss: 0.1098 - mean_squared_error: 0.5531\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 0\nTotal frames in episode: 238\nReplay buffer size: 49616\nTotal frame count: 49616\nEpsilon: 0.05\nTotal reward for episode: 616.4624505928748\nRunning average rewards: 256.13061335301666 \n\nEpisode: 474\nTrack generation: 1180..1479 -> 299-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0570 - mean_squared_error: 0.1523\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0982 - mean_squared_error: 0.3289\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1561 - mean_squared_error: 0.8111\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2373 - mean_squared_error: 1.7165\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1081 - mean_squared_error: 0.3546\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 1\nTotal frames in episode: 238\nReplay buffer size: 49854\nTotal frame count: 49854\nEpsilon: 0.05\nTotal reward for episode: 609.6979865771647\nRunning average rewards: 261.986871414277 \n\nEpisode: 475\nTrack generation: 1148..1439 -> 291-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0929 - mean_squared_error: 0.5186\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1702 - mean_squared_error: 1.2490\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 142\nReplay buffer size: 49996\nTotal frame count: 49996\nEpsilon: 0.05\nTotal reward for episode: 246.64827586206172\nRunning average rewards: 263.8609128917588 \n\nEpisode: 476\nTrack generation: 1056..1324 -> 268-tiles track\n1/1 [==============================] - 0s 10ms/step - loss: 0.1170 - mean_squared_error: 0.4551\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.2348 - mean_squared_error: 1.1828\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1551 - mean_squared_error: 0.8303\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 9ms/step - loss: 0.1882 - mean_squared_error: 1.0576\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1591 - mean_squared_error: 0.6304\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 0\nTotal frames in episode: 238\nReplay buffer size: 50234\nTotal frame count: 50234\nEpsilon: 0.05\nTotal reward for episode: 740.2059925093515\nRunning average rewards: 270.11471884859833 \n\nEpisode: 477\nTrack generation: 1270..1591 -> 321-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.1840 - mean_squared_error: 0.8537\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1467 - mean_squared_error: 0.7049\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1733 - mean_squared_error: 0.9083\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2108 - mean_squared_error: 1.0124\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1545 - mean_squared_error: 0.7318\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 50\nTotal frames in episode: 238\nReplay buffer size: 50472\nTotal frame count: 50472\nEpsilon: 0.05\nTotal reward for episode: 379.99999999998965\nRunning average rewards: 273.37392627893877 \n\nEpisode: 478\nTrack generation: 1110..1392 -> 282-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.2184 - mean_squared_error: 1.2475\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1247 - mean_squared_error: 0.6573\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1145 - mean_squared_error: 0.4321\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 131\nReplay buffer size: 50603\nTotal frame count: 50603\nEpsilon: 0.05\nTotal reward for episode: 75.7138790035615\nRunning average rewards: 273.40666170762984 \n\nEpisode: 479\nTrack generation: 1068..1339 -> 271-tiles track\n1/1 [==============================] - 0s 9ms/step - loss: 0.1816 - mean_squared_error: 0.8538\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1328 - mean_squared_error: 0.5805\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 108\nReplay buffer size: 50711\nTotal frame count: 50711\nEpsilon: 0.05\nTotal reward for episode: 197.54074074074248\nRunning average rewards: 274.363779152212 \n\nEpisode: 480\nTrack generation: 1371..1718 -> 347-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.1112 - mean_squared_error: 0.4234\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1423 - mean_squared_error: 0.5268\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0964 - mean_squared_error: 0.3874\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1255 - mean_squared_error: 0.4103\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 1\nTotal frames in episode: 238\nReplay buffer size: 50949\nTotal frame count: 50949\nEpsilon: 0.05\nTotal reward for episode: 491.70520231212765\nRunning average rewards: 279.15970365855475 \n\nEpisode: 481\nTrack generation: 1202..1515 -> 313-tiles track\n1/1 [==============================] - 0s 16ms/step - loss: 0.1545 - mean_squared_error: 0.6053\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1385 - mean_squared_error: 0.5357\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1445 - mean_squared_error: 0.7192\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2212 - mean_squared_error: 0.9777\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1312 - mean_squared_error: 0.5642\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 30\nTotal frames in episode: 238\nReplay buffer size: 51187\nTotal frame count: 51187\nEpsilon: 0.05\nTotal reward for episode: 459.4871794871674\nRunning average rewards: 277.7241832965638 \n\nEpisode: 482\nTrack generation: 1139..1428 -> 289-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.1630 - mean_squared_error: 0.7495\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1218 - mean_squared_error: 0.5144\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1454 - mean_squared_error: 0.7889\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1167 - mean_squared_error: 0.4009\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2986 - mean_squared_error: 4.3293\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 6\nTotal frames in episode: 238\nReplay buffer size: 51425\nTotal frame count: 51425\nEpsilon: 0.05\nTotal reward for episode: 606.3888888888752\nRunning average rewards: 282.78477321638036 \n\nEpisode: 483\nTrack generation: 1315..1648 -> 333-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.2202 - mean_squared_error: 1.4633\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.2030 - mean_squared_error: 0.8500\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1047 - mean_squared_error: 0.4643\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 138\nReplay buffer size: 51563\nTotal frame count: 51563\nEpsilon: 0.05\nTotal reward for episode: 212.87228915662968\nRunning average rewards: 284.6396353020858 \n\nEpisode: 484\nTrack generation: 1189..1490 -> 301-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.1488 - mean_squared_error: 0.6199\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2374 - mean_squared_error: 1.4251\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2469 - mean_squared_error: 1.6372\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1881 - mean_squared_error: 0.8473\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1797 - mean_squared_error: 0.9021\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 0\nTotal frames in episode: 238\nReplay buffer size: 51801\nTotal frame count: 51801\nEpsilon: 0.05\nTotal reward for episode: 441.6666666666628\nRunning average rewards: 288.92229509590027 \n\nEpisode: 485\nTrack generation: 1126..1419 -> 293-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.1741 - mean_squared_error: 0.7489\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1618 - mean_squared_error: 0.7374\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1491 - mean_squared_error: 0.5641\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.2262 - mean_squared_error: 1.3693\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 1\nTotal frames in episode: 238\nReplay buffer size: 52039\nTotal frame count: 52039\nEpsilon: 0.05\nTotal reward for episode: 394.72602739724834\nRunning average rewards: 291.5386568191481 \n\nEpisode: 486\nTrack generation: 1307..1638 -> 331-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.1151 - mean_squared_error: 0.4710\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1550 - mean_squared_error: 0.5774\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0914 - mean_squared_error: 0.3193\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.2706 - mean_squared_error: 1.6505\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1384 - mean_squared_error: 0.6111\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 0\nTotal frames in episode: 238\nReplay buffer size: 52277\nTotal frame count: 52277\nEpsilon: 0.05\nTotal reward for episode: 526.2121212121077\nRunning average rewards: 293.4391838283707 \n\nEpisode: 487\nTrack generation: 1160..1454 -> 294-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.1422 - mean_squared_error: 0.5670\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1256 - mean_squared_error: 0.5674\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 115\nReplay buffer size: 52392\nTotal frame count: 52392\nEpsilon: 0.05\nTotal reward for episode: 104.17064846416623\nRunning average rewards: 291.5747364668586 \n\nEpisode: 488\nTrack generation: 1142..1432 -> 290-tiles track\n1/1 [==============================] - 0s 10ms/step - loss: 0.0959 - mean_squared_error: 0.2894\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1797 - mean_squared_error: 0.6951\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0700 - mean_squared_error: 0.2011\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1982 - mean_squared_error: 1.4617\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 174\nReplay buffer size: 52566\nTotal frame count: 52566\nEpsilon: 0.05\nTotal reward for episode: 380.22698961936896\nRunning average rewards: 293.95928414083005 \n\nEpisode: 489\nTrack generation: 1123..1408 -> 285-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.1614 - mean_squared_error: 1.0181\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0897 - mean_squared_error: 0.3639\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1243 - mean_squared_error: 0.5980\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 171\nReplay buffer size: 52737\nTotal frame count: 52737\nEpsilon: 0.05\nTotal reward for episode: 329.48732394365345\nRunning average rewards: 296.1788670576859 \n\nEpisode: 490\nTrack generation: 1211..1524 -> 313-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0959 - mean_squared_error: 0.4120\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1114 - mean_squared_error: 0.4869\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1061 - mean_squared_error: 0.3880\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0923 - mean_squared_error: 0.2745\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 190\nReplay buffer size: 52927\nTotal frame count: 52927\nEpsilon: 0.05\nTotal reward for episode: 225.2820512820455\nRunning average rewards: 294.6712602708032 \n\nEpisode: 491\nTrack generation: 1101..1380 -> 279-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.1667 - mean_squared_error: 0.8031\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1477 - mean_squared_error: 0.5069\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1863 - mean_squared_error: 0.9636\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 152\nReplay buffer size: 53079\nTotal frame count: 53079\nEpsilon: 0.05\nTotal reward for episode: 223.37266187050076\nRunning average rewards: 293.76232279684416 \n\nEpisode: 492\nTrack generation: 1217..1525 -> 308-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.1499 - mean_squared_error: 0.9013\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1231 - mean_squared_error: 0.5004\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1769 - mean_squared_error: 1.2924\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1708 - mean_squared_error: 0.6884\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 206\nReplay buffer size: 53285\nTotal frame count: 53285\nEpsilon: 0.05\nTotal reward for episode: 298.7074918566731\nRunning average rewards: 296.2019425659093 \n\nEpisode: 493\nTrack generation: 1202..1506 -> 304-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.1241 - mean_squared_error: 0.4444\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1221 - mean_squared_error: 0.5889\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2045 - mean_squared_error: 1.1827\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1126 - mean_squared_error: 0.4964\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1401 - mean_squared_error: 0.5968\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 20\nTotal frames in episode: 238\nReplay buffer size: 53523\nTotal frame count: 53523\nEpsilon: 0.05\nTotal reward for episode: 522.161716171607\nRunning average rewards: 298.8289795228472 \n\nEpisode: 494\nTrack generation: 1397..1750 -> 353-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.1562 - mean_squared_error: 0.5970\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 70\nReplay buffer size: 53593\nTotal frame count: 53593\nEpsilon: 0.05\nTotal reward for episode: 23.136363636363278\nRunning average rewards: 296.9508307917196 \n\nEpisode: 495\nTrack generation: 1162..1464 -> 302-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.1272 - mean_squared_error: 0.4438\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 10ms/step - loss: 0.2284 - mean_squared_error: 1.3301\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1440 - mean_squared_error: 0.6476\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 9ms/step - loss: 0.1552 - mean_squared_error: 0.6156\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1814 - mean_squared_error: 0.9349\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 0\nTotal frames in episode: 238\nReplay buffer size: 53831\nTotal frame count: 53831\nEpsilon: 0.05\nTotal reward for episode: 499.68438538204987\nRunning average rewards: 301.3978307793691 \n\nEpisode: 496\nTrack generation: 1090..1367 -> 277-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.2105 - mean_squared_error: 1.2386\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 11ms/step - loss: 0.0983 - mean_squared_error: 0.3643\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1830 - mean_squared_error: 0.8893\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1748 - mean_squared_error: 0.7639\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1637 - mean_squared_error: 0.8343\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 2\nTotal frames in episode: 238\nReplay buffer size: 54069\nTotal frame count: 54069\nEpsilon: 0.05\nTotal reward for episode: 444.8550724637578\nRunning average rewards: 306.1818701771458 \n\nEpisode: 497\nTrack generation: 1200..1504 -> 304-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.1471 - mean_squared_error: 0.6373\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1614 - mean_squared_error: 0.7821\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 123\nReplay buffer size: 54192\nTotal frame count: 54192\nEpsilon: 0.05\nTotal reward for episode: 277.532673267322\nRunning average rewards: 308.7664194617479 \n\nEpisode: 498\nTrack generation: 1204..1509 -> 305-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.1451 - mean_squared_error: 0.5981\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1622 - mean_squared_error: 0.8034\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 102\nReplay buffer size: 54294\nTotal frame count: 54294\nEpsilon: 0.05\nTotal reward for episode: 24.989473684210452\nRunning average rewards: 307.5936423839181 \n\nEpisode: 499\nTrack generation: 1065..1335 -> 270-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.1377 - mean_squared_error: 0.8525\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 9ms/step - loss: 0.1852 - mean_squared_error: 0.8061\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1788 - mean_squared_error: 0.7957\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 140\nReplay buffer size: 54434\nTotal frame count: 54434\nEpsilon: 0.05\nTotal reward for episode: 293.44237918215106\nRunning average rewards: 306.69042138809493 \n\nEpisode: 500\nTrack generation: 1135..1423 -> 288-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.1596 - mean_squared_error: 0.8898\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1791 - mean_squared_error: 0.7327\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 114\nReplay buffer size: 54548\nTotal frame count: 54548\nEpsilon: 0.05\nTotal reward for episode: 111.19442508711029\nRunning average rewards: 306.883504215745 \n\nEpisode: 501\nTrack generation: 1145..1435 -> 290-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.1969 - mean_squared_error: 1.0643\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0817 - mean_squared_error: 0.3177\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1627 - mean_squared_error: 0.6662\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2404 - mean_squared_error: 1.1528\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 196\nReplay buffer size: 54744\nTotal frame count: 54744\nEpsilon: 0.05\nTotal reward for episode: 357.58615916954074\nRunning average rewards: 309.81818398925856 \n\nEpisode: 502\nTrack generation: 1148..1439 -> 291-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.1540 - mean_squared_error: 0.7714\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1565 - mean_squared_error: 0.5936\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.2164 - mean_squared_error: 0.9886\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 10ms/step - loss: 0.1311 - mean_squared_error: 0.4137\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 10ms/step - loss: 0.1694 - mean_squared_error: 0.7116\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 1\nTotal frames in episode: 238\nReplay buffer size: 54982\nTotal frame count: 54982\nEpsilon: 0.05\nTotal reward for episode: 511.8965517241255\nRunning average rewards: 310.591096874921 \n\nEpisode: 503\nTrack generation: 1131..1418 -> 287-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.1698 - mean_squared_error: 0.7431\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.2070 - mean_squared_error: 1.1725\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 9ms/step - loss: 0.1906 - mean_squared_error: 0.9290\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1456 - mean_squared_error: 0.6112\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 185\nReplay buffer size: 55167\nTotal frame count: 55167\nEpsilon: 0.05\nTotal reward for episode: 296.62937062936487\nRunning average rewards: 309.4565431235876 \n\nEpisode: 504\nTrack generation: 1095..1373 -> 278-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.1447 - mean_squared_error: 0.6010\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1437 - mean_squared_error: 0.6035\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1778 - mean_squared_error: 1.0740\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1636 - mean_squared_error: 0.7025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.3108 - mean_squared_error: 2.2249\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 0\nTotal frames in episode: 238\nReplay buffer size: 55405\nTotal frame count: 55405\nEpsilon: 0.05\nTotal reward for episode: 652.292418772549\nRunning average rewards: 311.99119570637487 \n\nEpisode: 505\nTrack generation: 1260..1579 -> 319-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2488 - mean_squared_error: 1.2578\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1887 - mean_squared_error: 0.9791\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 103\nReplay buffer size: 55508\nTotal frame count: 55508\nEpsilon: 0.05\nTotal reward for episode: 172.63647798742355\nRunning average rewards: 312.3005734732621 \n\nEpisode: 506\nTrack generation: 1229..1540 -> 311-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.1774 - mean_squared_error: 0.8317\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.2082 - mean_squared_error: 1.0367\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1704 - mean_squared_error: 0.7190\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0667 - mean_squared_error: 0.2297\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 2\nTotal frames in episode: 238\nReplay buffer size: 55746\nTotal frame count: 55746\nEpsilon: 0.05\nTotal reward for episode: 556.6129032257992\nRunning average rewards: 316.76600886390156 \n\nEpisode: 507\nTrack generation: 1135..1430 -> 295-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.2243 - mean_squared_error: 1.3019\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1694 - mean_squared_error: 0.8037\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1546 - mean_squared_error: 0.5553\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0900 - mean_squared_error: 0.2912\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 10ms/step - loss: 0.1109 - mean_squared_error: 0.4047\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 1\nTotal frames in episode: 238\nReplay buffer size: 55984\nTotal frame count: 55984\nEpsilon: 0.05\nTotal reward for episode: 653.2993197278812\nRunning average rewards: 319.1217293339077 \n\nEpisode: 508\nTrack generation: 1116..1399 -> 283-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.2949 - mean_squared_error: 1.9469\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1745 - mean_squared_error: 1.1455\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 9ms/step - loss: 0.1594 - mean_squared_error: 0.7894\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0922 - mean_squared_error: 0.3336\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0987 - mean_squared_error: 0.3582\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 50\nTotal frames in episode: 238\nReplay buffer size: 56222\nTotal frame count: 56222\nEpsilon: 0.05\nTotal reward for episode: 429.82269503545115\nRunning average rewards: 321.9255118398178 \n\nEpisode: 509\nTrack generation: 1300..1629 -> 329-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.1410 - mean_squared_error: 0.7388\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2102 - mean_squared_error: 0.9915\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 103\nReplay buffer size: 56325\nTotal frame count: 56325\nEpsilon: 0.05\nTotal reward for episode: 230.14146341463143\nRunning average rewards: 323.52909865939455 \n\nEpisode: 510\nTrack generation: 1207..1513 -> 306-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2403 - mean_squared_error: 1.2758\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1674 - mean_squared_error: 0.9670\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2426 - mean_squared_error: 1.4806\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 170\nReplay buffer size: 56495\nTotal frame count: 56495\nEpsilon: 0.05\nTotal reward for episode: 171.34426229508563\nRunning average rewards: 323.3082717787993 \n\nEpisode: 511\nTrack generation: 1041..1305 -> 264-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.1725 - mean_squared_error: 0.7769\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1806 - mean_squared_error: 1.3621\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1787 - mean_squared_error: 0.6958\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2067 - mean_squared_error: 0.9543\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 198\nReplay buffer size: 56693\nTotal frame count: 56693\nEpsilon: 0.05\nTotal reward for episode: 494.9444866920044\nRunning average rewards: 326.5081391809306 \n\nEpisode: 512\nTrack generation: 1171..1468 -> 297-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.1294 - mean_squared_error: 0.5729\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1612 - mean_squared_error: 0.7596\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1215 - mean_squared_error: 0.4792\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.2111 - mean_squared_error: 1.1219\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 206\nReplay buffer size: 56899\nTotal frame count: 56899\nEpsilon: 0.05\nTotal reward for episode: 326.3837837837783\nRunning average rewards: 329.32169130448267 \n\nEpisode: 513\nTrack generation: 1141..1438 -> 297-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.1223 - mean_squared_error: 0.6033\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 10ms/step - loss: 0.1906 - mean_squared_error: 1.5294\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 94\nReplay buffer size: 56993\nTotal frame count: 56993\nEpsilon: 0.05\nTotal reward for episode: 90.7783783783801\nRunning average rewards: 329.7279098708752 \n\nEpisode: 514\nTrack generation: 1324..1659 -> 335-tiles track\n1/1 [==============================] - 0s 9ms/step - loss: 0.1589 - mean_squared_error: 0.6238\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 9ms/step - loss: 0.1282 - mean_squared_error: 0.4908\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 100\nReplay buffer size: 57093\nTotal frame count: 57093\nEpsilon: 0.05\nTotal reward for episode: 91.73652694610969\nRunning average rewards: 326.95222250875736 \n\nEpisode: 515\nTrack generation: 1220..1529 -> 309-tiles track\n1/1 [==============================] - 0s 9ms/step - loss: 0.1375 - mean_squared_error: 0.5823\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1632 - mean_squared_error: 0.6258\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1684 - mean_squared_error: 0.7418\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1881 - mean_squared_error: 1.0607\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 175\nReplay buffer size: 57268\nTotal frame count: 57268\nEpsilon: 0.05\nTotal reward for episode: 296.8831168831127\nRunning average rewards: 326.40815142194947 \n\nEpisode: 516\nTrack generation: 1173..1470 -> 297-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.1363 - mean_squared_error: 1.1620\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1401 - mean_squared_error: 0.4978\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1453 - mean_squared_error: 0.5036\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0990 - mean_squared_error: 0.3129\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 216\nReplay buffer size: 57484\nTotal frame count: 57484\nEpsilon: 0.05\nTotal reward for episode: 484.5459459459372\nRunning average rewards: 327.52784296332027 \n\nEpisode: 517\nTrack generation: 1141..1434 -> 293-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.1260 - mean_squared_error: 0.4382\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2663 - mean_squared_error: 1.4153\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 81\nReplay buffer size: 57565\nTotal frame count: 57565\nEpsilon: 0.05\nTotal reward for episode: 49.79178082191933\nRunning average rewards: 325.4846365111844 \n\nEpisode: 518\nTrack generation: 1215..1523 -> 308-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.1486 - mean_squared_error: 0.6431\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 81\nReplay buffer size: 57646\nTotal frame count: 57646\nEpsilon: 0.05\nTotal reward for episode: 71.83452768729802\nRunning average rewards: 322.3079642441979 \n\nEpisode: 519\nTrack generation: 984..1233 -> 249-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2139 - mean_squared_error: 1.1312\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1199 - mean_squared_error: 0.5359\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1534 - mean_squared_error: 0.7471\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1621 - mean_squared_error: 1.1878\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1954 - mean_squared_error: 1.0438\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 0\nTotal frames in episode: 238\nReplay buffer size: 57884\nTotal frame count: 57884\nEpsilon: 0.05\nTotal reward for episode: 606.6129032257949\nRunning average rewards: 327.79824142460393 \n\nEpisode: 520\nTrack generation: 1162..1457 -> 295-tiles track\nretry to generate track (normal if there are not manyinstances of this message)\nTrack generation: 1186..1493 -> 307-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.1417 - mean_squared_error: 0.5209\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1427 - mean_squared_error: 0.6431\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 71\nReplay buffer size: 57955\nTotal frame count: 57955\nEpsilon: 0.05\nTotal reward for episode: 72.90718954248506\nRunning average rewards: 325.79588474860026 \n\nEpisode: 521\nTrack generation: 1137..1425 -> 288-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.1719 - mean_squared_error: 1.0684\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1262 - mean_squared_error: 0.7840\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 98\nReplay buffer size: 58053\nTotal frame count: 58053\nEpsilon: 0.05\nTotal reward for episode: 256.9672473867549\nRunning average rewards: 324.9476390068545 \n\nEpisode: 522\nTrack generation: 1155..1448 -> 293-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2411 - mean_squared_error: 1.2376\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1335 - mean_squared_error: 0.5313\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 106\nReplay buffer size: 58159\nTotal frame count: 58159\nEpsilon: 0.05\nTotal reward for episode: 156.23013698630328\nRunning average rewards: 324.4878153767175 \n\nEpisode: 523\nTrack generation: 1127..1422 -> 295-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2461 - mean_squared_error: 1.5396\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 74\nReplay buffer size: 58233\nTotal frame count: 58233\nEpsilon: 0.05\nTotal reward for episode: 96.2503401360557\nRunning average rewards: 325.17904605080525 \n\nEpisode: 524\nTrack generation: 1123..1408 -> 285-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.1580 - mean_squared_error: 0.7889\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1713 - mean_squared_error: 1.1099\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1719 - mean_squared_error: 0.8565\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2290 - mean_squared_error: 1.1341\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 170\nReplay buffer size: 58403\nTotal frame count: 58403\nEpsilon: 0.05\nTotal reward for episode: 343.9718309859081\nRunning average rewards: 326.99876436066427 \n\nEpisode: 525\nTrack generation: 1054..1326 -> 272-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.1516 - mean_squared_error: 0.6439\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 79\nReplay buffer size: 58482\nTotal frame count: 58482\nEpsilon: 0.05\nTotal reward for episode: 104.93136531365472\nRunning average rewards: 325.39522087094383 \n\nEpisode: 526\nTrack generation: 1186..1487 -> 301-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.1331 - mean_squared_error: 0.7200\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1523 - mean_squared_error: 0.5710\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1467 - mean_squared_error: 0.6511\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 164\nReplay buffer size: 58646\nTotal frame count: 58646\nEpsilon: 0.05\nTotal reward for episode: 314.3999999999934\nRunning average rewards: 324.5065219090061 \n\nEpisode: 527\nTrack generation: 1157..1448 -> 291-tiles track\n1/1 [==============================] - 0s 9ms/step - loss: 0.1836 - mean_squared_error: 0.7720\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1591 - mean_squared_error: 0.6040\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0649 - mean_squared_error: 0.1948\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1909 - mean_squared_error: 0.9825\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2546 - mean_squared_error: 1.9283\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 0\nTotal frames in episode: 238\nReplay buffer size: 58884\nTotal frame count: 58884\nEpsilon: 0.05\nTotal reward for episode: 667.0689655172268\nRunning average rewards: 328.4576018080809 \n\nEpisode: 528\nTrack generation: 945..1186 -> 241-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.1910 - mean_squared_error: 1.0497\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1578 - mean_squared_error: 0.7003\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0999 - mean_squared_error: 0.3450\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1445 - mean_squared_error: 0.6257\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1280 - mean_squared_error: 0.6107\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 34\nTotal frames in episode: 238\nReplay buffer size: 59122\nTotal frame count: 59122\nEpsilon: 0.05\nTotal reward for episode: 671.6666666666499\nRunning average rewards: 332.2060140577863 \n\nEpisode: 529\nTrack generation: 1188..1489 -> 301-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.1391 - mean_squared_error: 0.6844\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.2008 - mean_squared_error: 1.3003\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2091 - mean_squared_error: 1.0484\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1706 - mean_squared_error: 0.7061\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1257 - mean_squared_error: 0.4579\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 0\nTotal frames in episode: 238\nReplay buffer size: 59360\nTotal frame count: 59360\nEpsilon: 0.05\nTotal reward for episode: 401.66666666666526\nRunning average rewards: 332.91943397120616 \n\nEpisode: 530\nTrack generation: 1275..1598 -> 323-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.2062 - mean_squared_error: 1.4249\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1773 - mean_squared_error: 1.2094\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 93\nReplay buffer size: 59453\nTotal frame count: 59453\nEpsilon: 0.05\nTotal reward for episode: 167.7689440993805\nRunning average rewards: 330.8823189429263 \n\nEpisode: 531\nTrack generation: 1308..1639 -> 331-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.2608 - mean_squared_error: 2.2527\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1810 - mean_squared_error: 0.9165\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1628 - mean_squared_error: 1.0846\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1391 - mean_squared_error: 0.5137\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 32\nTotal frames in episode: 238\nReplay buffer size: 59691\nTotal frame count: 59691\nEpsilon: 0.05\nTotal reward for episode: 529.242424242408\nRunning average rewards: 332.61493926378176 \n\nEpisode: 532\nTrack generation: 1291..1618 -> 327-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.0769 - mean_squared_error: 0.2250\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1239 - mean_squared_error: 0.5146\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.2327 - mean_squared_error: 1.1850\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 12ms/step - loss: 0.2384 - mean_squared_error: 1.3484\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1431 - mean_squared_error: 0.6300\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 46\nTotal frames in episode: 238\nReplay buffer size: 59929\nTotal frame count: 59929\nEpsilon: 0.05\nTotal reward for episode: 138.12883435583296\nRunning average rewards: 328.1041223441824 \n\nEpisode: 533\nTrack generation: 1092..1369 -> 277-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0727 - mean_squared_error: 0.2298\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.2992 - mean_squared_error: 1.6328\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1289 - mean_squared_error: 0.4644\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 152\nReplay buffer size: 60081\nTotal frame count: 60081\nEpsilon: 0.05\nTotal reward for episode: 326.8811594202814\nRunning average rewards: 330.9042457663422 \n\nEpisode: 534\nTrack generation: 1200..1504 -> 304-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.3152 - mean_squared_error: 4.9940\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2538 - mean_squared_error: 1.3307\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.3219 - mean_squared_error: 2.9966\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1270 - mean_squared_error: 0.5432\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.2469 - mean_squared_error: 2.5493\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 0\nTotal frames in episode: 238\nReplay buffer size: 60319\nTotal frame count: 60319\nEpsilon: 0.05\nTotal reward for episode: 485.85808580857014\nRunning average rewards: 334.3062617829293 \n\nEpisode: 535\nTrack generation: 1252..1569 -> 317-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.1679 - mean_squared_error: 0.7480\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1634 - mean_squared_error: 0.7840\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2217 - mean_squared_error: 1.1123\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 172\nReplay buffer size: 60491\nTotal frame count: 60491\nEpsilon: 0.05\nTotal reward for episode: 323.6050632911339\nRunning average rewards: 334.60873346847234 \n\nEpisode: 536\nTrack generation: 1110..1402 -> 292-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.1173 - mean_squared_error: 0.4358\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.2776 - mean_squared_error: 1.6551\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.2634 - mean_squared_error: 1.4583\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1663 - mean_squared_error: 0.6774\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 9ms/step - loss: 0.1504 - mean_squared_error: 0.7008\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 1\nTotal frames in episode: 238\nReplay buffer size: 60729\nTotal frame count: 60729\nEpsilon: 0.05\nTotal reward for episode: 499.5017182130465\nRunning average rewards: 338.52717650611606 \n\nEpisode: 537\nTrack generation: 1097..1378 -> 281-tiles track\nretry to generate track (normal if there are not manyinstances of this message)\nTrack generation: 1231..1543 -> 312-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.2243 - mean_squared_error: 1.0784\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1475 - mean_squared_error: 0.5924\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 11ms/step - loss: 0.2721 - mean_squared_error: 1.8609\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1339 - mean_squared_error: 0.4966\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 178\nReplay buffer size: 60907\nTotal frame count: 60907\nEpsilon: 0.05\nTotal reward for episode: 282.49774919613697\nRunning average rewards: 337.91090886189073 \n\nEpisode: 538\nTrack generation: 1290..1616 -> 326-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.1638 - mean_squared_error: 0.6394\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2131 - mean_squared_error: 1.0036\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1856 - mean_squared_error: 1.0551\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1004 - mean_squared_error: 0.3040\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 45\nTotal frames in episode: 238\nReplay buffer size: 61145\nTotal frame count: 61145\nEpsilon: 0.05\nTotal reward for episode: 369.61538461537305\nRunning average rewards: 337.8490335109642 \n\nEpisode: 539\nTrack generation: 1210..1515 -> 305-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.1117 - mean_squared_error: 0.4415\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.2221 - mean_squared_error: 1.0212\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1928 - mean_squared_error: 0.9637\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 140\nReplay buffer size: 61285\nTotal frame count: 61285\nEpsilon: 0.05\nTotal reward for episode: 266.368421052627\nRunning average rewards: 338.65121772149047 \n\nEpisode: 540\nTrack generation: 1096..1374 -> 278-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.2163 - mean_squared_error: 1.0125\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1604 - mean_squared_error: 0.7647\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 9ms/step - loss: 0.1828 - mean_squared_error: 0.8259\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.0990 - mean_squared_error: 0.4060\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1322 - mean_squared_error: 0.5664\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 37\nTotal frames in episode: 238\nReplay buffer size: 61523\nTotal frame count: 61523\nEpsilon: 0.05\nTotal reward for episode: 645.0722021660532\nRunning average rewards: 341.17738777182495 \n\nEpisode: 541\nTrack generation: 1111..1399 -> 288-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.1286 - mean_squared_error: 0.5722\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 19\nTotal frames in episode: 42\nReplay buffer size: 61565\nTotal frame count: 61565\nEpsilon: 0.05\nTotal reward for episode: -29.391986062717123\nRunning average rewards: 337.31334407218856 \n\nEpisode: 542\nTrack generation: 1352..1695 -> 343-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2014 - mean_squared_error: 1.0716\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2458 - mean_squared_error: 2.1025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2290 - mean_squared_error: 1.2361\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 146\nReplay buffer size: 61711\nTotal frame count: 61711\nEpsilon: 0.05\nTotal reward for episode: 251.5415204678324\nRunning average rewards: 335.9627057651612 \n\nEpisode: 543\nTrack generation: 1135..1423 -> 288-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.2047 - mean_squared_error: 1.0463\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1381 - mean_squared_error: 0.6509\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 118\nReplay buffer size: 61829\nTotal frame count: 61829\nEpsilon: 0.05\nTotal reward for episode: 140.95331010453197\nRunning average rewards: 337.050654973589 \n\nEpisode: 544\nTrack generation: 1120..1404 -> 284-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.1862 - mean_squared_error: 0.8802\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2258 - mean_squared_error: 1.1262\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1634 - mean_squared_error: 0.7839\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1755 - mean_squared_error: 0.8873\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1086 - mean_squared_error: 0.4198\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 48\nTotal frames in episode: 238\nReplay buffer size: 62067\nTotal frame count: 62067\nEpsilon: 0.05\nTotal reward for episode: 516.307420494688\nRunning average rewards: 338.42852668632423 \n\nEpisode: 545\nTrack generation: 1064..1340 -> 276-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.1691 - mean_squared_error: 0.7541\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1348 - mean_squared_error: 0.7970\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 9ms/step - loss: 0.1360 - mean_squared_error: 0.6237\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1528 - mean_squared_error: 0.8628\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.2242 - mean_squared_error: 1.2231\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 15\nTotal frames in episode: 238\nReplay buffer size: 62305\nTotal frame count: 62305\nEpsilon: 0.05\nTotal reward for episode: 352.27272727271986\nRunning average rewards: 337.2694850059829 \n\nEpisode: 546\nTrack generation: 1119..1403 -> 284-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2270 - mean_squared_error: 1.6389\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2339 - mean_squared_error: 1.0512\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2873 - mean_squared_error: 2.3535\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2703 - mean_squared_error: 3.7613\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 0\nTotal frames in episode: 238\nReplay buffer size: 62543\nTotal frame count: 62543\nEpsilon: 0.05\nTotal reward for episode: 442.10247349821964\nRunning average rewards: 335.36135779750236 \n\nEpisode: 547\nTrack generation: 1232..1544 -> 312-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.1540 - mean_squared_error: 0.6231\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0856 - mean_squared_error: 0.2981\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 78\nReplay buffer size: 62621\nTotal frame count: 62621\nEpsilon: 0.05\nTotal reward for episode: 55.61672025723618\nRunning average rewards: 332.4503470859643 \n\nEpisode: 548\nTrack generation: 1159..1453 -> 294-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2018 - mean_squared_error: 1.1859\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1264 - mean_squared_error: 0.5113\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1785 - mean_squared_error: 0.9582\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1932 - mean_squared_error: 1.1172\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1341 - mean_squared_error: 0.7060\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 12\nTotal frames in episode: 238\nReplay buffer size: 62859\nTotal frame count: 62859\nEpsilon: 0.05\nTotal reward for episode: 270.18771331057496\nRunning average rewards: 332.77104774848186 \n\nEpisode: 549\nTrack generation: 1140..1429 -> 289-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.1543 - mean_squared_error: 0.6993\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2943 - mean_squared_error: 1.8327\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 118\nReplay buffer size: 62977\nTotal frame count: 62977\nEpsilon: 0.05\nTotal reward for episode: 254.88333333332952\nRunning average rewards: 332.5839849779191 \n\nEpisode: 550\nTrack generation: 1170..1475 -> 305-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.1642 - mean_squared_error: 0.6595\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 9ms/step - loss: 0.1636 - mean_squared_error: 0.9961\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1401 - mean_squared_error: 0.5899\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.2506 - mean_squared_error: 1.8897\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1551 - mean_squared_error: 0.5890\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 44\nTotal frames in episode: 238\nReplay buffer size: 63215\nTotal frame count: 63215\nEpsilon: 0.05\nTotal reward for episode: 303.02631578947006\nRunning average rewards: 330.52397967943796 \n\nEpisode: 551\nTrack generation: 1174..1480 -> 306-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.1524 - mean_squared_error: 0.6035\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1807 - mean_squared_error: 0.8538\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1801 - mean_squared_error: 0.9244\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.2372 - mean_squared_error: 1.3357\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1309 - mean_squared_error: 0.4100\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 1\nTotal frames in episode: 238\nReplay buffer size: 63453\nTotal frame count: 63453\nEpsilon: 0.05\nTotal reward for episode: 541.0655737704826\nRunning average rewards: 335.73345894655455 \n\nEpisode: 552\nTrack generation: 1115..1400 -> 285-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.1554 - mean_squared_error: 0.7323\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1829 - mean_squared_error: 0.8710\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1637 - mean_squared_error: 0.9915\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2861 - mean_squared_error: 4.2340\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 209\nReplay buffer size: 63662\nTotal frame count: 63662\nEpsilon: 0.05\nTotal reward for episode: 493.86478873238434\nRunning average rewards: 337.7213879726685 \n\nEpisode: 553\nTrack generation: 1171..1468 -> 297-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.1015 - mean_squared_error: 0.3633\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1693 - mean_squared_error: 0.8183\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1258 - mean_squared_error: 0.4272\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1252 - mean_squared_error: 0.5035\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 190\nReplay buffer size: 63852\nTotal frame count: 63852\nEpsilon: 0.05\nTotal reward for episode: 268.5945945945913\nRunning average rewards: 337.8355429778479 \n\nEpisode: 554\nTrack generation: 1139..1428 -> 289-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.1367 - mean_squared_error: 0.5986\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 10ms/step - loss: 0.0903 - mean_squared_error: 0.2484\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2971 - mean_squared_error: 1.6671\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1124 - mean_squared_error: 0.4878\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 14\nTotal frames in episode: 238\nReplay buffer size: 64090\nTotal frame count: 64090\nEpsilon: 0.05\nTotal reward for episode: 818.1944444444255\nRunning average rewards: 344.72062666279845 \n\nEpisode: 555\nTrack generation: 1274..1598 -> 324-tiles track\nretry to generate track (normal if there are not manyinstances of this message)\nTrack generation: 1135..1423 -> 288-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.0788 - mean_squared_error: 0.2374\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1877 - mean_squared_error: 0.9112\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.2284 - mean_squared_error: 1.0799\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2635 - mean_squared_error: 1.3819\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.2212 - mean_squared_error: 4.4890\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 0\nTotal frames in episode: 238\nReplay buffer size: 64328\nTotal frame count: 64328\nEpsilon: 0.05\nTotal reward for episode: 539.1463414634025\nRunning average rewards: 344.6814930625073 \n\nEpisode: 556\nTrack generation: 1159..1461 -> 302-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.2408 - mean_squared_error: 1.6556\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1437 - mean_squared_error: 0.6086\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2291 - mean_squared_error: 1.1839\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1528 - mean_squared_error: 0.6714\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 9ms/step - loss: 0.1662 - mean_squared_error: 0.7617\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 0\nTotal frames in episode: 238\nReplay buffer size: 64566\nTotal frame count: 64566\nEpsilon: 0.05\nTotal reward for episode: 566.1295681063054\nRunning average rewards: 346.32443431319075 \n\nEpisode: 557\nTrack generation: 1202..1507 -> 305-tiles track\n1/1 [==============================] - 0s 9ms/step - loss: 0.1982 - mean_squared_error: 0.9666\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2964 - mean_squared_error: 1.6469\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.2360 - mean_squared_error: 1.1350\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2266 - mean_squared_error: 1.4041\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2611 - mean_squared_error: 1.6802\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 0\nTotal frames in episode: 238\nReplay buffer size: 64804\nTotal frame count: 64804\nEpsilon: 0.05\nTotal reward for episode: 362.2368421052516\nRunning average rewards: 346.73298020864604 \n\nEpisode: 558\nTrack generation: 1187..1488 -> 301-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2163 - mean_squared_error: 1.2075\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1657 - mean_squared_error: 0.8602\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1757 - mean_squared_error: 0.7891\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1918 - mean_squared_error: 0.8983\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 24\nTotal frames in episode: 238\nReplay buffer size: 65042\nTotal frame count: 65042\nEpsilon: 0.05\nTotal reward for episode: 511.6666666666533\nRunning average rewards: 347.6791649476018 \n\nEpisode: 559\nTrack generation: 1220..1530 -> 310-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.1698 - mean_squared_error: 0.7457\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 9ms/step - loss: 0.2988 - mean_squared_error: 1.7226\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1960 - mean_squared_error: 1.0807\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4087 - mean_squared_error: 4.0051\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.2407 - mean_squared_error: 1.5865\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 43\nTotal frames in episode: 238\nReplay buffer size: 65280\nTotal frame count: 65280\nEpsilon: 0.05\nTotal reward for episode: 458.3980582524126\nRunning average rewards: 347.59036972941425 \n\nEpisode: 560\nTrack generation: 1202..1507 -> 305-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.1884 - mean_squared_error: 1.2950\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 9ms/step - loss: 0.2258 - mean_squared_error: 1.2467\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.2427 - mean_squared_error: 1.4208\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.3212 - mean_squared_error: 1.8739\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1541 - mean_squared_error: 0.5457\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 0\nTotal frames in episode: 238\nReplay buffer size: 65518\nTotal frame count: 65518\nEpsilon: 0.05\nTotal reward for episode: 625.3947368420928\nRunning average rewards: 351.17167476206873 \n\nEpisode: 561\nTrack generation: 1313..1645 -> 332-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.1744 - mean_squared_error: 0.8138\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1548 - mean_squared_error: 0.7714\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2008 - mean_squared_error: 1.1600\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.2169 - mean_squared_error: 1.1311\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1419 - mean_squared_error: 1.0519\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 39\nTotal frames in episode: 238\nReplay buffer size: 65756\nTotal frame count: 65756\nEpsilon: 0.05\nTotal reward for episode: 451.8277945619203\nRunning average rewards: 353.0028415965769 \n\nEpisode: 562\nTrack generation: 1137..1431 -> 294-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.3386 - mean_squared_error: 2.1918\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2739 - mean_squared_error: 1.7753\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1858 - mean_squared_error: 1.2216\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 177\nReplay buffer size: 65933\nTotal frame count: 65933\nEpsilon: 0.05\nTotal reward for episode: 226.12832764504884\nRunning average rewards: 348.36690265080534 \n\nEpisode: 563\nTrack generation: 1091..1367 -> 276-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.4216 - mean_squared_error: 7.2027\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2902 - mean_squared_error: 2.6247\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1923 - mean_squared_error: 0.9194\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 144\nReplay buffer size: 66077\nTotal frame count: 66077\nEpsilon: 0.05\nTotal reward for episode: 313.3090909090828\nRunning average rewards: 348.3560472511714 \n\nEpisode: 564\nTrack generation: 1074..1346 -> 272-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.1743 - mean_squared_error: 0.8502\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.3234 - mean_squared_error: 2.3944\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1624 - mean_squared_error: 0.6467\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 37\nTotal frames in episode: 136\nReplay buffer size: 66213\nTotal frame count: 66213\nEpsilon: 0.05\nTotal reward for episode: 373.475276752762\nRunning average rewards: 350.1743486568313 \n\nEpisode: 565\nTrack generation: 1080..1354 -> 274-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.1607 - mean_squared_error: 0.8813\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 11ms/step - loss: 0.1419 - mean_squared_error: 0.6231\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 108\nReplay buffer size: 66321\nTotal frame count: 66321\nEpsilon: 0.05\nTotal reward for episode: 213.21025641025642\nRunning average rewards: 349.6787289987117 \n\nEpisode: 566\nTrack generation: 1043..1316 -> 273-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.1943 - mean_squared_error: 0.9873\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 77\nReplay buffer size: 66398\nTotal frame count: 66398\nEpsilon: 0.05\nTotal reward for episode: 108.90588235294271\nRunning average rewards: 349.88996429282923 \n\nEpisode: 567\nTrack generation: 1252..1569 -> 317-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2990 - mean_squared_error: 1.7148\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1805 - mean_squared_error: 0.7366\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 9ms/step - loss: 0.2319 - mean_squared_error: 1.1834\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2075 - mean_squared_error: 1.1111\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 171\nReplay buffer size: 66569\nTotal frame count: 66569\nEpsilon: 0.05\nTotal reward for episode: 178.43544303797842\nRunning average rewards: 347.1903564590582 \n\nEpisode: 568\nTrack generation: 1242..1556 -> 314-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2263 - mean_squared_error: 1.2822\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.2569 - mean_squared_error: 1.5641\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1603 - mean_squared_error: 0.6576\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2800 - mean_squared_error: 1.9839\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 210\nReplay buffer size: 66779\nTotal frame count: 66779\nEpsilon: 0.05\nTotal reward for episode: 417.5974440894464\nRunning average rewards: 347.6496642332861 \n\nEpisode: 569\nTrack generation: 1020..1279 -> 259-tiles track\n1/1 [==============================] - 0s 10ms/step - loss: 0.1516 - mean_squared_error: 0.6370\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.3631 - mean_squared_error: 2.7569\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2625 - mean_squared_error: 1.3561\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.2396 - mean_squared_error: 1.8290\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.2016 - mean_squared_error: 1.3307\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 6\nTotal frames in episode: 238\nReplay buffer size: 67017\nTotal frame count: 67017\nEpsilon: 0.05\nTotal reward for episode: 831.3565891472789\nRunning average rewards: 354.69863753216623 \n\nEpisode: 570\nTrack generation: 1240..1555 -> 315-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.2439 - mean_squared_error: 1.5393\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1198 - mean_squared_error: 0.5276\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1506 - mean_squared_error: 0.8086\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 164\nReplay buffer size: 67181\nTotal frame count: 67181\nEpsilon: 0.05\nTotal reward for episode: 307.011464968146\nRunning average rewards: 357.1507119133914 \n\nEpisode: 571\nTrack generation: 1210..1519 -> 309-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2415 - mean_squared_error: 1.1440\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2159 - mean_squared_error: 1.0904\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1497 - mean_squared_error: 0.5816\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3214 - mean_squared_error: 1.9222\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1793 - mean_squared_error: 0.8214\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 0\nTotal frames in episode: 238\nReplay buffer size: 67419\nTotal frame count: 67419\nEpsilon: 0.05\nTotal reward for episode: 430.97402597402186\nRunning average rewards: 355.76593390070644 \n\nEpisode: 572\nTrack generation: 1123..1408 -> 285-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.1875 - mean_squared_error: 0.9916\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1929 - mean_squared_error: 0.9025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.2125 - mean_squared_error: 1.2637\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1513 - mean_squared_error: 0.6503\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1311 - mean_squared_error: 0.6466\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 33\nTotal frames in episode: 238\nReplay buffer size: 67657\nTotal frame count: 67657\nEpsilon: 0.05\nTotal reward for episode: 373.3098591549281\nRunning average rewards: 353.9167744277397 \n\nEpisode: 573\nTrack generation: 1036..1305 -> 269-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.1394 - mean_squared_error: 0.6407\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.2048 - mean_squared_error: 0.9740\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1893 - mean_squared_error: 0.9733\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2692 - mean_squared_error: 1.5808\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 1\nTotal frames in episode: 238\nReplay buffer size: 67895\nTotal frame count: 67895\nEpsilon: 0.05\nTotal reward for episode: 513.2089552238702\nRunning average rewards: 352.8842394740497 \n\nEpisode: 574\nTrack generation: 1075..1348 -> 273-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.2054 - mean_squared_error: 1.3922\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1570 - mean_squared_error: 0.6716\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.2021 - mean_squared_error: 1.3817\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 143\nReplay buffer size: 68038\nTotal frame count: 68038\nEpsilon: 0.05\nTotal reward for episode: 281.03529411764276\nRunning average rewards: 349.5976125494544 \n\nEpisode: 575\nTrack generation: 1069..1345 -> 276-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.1524 - mean_squared_error: 0.6150\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1774 - mean_squared_error: 0.9337\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 69\nReplay buffer size: 68107\nTotal frame count: 68107\nEpsilon: 0.05\nTotal reward for episode: 66.94545454545592\nRunning average rewards: 347.80058433628847 \n\nEpisode: 576\nTrack generation: 1103..1390 -> 287-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.1255 - mean_squared_error: 0.5035\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 78\nReplay buffer size: 68185\nTotal frame count: 68185\nEpsilon: 0.05\nTotal reward for episode: 98.17062937063082\nRunning average rewards: 341.3802307049012 \n\nEpisode: 577\nTrack generation: 1071..1343 -> 272-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.1771 - mean_squared_error: 0.8338\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1561 - mean_squared_error: 0.5798\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 69\nReplay buffer size: 68254\nTotal frame count: 68254\nEpsilon: 0.05\nTotal reward for episode: 57.27084870848847\nRunning average rewards: 338.1529391919862 \n\nEpisode: 578\nTrack generation: 1046..1320 -> 274-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2054 - mean_squared_error: 1.2599\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0975 - mean_squared_error: 0.5127\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 9ms/step - loss: 0.1829 - mean_squared_error: 0.8019\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 152\nReplay buffer size: 68406\nTotal frame count: 68406\nEpsilon: 0.05\nTotal reward for episode: 360.44542124541556\nRunning average rewards: 341.0002546144047 \n\nEpisode: 579\nTrack generation: 1239..1553 -> 314-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2042 - mean_squared_error: 1.1354\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2272 - mean_squared_error: 1.1318\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2297 - mean_squared_error: 1.7283\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2995 - mean_squared_error: 1.9171\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 14\nTotal frames in episode: 238\nReplay buffer size: 68644\nTotal frame count: 68644\nEpsilon: 0.05\nTotal reward for episode: 345.89456869009484\nRunning average rewards: 342.4837928938982 \n\nEpisode: 580\nTrack generation: 1197..1500 -> 303-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.1367 - mean_squared_error: 0.5223\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2660 - mean_squared_error: 1.2960\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2489 - mean_squared_error: 1.4071\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 146\nReplay buffer size: 68790\nTotal frame count: 68790\nEpsilon: 0.05\nTotal reward for episode: 319.08344370860175\nRunning average rewards: 340.7575753078629 \n\nEpisode: 581\nTrack generation: 1355..1698 -> 343-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.1711 - mean_squared_error: 0.6879\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1621 - mean_squared_error: 0.6970\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2188 - mean_squared_error: 1.3737\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2300 - mean_squared_error: 1.2064\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 196\nReplay buffer size: 68986\nTotal frame count: 68986\nEpsilon: 0.05\nTotal reward for episode: 272.47719298245033\nRunning average rewards: 338.8874754428158 \n\nEpisode: 582\nTrack generation: 1348..1689 -> 341-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.3314 - mean_squared_error: 3.6645\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.2021 - mean_squared_error: 0.9083\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2082 - mean_squared_error: 1.3782\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1413 - mean_squared_error: 0.6662\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 189\nReplay buffer size: 69175\nTotal frame count: 69175\nEpsilon: 0.05\nTotal reward for episode: 353.8117647058736\nRunning average rewards: 336.36170420098586 \n\nEpisode: 583\nTrack generation: 1111..1392 -> 281-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2092 - mean_squared_error: 1.1137\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0935 - mean_squared_error: 0.4415\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1776 - mean_squared_error: 1.0115\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2127 - mean_squared_error: 0.9252\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.2772 - mean_squared_error: 1.3591\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 1\nTotal frames in episode: 238\nReplay buffer size: 69413\nTotal frame count: 69413\nEpsilon: 0.05\nTotal reward for episode: 769.2857142856997\nRunning average rewards: 341.92583845227654 \n\nEpisode: 584\nTrack generation: 1113..1405 -> 292-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2264 - mean_squared_error: 1.1513\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.2049 - mean_squared_error: 1.1509\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.2046 - mean_squared_error: 1.0882\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1433 - mean_squared_error: 0.5067\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2496 - mean_squared_error: 1.8314\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 1\nTotal frames in episode: 238\nReplay buffer size: 69651\nTotal frame count: 69651\nEpsilon: 0.05\nTotal reward for episode: 740.0515463917345\nRunning average rewards: 344.9096872495273 \n\nEpisode: 585\nTrack generation: 1295..1623 -> 328-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.1971 - mean_squared_error: 0.8984\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0945 - mean_squared_error: 0.3316\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1732 - mean_squared_error: 0.6990\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.0955 - mean_squared_error: 0.3023\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 213\nReplay buffer size: 69864\nTotal frame count: 69864\nEpsilon: 0.05\nTotal reward for episode: 196.14556574924057\nRunning average rewards: 342.9238826330472 \n\nEpisode: 586\nTrack generation: 1188..1489 -> 301-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.1673 - mean_squared_error: 0.6767\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1158 - mean_squared_error: 0.3450\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2036 - mean_squared_error: 0.9755\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 144\nReplay buffer size: 70008\nTotal frame count: 70008\nEpsilon: 0.05\nTotal reward for episode: 262.3999999999916\nRunning average rewards: 340.28576142092606 \n\nEpisode: 587\nTrack generation: 1196..1502 -> 306-tiles track\nretry to generate track (normal if there are not manyinstances of this message)\nTrack generation: 1140..1435 -> 295-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2073 - mean_squared_error: 1.1265\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4157 - mean_squared_error: 5.0209\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2098 - mean_squared_error: 1.1765\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 178\nReplay buffer size: 70186\nTotal frame count: 70186\nEpsilon: 0.05\nTotal reward for episode: 265.534693877548\nRunning average rewards: 341.89940187505977 \n\nEpisode: 588\nTrack generation: 1076..1349 -> 273-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.3100 - mean_squared_error: 1.8943\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3424 - mean_squared_error: 2.2124\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 83\nReplay buffer size: 70269\nTotal frame count: 70269\nEpsilon: 0.05\nTotal reward for episode: 139.59411764706059\nRunning average rewards: 339.49307315533673 \n\nEpisode: 589\nTrack generation: 1183..1483 -> 300-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.1469 - mean_squared_error: 0.6067\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 74\nReplay buffer size: 70343\nTotal frame count: 70343\nEpsilon: 0.05\nTotal reward for episode: 87.45685618729253\nRunning average rewards: 337.07276847777314 \n\nEpisode: 590\nTrack generation: 1082..1356 -> 274-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.1729 - mean_squared_error: 0.6254\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.2530 - mean_squared_error: 1.7915\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1873 - mean_squared_error: 1.1102\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 150\nReplay buffer size: 70493\nTotal frame count: 70493\nEpsilon: 0.05\nTotal reward for episode: 244.02930402929724\nRunning average rewards: 337.26024100524563 \n\nEpisode: 591\nTrack generation: 1039..1310 -> 271-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.1943 - mean_squared_error: 0.7156\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2412 - mean_squared_error: 1.4229\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1641 - mean_squared_error: 0.8480\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2387 - mean_squared_error: 1.6441\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 172\nReplay buffer size: 70665\nTotal frame count: 70665\nEpsilon: 0.05\nTotal reward for episode: 338.60740740740175\nRunning average rewards: 338.4125884606146 \n\nEpisode: 592\nTrack generation: 1184..1484 -> 300-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.3679 - mean_squared_error: 7.5638\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1815 - mean_squared_error: 0.9484\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1586 - mean_squared_error: 0.9035\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.3101 - mean_squared_error: 2.0916\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2770 - mean_squared_error: 1.6558\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 1\nTotal frames in episode: 238\nReplay buffer size: 70903\nTotal frame count: 70903\nEpsilon: 0.05\nTotal reward for episode: 670.8862876254005\nRunning average rewards: 342.1343764183019 \n\nEpisode: 593\nTrack generation: 1177..1475 -> 298-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.2710 - mean_squared_error: 1.6163\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1198 - mean_squared_error: 0.4835\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2397 - mean_squared_error: 1.5048\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 191\nReplay buffer size: 71094\nTotal frame count: 71094\nEpsilon: 0.05\nTotal reward for episode: 381.5124579124473\nRunning average rewards: 340.72788383571026 \n\nEpisode: 594\nTrack generation: 1127..1413 -> 286-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.2498 - mean_squared_error: 1.5476\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1600 - mean_squared_error: 0.7811\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1645 - mean_squared_error: 0.7780\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1396 - mean_squared_error: 0.6103\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1859 - mean_squared_error: 1.0485\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 0\nTotal frames in episode: 238\nReplay buffer size: 71332\nTotal frame count: 71332\nEpsilon: 0.05\nTotal reward for episode: 722.5438596491034\nRunning average rewards: 347.7219587958376 \n\nEpisode: 595\nTrack generation: 1117..1407 -> 290-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2667 - mean_squared_error: 1.4364\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1860 - mean_squared_error: 0.9075\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2759 - mean_squared_error: 1.6246\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1517 - mean_squared_error: 0.6733\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2360 - mean_squared_error: 1.8594\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 2\nTotal frames in episode: 238\nReplay buffer size: 71570\nTotal frame count: 71570\nEpsilon: 0.05\nTotal reward for episode: 375.5882352941117\nRunning average rewards: 346.4809972949583 \n\nEpisode: 596\nTrack generation: 1399..1753 -> 354-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.1570 - mean_squared_error: 0.9319\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1154 - mean_squared_error: 0.4281\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.2288 - mean_squared_error: 1.2440\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1937 - mean_squared_error: 1.1367\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 208\nReplay buffer size: 71778\nTotal frame count: 71778\nEpsilon: 0.05\nTotal reward for episode: 327.5648725212362\nRunning average rewards: 345.3080952955331 \n\nEpisode: 597\nTrack generation: 1007..1263 -> 256-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.1682 - mean_squared_error: 0.7992\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1485 - mean_squared_error: 0.6432\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.3125 - mean_squared_error: 2.0469\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 137\nReplay buffer size: 71915\nTotal frame count: 71915\nEpsilon: 0.05\nTotal reward for episode: 247.16078431371778\nRunning average rewards: 345.00437640599705 \n\nEpisode: 598\nTrack generation: 1060..1329 -> 269-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.1160 - mean_squared_error: 0.4095\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.2817 - mean_squared_error: 1.7431\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1689 - mean_squared_error: 0.6540\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 157\nReplay buffer size: 72072\nTotal frame count: 72072\nEpsilon: 0.05\nTotal reward for episode: 355.1104477611834\nRunning average rewards: 348.3055861467668 \n\nEpisode: 599\nTrack generation: 996..1249 -> 253-tiles track\n1/1 [==============================] - 0s 9ms/step - loss: 0.1813 - mean_squared_error: 0.9771\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1586 - mean_squared_error: 0.6943\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 119\nReplay buffer size: 72191\nTotal frame count: 72191\nEpsilon: 0.05\nTotal reward for episode: 301.60634920634493\nRunning average rewards: 348.3872258470087 \n\nEpisode: 600\nTrack generation: 1262..1582 -> 320-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.1978 - mean_squared_error: 1.0860\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2307 - mean_squared_error: 2.5826\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2158 - mean_squared_error: 1.0650\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2455 - mean_squared_error: 1.8454\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 163\nReplay buffer size: 72354\nTotal frame count: 72354\nEpsilon: 0.05\nTotal reward for episode: 276.4927899686458\nRunning average rewards: 350.0402094958241 \n\nEpisode: 601\nTrack generation: 1140..1429 -> 289-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.2896 - mean_squared_error: 1.6330\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2460 - mean_squared_error: 3.3821\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2000 - mean_squared_error: 1.0379\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 192\nReplay buffer size: 72546\nTotal frame count: 72546\nEpsilon: 0.05\nTotal reward for episode: 506.53333333332375\nRunning average rewards: 351.52968123746194 \n\nEpisode: 602\nTrack generation: 1179..1478 -> 299-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2118 - mean_squared_error: 1.3095\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1828 - mean_squared_error: 0.7742\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.2587 - mean_squared_error: 1.5756\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 113\nReplay buffer size: 72659\nTotal frame count: 72659\nEpsilon: 0.05\nTotal reward for episode: 179.6322147651027\nRunning average rewards: 348.2070378678717 \n\nEpisode: 603\nTrack generation: 1064..1334 -> 270-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.2736 - mean_squared_error: 1.9099\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.2090 - mean_squared_error: 1.0971\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1913 - mean_squared_error: 0.8324\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2957 - mean_squared_error: 1.8335\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 51\nTotal frames in episode: 238\nReplay buffer size: 72897\nTotal frame count: 72897\nEpsilon: 0.05\nTotal reward for episode: 592.732342007422\nRunning average rewards: 351.1680675816523 \n\nEpisode: 604\nTrack generation: 1073..1355 -> 282-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.1786 - mean_squared_error: 0.9637\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1400 - mean_squared_error: 0.6387\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 18\nTotal frames in episode: 59\nReplay buffer size: 72956\nTotal frame count: 72956\nEpsilon: 0.05\nTotal reward for episode: 29.824911032029405\nRunning average rewards: 344.9433925042471 \n\nEpisode: 605\nTrack generation: 1016..1274 -> 258-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.1671 - mean_squared_error: 0.6923\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2539 - mean_squared_error: 1.3840\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 107\nReplay buffer size: 73063\nTotal frame count: 73063\nEpsilon: 0.05\nTotal reward for episode: 315.17665369649274\nRunning average rewards: 346.36879426133777 \n\nEpisode: 606\nTrack generation: 1036..1301 -> 265-tiles track\nretry to generate track (normal if there are not manyinstances of this message)\nTrack generation: 1051..1318 -> 267-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.1479 - mean_squared_error: 0.5586\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2111 - mean_squared_error: 1.1572\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 128\nReplay buffer size: 73191\nTotal frame count: 73191\nEpsilon: 0.05\nTotal reward for episode: 305.9428571428516\nRunning average rewards: 343.8620938005083 \n\nEpisode: 607\nTrack generation: 1259..1585 -> 326-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.1663 - mean_squared_error: 0.8299\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1894 - mean_squared_error: 0.9021\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 82\nReplay buffer size: 73273\nTotal frame count: 73273\nEpsilon: 0.05\nTotal reward for episode: 77.9692307692322\nRunning average rewards: 338.10879291092175 \n\nEpisode: 608\nTrack generation: 1207..1513 -> 306-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.3078 - mean_squared_error: 1.5894\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 9ms/step - loss: 0.2906 - mean_squared_error: 2.7802\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 97\nReplay buffer size: 73370\nTotal frame count: 73370\nEpsilon: 0.05\nTotal reward for episode: 36.609836065575514\nRunning average rewards: 334.176664321223 \n\nEpisode: 609\nTrack generation: 1093..1370 -> 277-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2356 - mean_squared_error: 1.1740\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1337 - mean_squared_error: 0.4748\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 94\nReplay buffer size: 73464\nTotal frame count: 73464\nEpsilon: 0.05\nTotal reward for episode: 139.93623188405957\nRunning average rewards: 333.2746120059173 \n\nEpisode: 610\nTrack generation: 1276..1607 -> 331-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.1530 - mean_squared_error: 0.6013\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 79\nReplay buffer size: 73543\nTotal frame count: 73543\nEpsilon: 0.05\nTotal reward for episode: 80.52121212121358\nRunning average rewards: 332.36638150417855 \n\nEpisode: 611\nTrack generation: 1041..1312 -> 271-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.1458 - mean_squared_error: 0.6003\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 25\nTotal frames in episode: 55\nReplay buffer size: 73598\nTotal frame count: 73598\nEpsilon: 0.05\nTotal reward for episode: -3.1814814814806027\nRunning average rewards: 327.38512182244375 \n\nEpisode: 612\nTrack generation: 1141..1430 -> 289-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.1533 - mean_squared_error: 0.5495\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1304 - mean_squared_error: 0.4806\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1957 - mean_squared_error: 0.8608\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1786 - mean_squared_error: 0.7390\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 152\nReplay buffer size: 73750\nTotal frame count: 73750\nEpsilon: 0.05\nTotal reward for episode: 359.33888888888305\nRunning average rewards: 327.7146728734948 \n\nEpisode: 613\nTrack generation: 1044..1309 -> 265-tiles track\n1/1 [==============================] - 0s 10ms/step - loss: 0.1815 - mean_squared_error: 0.9131\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 9ms/step - loss: 0.1165 - mean_squared_error: 0.4194\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2625 - mean_squared_error: 1.6746\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 176\nReplay buffer size: 73926\nTotal frame count: 73926\nEpsilon: 0.05\nTotal reward for episode: 327.32727272726197\nRunning average rewards: 330.08016181698366 \n\nEpisode: 614\nTrack generation: 1142..1432 -> 290-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.1179 - mean_squared_error: 0.5086\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.2324 - mean_squared_error: 1.1593\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1422 - mean_squared_error: 0.7313\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1920 - mean_squared_error: 0.8832\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1887 - mean_squared_error: 1.1059\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 16\nTotal frames in episode: 238\nReplay buffer size: 74164\nTotal frame count: 74164\nEpsilon: 0.05\nTotal reward for episode: 586.6608996539671\nRunning average rewards: 335.0294055440622 \n\nEpisode: 615\nTrack generation: 1247..1563 -> 316-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.2301 - mean_squared_error: 1.1346\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1644 - mean_squared_error: 0.5986\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 108\nReplay buffer size: 74272\nTotal frame count: 74272\nEpsilon: 0.05\nTotal reward for episode: 248.86349206348734\nRunning average rewards: 334.5492092958659 \n\nEpisode: 616\nTrack generation: 1211..1518 -> 307-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.3300 - mean_squared_error: 2.4538\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.2161 - mean_squared_error: 1.2318\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.3113 - mean_squared_error: 2.1388\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 131\nReplay buffer size: 74403\nTotal frame count: 74403\nEpsilon: 0.05\nTotal reward for episode: 248.25359477123789\nRunning average rewards: 332.186285784119 \n\nEpisode: 617\nTrack generation: 1147..1438 -> 291-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.1814 - mean_squared_error: 0.9287\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1411 - mean_squared_error: 0.6074\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 137\nReplay buffer size: 74540\nTotal frame count: 74540\nEpsilon: 0.05\nTotal reward for episode: 310.7172413793047\nRunning average rewards: 334.79554038969275 \n\nEpisode: 618\nTrack generation: 1123..1408 -> 285-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.2272 - mean_squared_error: 1.0477\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1747 - mean_squared_error: 0.8006\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 90\nReplay buffer size: 74630\nTotal frame count: 74630\nEpsilon: 0.05\nTotal reward for episode: 199.91549295774863\nRunning average rewards: 336.07635004239734 \n\nEpisode: 619\nTrack generation: 1173..1470 -> 297-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.1933 - mean_squared_error: 0.7750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2529 - mean_squared_error: 1.8483\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2709 - mean_squared_error: 2.0309\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 9ms/step - loss: 0.2118 - mean_squared_error: 1.2845\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1297 - mean_squared_error: 0.4684\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 15\nTotal frames in episode: 238\nReplay buffer size: 74868\nTotal frame count: 74868\nEpsilon: 0.05\nTotal reward for episode: 445.54054054052625\nRunning average rewards: 334.4656264155446 \n\nEpisode: 620\nTrack generation: 1128..1414 -> 286-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.3480 - mean_squared_error: 5.5585\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.2711 - mean_squared_error: 1.4445\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1948 - mean_squared_error: 0.8766\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 146\nReplay buffer size: 75014\nTotal frame count: 75014\nEpsilon: 0.05\nTotal reward for episode: 306.51228070174534\nRunning average rewards: 336.8016773271372 \n\nEpisode: 621\nTrack generation: 1140..1429 -> 289-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.1519 - mean_squared_error: 0.7862\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2753 - mean_squared_error: 1.5145\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2808 - mean_squared_error: 1.7983\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 158\nReplay buffer size: 75172\nTotal frame count: 75172\nEpsilon: 0.05\nTotal reward for episode: 329.1611111111047\nRunning average rewards: 337.5236159643807 \n\nEpisode: 622\nTrack generation: 1217..1525 -> 308-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.2326 - mean_squared_error: 1.1436\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.2314 - mean_squared_error: 1.4572\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2858 - mean_squared_error: 2.1609\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1905 - mean_squared_error: 1.1685\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.2380 - mean_squared_error: 1.4437\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 1\nTotal frames in episode: 238\nReplay buffer size: 75410\nTotal frame count: 75410\nEpsilon: 0.05\nTotal reward for episode: 598.81107491855\nRunning average rewards: 341.94942534370324 \n\nEpisode: 623\nTrack generation: 1320..1655 -> 335-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.3416 - mean_squared_error: 2.1352\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.2590 - mean_squared_error: 1.5268\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1559 - mean_squared_error: 0.8971\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3313 - mean_squared_error: 2.3137\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 2\nTotal frames in episode: 238\nReplay buffer size: 75648\nTotal frame count: 75648\nEpsilon: 0.05\nTotal reward for episode: 677.4550898203407\nRunning average rewards: 347.76147284054605 \n\nEpisode: 624\nTrack generation: 1128..1414 -> 286-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.3899 - mean_squared_error: 3.3830\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 9ms/step - loss: 0.1462 - mean_squared_error: 0.6181\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2227 - mean_squared_error: 1.3120\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 128\nReplay buffer size: 75776\nTotal frame count: 75776\nEpsilon: 0.05\nTotal reward for episode: 257.57192982455615\nRunning average rewards: 346.8974738289325 \n\nEpisode: 625\nTrack generation: 1344..1684 -> 340-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2121 - mean_squared_error: 1.1839\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2016 - mean_squared_error: 1.1739\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2045 - mean_squared_error: 0.9736\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2950 - mean_squared_error: 1.4121\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2495 - mean_squared_error: 1.6541\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 236\nReplay buffer size: 76012\nTotal frame count: 76012\nEpsilon: 0.05\nTotal reward for episode: 330.3787610619395\nRunning average rewards: 349.15194778641535 \n\nEpisode: 626\nTrack generation: 1078..1359 -> 281-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2063 - mean_squared_error: 1.7475\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 81\nReplay buffer size: 76093\nTotal frame count: 76093\nEpsilon: 0.05\nTotal reward for episode: 106.88571428571592\nRunning average rewards: 347.07680492927256 \n\nEpisode: 627\nTrack generation: 1064..1343 -> 279-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.1659 - mean_squared_error: 0.7872\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1985 - mean_squared_error: 1.1610\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2868 - mean_squared_error: 4.0258\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2417 - mean_squared_error: 1.5240\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2133 - mean_squared_error: 1.2534\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 0\nTotal frames in episode: 238\nReplay buffer size: 76331\nTotal frame count: 76331\nEpsilon: 0.05\nTotal reward for episode: 775.5035971222873\nRunning average rewards: 348.1611512453232 \n\nEpisode: 628\nTrack generation: 1195..1506 -> 311-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.1234 - mean_squared_error: 0.5169\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2219 - mean_squared_error: 1.0650\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 75\nReplay buffer size: 76406\nTotal frame count: 76406\nEpsilon: 0.05\nTotal reward for episode: 89.35483870967872\nRunning average rewards: 342.33803296575354 \n\nEpisode: 629\nTrack generation: 1230..1549 -> 319-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2937 - mean_squared_error: 1.4339\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 80\nReplay buffer size: 76486\nTotal frame count: 76486\nEpsilon: 0.05\nTotal reward for episode: 96.93081761006447\nRunning average rewards: 339.29067447518753 \n\nEpisode: 630\nTrack generation: 1201..1505 -> 304-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.1646 - mean_squared_error: 0.6954\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.2055 - mean_squared_error: 0.9050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1570 - mean_squared_error: 0.8078\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2357 - mean_squared_error: 1.4285\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1719 - mean_squared_error: 0.8667\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 43\nTotal frames in episode: 238\nReplay buffer size: 76724\nTotal frame count: 76724\nEpsilon: 0.05\nTotal reward for episode: 574.9669966996573\nRunning average rewards: 343.36265500119026 \n\nEpisode: 631\nTrack generation: 1156..1449 -> 293-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.1794 - mean_squared_error: 0.8971\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2183 - mean_squared_error: 1.2161\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 113\nReplay buffer size: 76837\nTotal frame count: 76837\nEpsilon: 0.05\nTotal reward for episode: 276.7178082191732\nRunning average rewards: 340.83740884095795 \n\nEpisode: 632\nTrack generation: 1120..1404 -> 284-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.1436 - mean_squared_error: 0.4875\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1953 - mean_squared_error: 1.0131\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2154 - mean_squared_error: 1.1352\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 152\nReplay buffer size: 76989\nTotal frame count: 76989\nEpsilon: 0.05\nTotal reward for episode: 366.7618374558249\nRunning average rewards: 343.1237388719578 \n\nEpisode: 633\nTrack generation: 1104..1386 -> 282-tiles track\nretry to generate track (normal if there are not manyinstances of this message)\nTrack generation: 1284..1609 -> 325-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2300 - mean_squared_error: 1.3186\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2277 - mean_squared_error: 1.1424\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2952 - mean_squared_error: 1.5345\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2496 - mean_squared_error: 1.4678\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1841 - mean_squared_error: 0.7145\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 39\nTotal frames in episode: 238\nReplay buffer size: 77227\nTotal frame count: 77227\nEpsilon: 0.05\nTotal reward for episode: 605.6172839506037\nRunning average rewards: 345.911100117261 \n\nEpisode: 634\nTrack generation: 1286..1611 -> 325-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2391 - mean_squared_error: 1.3135\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2428 - mean_squared_error: 1.1675\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1617 - mean_squared_error: 0.7306\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1423 - mean_squared_error: 0.7203\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1407 - mean_squared_error: 0.4928\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 223\nReplay buffer size: 77450\nTotal frame count: 77450\nEpsilon: 0.05\nTotal reward for episode: 333.6395061728303\nRunning average rewards: 344.38891432090367 \n\nEpisode: 635\nTrack generation: 1139..1428 -> 289-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.3948 - mean_squared_error: 2.4043\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 92\nReplay buffer size: 77542\nTotal frame count: 77542\nEpsilon: 0.05\nTotal reward for episode: 161.11666666666875\nRunning average rewards: 342.764030354659 \n\nEpisode: 636\nTrack generation: 1220..1529 -> 309-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2194 - mean_squared_error: 1.1548\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1782 - mean_squared_error: 0.9615\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1467 - mean_squared_error: 0.6162\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2205 - mean_squared_error: 1.2320\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 204\nReplay buffer size: 77746\nTotal frame count: 77746\nEpsilon: 0.05\nTotal reward for episode: 366.45194805193825\nRunning average rewards: 341.4335326530479 \n\nEpisode: 637\nTrack generation: 1215..1523 -> 308-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2463 - mean_squared_error: 1.0603\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2113 - mean_squared_error: 1.0125\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2158 - mean_squared_error: 1.2217\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 118\nReplay buffer size: 77864\nTotal frame count: 77864\nEpsilon: 0.05\nTotal reward for episode: 158.01172638436748\nRunning average rewards: 340.1886724249302 \n\nEpisode: 638\nTrack generation: 1110..1396 -> 286-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2214 - mean_squared_error: 1.3055\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 71\nReplay buffer size: 77935\nTotal frame count: 77935\nEpsilon: 0.05\nTotal reward for episode: 87.38947368421188\nRunning average rewards: 337.36641331561856 \n\nEpisode: 639\nTrack generation: 1071..1352 -> 281-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.1932 - mean_squared_error: 0.9254\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2019 - mean_squared_error: 0.9322\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 106\nReplay buffer size: 78041\nTotal frame count: 78041\nEpsilon: 0.05\nTotal reward for episode: 93.3142857142879\nRunning average rewards: 335.63587196223517 \n\nEpisode: 640\nTrack generation: 1128..1414 -> 286-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2416 - mean_squared_error: 1.1991\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1968 - mean_squared_error: 0.9083\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2475 - mean_squared_error: 1.8623\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1942 - mean_squared_error: 1.0549\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1911 - mean_squared_error: 0.9829\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 2\nTotal frames in episode: 238\nReplay buffer size: 78279\nTotal frame count: 78279\nEpsilon: 0.05\nTotal reward for episode: 782.1929824561201\nRunning average rewards: 337.00707976513587 \n\nEpisode: 641\nTrack generation: 1072..1344 -> 272-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.3905 - mean_squared_error: 6.0760\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2488 - mean_squared_error: 1.1350\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2378 - mean_squared_error: 1.1085\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1709 - mean_squared_error: 0.6854\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.2003 - mean_squared_error: 1.3851\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 5\nTotal frames in episode: 238\nReplay buffer size: 78517\nTotal frame count: 78517\nEpsilon: 0.05\nTotal reward for episode: 827.5092250922368\nRunning average rewards: 345.57609187668544 \n\nEpisode: 642\nTrack generation: 1208..1514 -> 306-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.2190 - mean_squared_error: 1.0974\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.2139 - mean_squared_error: 1.1688\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2335 - mean_squared_error: 1.2149\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 173\nReplay buffer size: 78690\nTotal frame count: 78690\nEpsilon: 0.05\nTotal reward for episode: 212.7672131147562\nRunning average rewards: 345.18834880315467 \n\nEpisode: 643\nTrack generation: 1063..1333 -> 270-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.1625 - mean_squared_error: 0.7009\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.2955 - mean_squared_error: 1.6361\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1917 - mean_squared_error: 0.9206\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1731 - mean_squared_error: 0.7253\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2575 - mean_squared_error: 1.5448\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 2\nTotal frames in episode: 238\nReplay buffer size: 78928\nTotal frame count: 78928\nEpsilon: 0.05\nTotal reward for episode: 808.3457249070474\nRunning average rewards: 351.8622729511798 \n\nEpisode: 644\nTrack generation: 1148..1439 -> 291-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2267 - mean_squared_error: 1.1611\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1191 - mean_squared_error: 0.5109\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2454 - mean_squared_error: 1.2114\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1784 - mean_squared_error: 0.7987\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.2007 - mean_squared_error: 0.9080\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 5\nTotal frames in episode: 238\nReplay buffer size: 79166\nTotal frame count: 79166\nEpsilon: 0.05\nTotal reward for episode: 522.2413793103365\nRunning average rewards: 351.92161253933625 \n\nEpisode: 645\nTrack generation: 1100..1379 -> 279-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.3388 - mean_squared_error: 5.0364\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 9ms/step - loss: 0.1866 - mean_squared_error: 0.8672\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1522 - mean_squared_error: 0.6148\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 154\nReplay buffer size: 79320\nTotal frame count: 79320\nEpsilon: 0.05\nTotal reward for episode: 280.12661870502666\nRunning average rewards: 351.20015145365943 \n\nEpisode: 646\nTrack generation: 1184..1484 -> 300-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.2857 - mean_squared_error: 2.4583\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2231 - mean_squared_error: 5.5985\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 128\nReplay buffer size: 79448\nTotal frame count: 79448\nEpsilon: 0.05\nTotal reward for episode: 306.659531772571\nRunning average rewards: 349.8457220364029 \n\nEpisode: 647\nTrack generation: 1185..1492 -> 307-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2669 - mean_squared_error: 1.6062\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 18\nTotal frames in episode: 41\nReplay buffer size: 79489\nTotal frame count: 79489\nEpsilon: 0.05\nTotal reward for episode: -1.8209150326790393\nRunning average rewards: 349.27134568350374 \n\nEpisode: 648\nTrack generation: 1107..1388 -> 281-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.1228 - mean_squared_error: 0.4042\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1868 - mean_squared_error: 0.9443\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1657 - mean_squared_error: 0.8323\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1991 - mean_squared_error: 0.8599\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3146 - mean_squared_error: 1.8861\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 5\nTotal frames in episode: 238\nReplay buffer size: 79727\nTotal frame count: 79727\nEpsilon: 0.05\nTotal reward for episode: 597.8571428571249\nRunning average rewards: 352.54803997896926 \n\nEpisode: 649\nTrack generation: 970..1220 -> 250-tiles track\nretry to generate track (normal if there are not manyinstances of this message)\nTrack generation: 1186..1486 -> 300-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.2719 - mean_squared_error: 1.7683\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4175 - mean_squared_error: 5.0413\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1427 - mean_squared_error: 0.7434\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.2715 - mean_squared_error: 1.4090\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.3432 - mean_squared_error: 2.4870\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 0\nTotal frames in episode: 238\nReplay buffer size: 79965\nTotal frame count: 79965\nEpsilon: 0.05\nTotal reward for episode: 500.3177257525004\nRunning average rewards: 355.00238390316105 \n\nEpisode: 650\nTrack generation: 1135..1429 -> 294-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2334 - mean_squared_error: 1.1842\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1908 - mean_squared_error: 2.0926\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2245 - mean_squared_error: 1.3493\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2262 - mean_squared_error: 1.5204\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3681 - mean_squared_error: 2.4142\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 3\nTotal frames in episode: 238\nReplay buffer size: 80203\nTotal frame count: 80203\nEpsilon: 0.05\nTotal reward for episode: 369.1638225255931\nRunning average rewards: 355.66375897052217 \n\nEpisode: 651\nTrack generation: 1189..1497 -> 308-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.3190 - mean_squared_error: 2.2596\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 72\nReplay buffer size: 80275\nTotal frame count: 80275\nEpsilon: 0.05\nTotal reward for episode: 75.43452768729784\nRunning average rewards: 351.00744850969045 \n\nEpisode: 652\nTrack generation: 1312..1650 -> 338-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.1985 - mean_squared_error: 0.9495\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 70\nReplay buffer size: 80345\nTotal frame count: 80345\nEpsilon: 0.05\nTotal reward for episode: 63.98813056379939\nRunning average rewards: 346.7086819280045 \n\nEpisode: 653\nTrack generation: 1188..1489 -> 301-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2559 - mean_squared_error: 1.7374\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2406 - mean_squared_error: 1.4894\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1859 - mean_squared_error: 1.1398\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2555 - mean_squared_error: 1.6478\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1967 - mean_squared_error: 0.8974\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 10\nTotal frames in episode: 238\nReplay buffer size: 80583\nTotal frame count: 80583\nEpsilon: 0.05\nTotal reward for episode: 404.9999999999823\nRunning average rewards: 348.07273598205853 \n\nEpisode: 654\nTrack generation: 1256..1574 -> 318-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.3347 - mean_squared_error: 1.9667\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.4097 - mean_squared_error: 3.2324\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 80\nReplay buffer size: 80663\nTotal frame count: 80663\nEpsilon: 0.05\nTotal reward for episode: 97.33753943217825\nRunning average rewards: 340.864166931936 \n\nEpisode: 655\nTrack generation: 1167..1463 -> 296-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.3020 - mean_squared_error: 1.6005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4109 - mean_squared_error: 2.7047\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2300 - mean_squared_error: 1.1561\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 186\nReplay buffer size: 80849\nTotal frame count: 80849\nEpsilon: 0.05\nTotal reward for episode: 196.78644067796995\nRunning average rewards: 337.44056792408156 \n\nEpisode: 656\nTrack generation: 1160..1454 -> 294-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.1740 - mean_squared_error: 0.7557\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.3485 - mean_squared_error: 5.2400\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1469 - mean_squared_error: 0.6294\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2400 - mean_squared_error: 1.4043\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1648 - mean_squared_error: 0.9046\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 24\nTotal frames in episode: 238\nReplay buffer size: 81087\nTotal frame count: 81087\nEpsilon: 0.05\nTotal reward for episode: 529.5733788395826\nRunning average rewards: 337.0750060314144 \n\nEpisode: 657\nTrack generation: 1037..1303 -> 266-tiles track\nretry to generate track (normal if there are not manyinstances of this message)\nTrack generation: 1087..1363 -> 276-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.2038 - mean_squared_error: 1.1095\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3465 - mean_squared_error: 2.2573\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 99\nReplay buffer size: 81186\nTotal frame count: 81186\nEpsilon: 0.05\nTotal reward for episode: 236.7636363636317\nRunning average rewards: 335.8202739739982 \n\nEpisode: 658\nTrack generation: 1084..1365 -> 281-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.1437 - mean_squared_error: 0.4617\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1838 - mean_squared_error: 0.8888\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2163 - mean_squared_error: 1.5055\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2404 - mean_squared_error: 1.2032\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 188\nReplay buffer size: 81374\nTotal frame count: 81374\nEpsilon: 0.05\nTotal reward for episode: 396.22857142856253\nRunning average rewards: 334.66589302161725 \n\nEpisode: 659\nTrack generation: 1115..1405 -> 290-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2656 - mean_squared_error: 1.3631\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 9ms/step - loss: 0.1750 - mean_squared_error: 0.8040\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 78\nReplay buffer size: 81452\nTotal frame count: 81452\nEpsilon: 0.05\nTotal reward for episode: 93.36747404844428\nRunning average rewards: 331.0155871795775 \n\nEpisode: 660\nTrack generation: 1137..1425 -> 288-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.3060 - mean_squared_error: 1.8675\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1892 - mean_squared_error: 0.8966\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2688 - mean_squared_error: 1.4815\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 197\nReplay buffer size: 81649\nTotal frame count: 81649\nEpsilon: 0.05\nTotal reward for episode: 342.80278745643943\nRunning average rewards: 328.189667685721 \n\nEpisode: 661\nTrack generation: 1104..1386 -> 282-tiles track\nretry to generate track (normal if there are not manyinstances of this message)\nTrack generation: 1223..1533 -> 310-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.1502 - mean_squared_error: 0.7640\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1987 - mean_squared_error: 0.8524\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2683 - mean_squared_error: 1.5869\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 139\nReplay buffer size: 81788\nTotal frame count: 81788\nEpsilon: 0.05\nTotal reward for episode: 235.66213592232543\nRunning average rewards: 326.02801109932506 \n\nEpisode: 662\nTrack generation: 1124..1409 -> 285-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.1911 - mean_squared_error: 1.0772\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1917 - mean_squared_error: 1.1007\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3685 - mean_squared_error: 2.4392\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1815 - mean_squared_error: 1.2114\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2081 - mean_squared_error: 1.1719\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 1\nTotal frames in episode: 238\nReplay buffer size: 82026\nTotal frame count: 82026\nEpsilon: 0.05\nTotal reward for episode: 693.7323943661816\nRunning average rewards: 330.70405176653645 \n\nEpisode: 663\nTrack generation: 1368..1714 -> 346-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2628 - mean_squared_error: 1.3687\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2816 - mean_squared_error: 1.6084\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1527 - mean_squared_error: 0.6415\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 143\nReplay buffer size: 82169\nTotal frame count: 82169\nEpsilon: 0.05\nTotal reward for episode: 252.94492753622853\nRunning average rewards: 330.1004101328079 \n\nEpisode: 664\nTrack generation: 1111..1393 -> 282-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2254 - mean_squared_error: 1.0161\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2324 - mean_squared_error: 1.6991\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1595 - mean_squared_error: 0.8537\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 136\nReplay buffer size: 82305\nTotal frame count: 82305\nEpsilon: 0.05\nTotal reward for episode: 269.44341637010285\nRunning average rewards: 329.0600915289813 \n\nEpisode: 665\nTrack generation: 1407..1763 -> 356-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.2107 - mean_squared_error: 1.0389\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.2459 - mean_squared_error: 1.3416\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.2417 - mean_squared_error: 1.5538\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.2248 - mean_squared_error: 1.0670\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 48\nTotal frames in episode: 238\nReplay buffer size: 82543\nTotal frame count: 82543\nEpsilon: 0.05\nTotal reward for episode: 364.1549295774503\nRunning average rewards: 330.5695382606532 \n\nEpisode: 666\nTrack generation: 1258..1577 -> 319-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.3030 - mean_squared_error: 1.7773\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.2804 - mean_squared_error: 1.7539\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2743 - mean_squared_error: 1.9616\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 138\nReplay buffer size: 82681\nTotal frame count: 82681\nEpsilon: 0.05\nTotal reward for episode: 259.26540880502614\nRunning average rewards: 332.07313352517406 \n\nEpisode: 667\nTrack generation: 1236..1549 -> 313-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2846 - mean_squared_error: 1.4560\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 10ms/step - loss: 0.3769 - mean_squared_error: 3.7568\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1558 - mean_squared_error: 0.6722\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2498 - mean_squared_error: 1.6810\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 169\nReplay buffer size: 82850\nTotal frame count: 82850\nEpsilon: 0.05\nTotal reward for episode: 336.24615384614907\nRunning average rewards: 333.6512406332558 \n\nEpisode: 668\nTrack generation: 1137..1432 -> 295-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2056 - mean_squared_error: 1.1096\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4028 - mean_squared_error: 2.9416\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 109\nReplay buffer size: 82959\nTotal frame count: 82959\nEpsilon: 0.05\nTotal reward for episode: 129.86938775510401\nRunning average rewards: 330.7739600699123 \n\nEpisode: 669\nTrack generation: 1107..1388 -> 281-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2162 - mean_squared_error: 1.1006\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4420 - mean_squared_error: 3.6890\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 100\nReplay buffer size: 83059\nTotal frame count: 83059\nEpsilon: 0.05\nTotal reward for episode: 245.71428571428135\nRunning average rewards: 324.91753703558237 \n\nEpisode: 670\nTrack generation: 1172..1469 -> 297-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.1730 - mean_squared_error: 0.6824\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.2342 - mean_squared_error: 1.4516\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4058 - mean_squared_error: 3.3449\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2671 - mean_squared_error: 1.4015\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 18\nTotal frames in episode: 238\nReplay buffer size: 83297\nTotal frame count: 83297\nEpsilon: 0.05\nTotal reward for episode: 705.6756756756582\nRunning average rewards: 328.90417914265754 \n\nEpisode: 671\nTrack generation: 1096..1382 -> 286-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2009 - mean_squared_error: 0.7558\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 17\nTotal frames in episode: 42\nReplay buffer size: 83339\nTotal frame count: 83339\nEpsilon: 0.05\nTotal reward for episode: 20.1421052631585\nRunning average rewards: 324.79585993554883 \n\nEpisode: 672\nTrack generation: 1236..1549 -> 313-tiles track\n1/1 [==============================] - 0s 9ms/step - loss: 0.1742 - mean_squared_error: 0.9879\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3913 - mean_squared_error: 5.4379\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.2102 - mean_squared_error: 1.1263\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1396 - mean_squared_error: 0.5050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 188\nReplay buffer size: 83527\nTotal frame count: 83527\nEpsilon: 0.05\nTotal reward for episode: 395.95384615383887\nRunning average rewards: 325.02229980553795 \n\nEpisode: 673\nTrack generation: 1227..1538 -> 311-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2339 - mean_squared_error: 1.5802\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 14ms/step - loss: 0.2975 - mean_squared_error: 1.8399\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2499 - mean_squared_error: 1.5205\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1637 - mean_squared_error: 0.7337\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 208\nReplay buffer size: 83735\nTotal frame count: 83735\nEpsilon: 0.05\nTotal reward for episode: 545.832258064508\nRunning average rewards: 325.3485328339443 \n\nEpisode: 674\nTrack generation: 1260..1579 -> 319-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2053 - mean_squared_error: 1.0308\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2062 - mean_squared_error: 1.3125\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.2402 - mean_squared_error: 1.3061\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2653 - mean_squared_error: 1.1969\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 208\nReplay buffer size: 83943\nTotal frame count: 83943\nEpsilon: 0.05\nTotal reward for episode: 300.4477987421315\nRunning average rewards: 325.54265788018915 \n\nEpisode: 675\nTrack generation: 1146..1441 -> 295-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2244 - mean_squared_error: 1.0985\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1453 - mean_squared_error: 0.5891\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2161 - mean_squared_error: 0.9226\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4302 - mean_squared_error: 5.9159\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2509 - mean_squared_error: 1.4791\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 0\nTotal frames in episode: 238\nReplay buffer size: 84181\nTotal frame count: 84181\nEpsilon: 0.05\nTotal reward for episode: 700.9183673469288\nRunning average rewards: 331.882387008204 \n\nEpisode: 676\nTrack generation: 1184..1484 -> 300-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2542 - mean_squared_error: 1.7135\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1453 - mean_squared_error: 0.7165\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 107\nReplay buffer size: 84288\nTotal frame count: 84288\nEpsilon: 0.05\nTotal reward for episode: 57.53444816053738\nRunning average rewards: 331.4760251961029 \n\nEpisode: 677\nTrack generation: 1115..1398 -> 283-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.1893 - mean_squared_error: 0.8996\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2071 - mean_squared_error: 0.8534\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 109\nReplay buffer size: 84397\nTotal frame count: 84397\nEpsilon: 0.05\nTotal reward for episode: 321.6482269503499\nRunning average rewards: 334.1197989785215 \n\nEpisode: 678\nTrack generation: 1288..1614 -> 326-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.1757 - mean_squared_error: 0.7332\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3595 - mean_squared_error: 4.3586\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2803 - mean_squared_error: 1.9023\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 122\nReplay buffer size: 84519\nTotal frame count: 84519\nEpsilon: 0.05\nTotal reward for episode: 225.04615384615215\nRunning average rewards: 332.76580630452895 \n\nEpisode: 679\nTrack generation: 1068..1339 -> 271-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.3077 - mean_squared_error: 2.6066\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2086 - mean_squared_error: 1.0053\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 107\nReplay buffer size: 84626\nTotal frame count: 84626\nEpsilon: 0.05\nTotal reward for episode: 283.12592592592017\nRunning average rewards: 332.13811987688723 \n\nEpisode: 680\nTrack generation: 1157..1450 -> 293-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.1651 - mean_squared_error: 0.7654\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2516 - mean_squared_error: 1.5689\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 10ms/step - loss: 0.2638 - mean_squared_error: 1.6891\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1691 - mean_squared_error: 0.6849\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 190\nReplay buffer size: 84816\nTotal frame count: 84816\nEpsilon: 0.05\nTotal reward for episode: 338.3835616438295\nRunning average rewards: 332.3311210562395 \n\nEpisode: 681\nTrack generation: 1374..1722 -> 348-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.1864 - mean_squared_error: 0.8228\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1307 - mean_squared_error: 0.5406\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2190 - mean_squared_error: 0.9697\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 152\nReplay buffer size: 84968\nTotal frame count: 84968\nEpsilon: 0.05\nTotal reward for episode: 143.81095100864795\nRunning average rewards: 331.04445863650153 \n\nEpisode: 682\nTrack generation: 1135..1423 -> 288-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.1430 - mean_squared_error: 0.6245\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2929 - mean_squared_error: 2.4303\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2410 - mean_squared_error: 1.0881\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3291 - mean_squared_error: 2.7734\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2248 - mean_squared_error: 1.1195\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 15\nTotal frames in episode: 238\nReplay buffer size: 85206\nTotal frame count: 85206\nEpsilon: 0.05\nTotal reward for episode: 643.6759581881439\nRunning average rewards: 333.9431005713242 \n\nEpisode: 683\nTrack generation: 1108..1389 -> 281-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2809 - mean_squared_error: 2.0123\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3542 - mean_squared_error: 2.3406\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2464 - mean_squared_error: 1.4580\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2142 - mean_squared_error: 1.4626\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 1\nTotal frames in episode: 238\nReplay buffer size: 85444\nTotal frame count: 85444\nEpsilon: 0.05\nTotal reward for episode: 501.4285714285581\nRunning average rewards: 331.2645291427528 \n\nEpisode: 684\nTrack generation: 1229..1540 -> 311-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.3755 - mean_squared_error: 2.4710\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3366 - mean_squared_error: 2.5344\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2564 - mean_squared_error: 1.5953\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 125\nReplay buffer size: 85569\nTotal frame count: 85569\nEpsilon: 0.05\nTotal reward for episode: 243.54838709676994\nRunning average rewards: 326.2994975498031 \n\nEpisode: 685\nTrack generation: 1168..1466 -> 298-tiles track\nretry to generate track (normal if there are not manyinstances of this message)\nTrack generation: 1115..1398 -> 283-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2085 - mean_squared_error: 1.1330\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2294 - mean_squared_error: 1.3368\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.2879 - mean_squared_error: 1.7067\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 9ms/step - loss: 0.2359 - mean_squared_error: 1.4237\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 10ms/step - loss: 0.3822 - mean_squared_error: 3.0280\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 0\nTotal frames in episode: 238\nReplay buffer size: 85807\nTotal frame count: 85807\nEpsilon: 0.05\nTotal reward for episode: 451.0992907801333\nRunning average rewards: 328.84903480011207 \n\nEpisode: 686\nTrack generation: 1096..1374 -> 278-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2921 - mean_squared_error: 2.0135\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2545 - mean_squared_error: 1.6695\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 114\nReplay buffer size: 85921\nTotal frame count: 85921\nEpsilon: 0.05\nTotal reward for episode: 308.1906137184058\nRunning average rewards: 329.30694093729625 \n\nEpisode: 687\nTrack generation: 1127..1419 -> 292-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.1588 - mean_squared_error: 0.6013\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1240 - mean_squared_error: 0.4092\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3115 - mean_squared_error: 2.1488\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4329 - mean_squared_error: 3.9037\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.5893 - mean_squared_error: 9.3830\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 1\nTotal frames in episode: 238\nReplay buffer size: 86159\nTotal frame count: 86159\nEpsilon: 0.05\nTotal reward for episode: 588.8487972508469\nRunning average rewards: 332.54008197102917 \n\nEpisode: 688\nTrack generation: 1017..1275 -> 258-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.1416 - mean_squared_error: 0.5660\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.2963 - mean_squared_error: 3.2353\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2275 - mean_squared_error: 1.7985\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3899 - mean_squared_error: 3.2023\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 44\nTotal frames in episode: 238\nReplay buffer size: 86397\nTotal frame count: 86397\nEpsilon: 0.05\nTotal reward for episode: 827.1789883268345\nRunning average rewards: 339.4159306778269 \n\nEpisode: 689\nTrack generation: 1321..1655 -> 334-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.3645 - mean_squared_error: 2.3150\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2623 - mean_squared_error: 1.4210\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3133 - mean_squared_error: 2.0804\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2388 - mean_squared_error: 0.9984\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2401 - mean_squared_error: 1.5510\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 43\nTotal frames in episode: 238\nReplay buffer size: 86635\nTotal frame count: 86635\nEpsilon: 0.05\nTotal reward for episode: 526.6216216216111\nRunning average rewards: 343.80757833217007 \n\nEpisode: 690\nTrack generation: 1296..1624 -> 328-tiles track\n1/1 [==============================] - 0s 9ms/step - loss: 0.3392 - mean_squared_error: 2.5639\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2999 - mean_squared_error: 1.9178\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.2731 - mean_squared_error: 1.5393\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 138\nReplay buffer size: 86773\nTotal frame count: 86773\nEpsilon: 0.05\nTotal reward for episode: 232.26177370030305\nRunning average rewards: 343.6899030288802 \n\nEpisode: 691\nTrack generation: 1152..1444 -> 292-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.2908 - mean_squared_error: 1.8838\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3015 - mean_squared_error: 1.8053\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 106\nReplay buffer size: 86879\nTotal frame count: 86879\nEpsilon: 0.05\nTotal reward for episode: 235.95051546391267\nRunning average rewards: 342.66333410944526 \n\nEpisode: 692\nTrack generation: 1248..1564 -> 316-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2639 - mean_squared_error: 1.7391\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2425 - mean_squared_error: 1.7114\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 104\nReplay buffer size: 86983\nTotal frame count: 86983\nEpsilon: 0.05\nTotal reward for episode: 225.06666666666442\nRunning average rewards: 338.20513789985796 \n\nEpisode: 693\nTrack generation: 1015..1273 -> 258-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2213 - mean_squared_error: 1.1149\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2939 - mean_squared_error: 1.7257\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3121 - mean_squared_error: 3.1900\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1088 - mean_squared_error: 0.3572\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 202\nReplay buffer size: 87185\nTotal frame count: 87185\nEpsilon: 0.05\nTotal reward for episode: 436.70972762644897\nRunning average rewards: 338.7571105969979 \n\nEpisode: 694\nTrack generation: 1077..1358 -> 281-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2397 - mean_squared_error: 1.0661\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2208 - mean_squared_error: 1.1569\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 94\nReplay buffer size: 87279\nTotal frame count: 87279\nEpsilon: 0.05\nTotal reward for episode: 101.68571428571605\nRunning average rewards: 332.5485291433641 \n\nEpisode: 695\nTrack generation: 1105..1385 -> 280-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2108 - mean_squared_error: 1.2447\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.3709 - mean_squared_error: 2.4529\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3837 - mean_squared_error: 3.2667\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2081 - mean_squared_error: 0.9591\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 184\nReplay buffer size: 87463\nTotal frame count: 87463\nEpsilon: 0.05\nTotal reward for episode: 374.4286738351131\nRunning average rewards: 332.5369335287741 \n\nEpisode: 696\nTrack generation: 1288..1614 -> 326-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.3244 - mean_squared_error: 2.3602\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1184 - mean_squared_error: 0.4388\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 100\nReplay buffer size: 87563\nTotal frame count: 87563\nEpsilon: 0.05\nTotal reward for episode: 150.76923076923256\nRunning average rewards: 330.76897711125406 \n\nEpisode: 697\nTrack generation: 1032..1294 -> 262-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2215 - mean_squared_error: 1.0414\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2039 - mean_squared_error: 1.1207\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 108\nReplay buffer size: 87671\nTotal frame count: 87671\nEpsilon: 0.05\nTotal reward for episode: 270.9762452107225\nRunning average rewards: 331.00713172022415 \n\nEpisode: 698\nTrack generation: 1207..1513 -> 306-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.3828 - mean_squared_error: 3.0598\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2041 - mean_squared_error: 1.0476\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3029 - mean_squared_error: 1.7891\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 170\nReplay buffer size: 87841\nTotal frame count: 87841\nEpsilon: 0.05\nTotal reward for episode: 364.7868852458914\nRunning average rewards: 331.10389609507126 \n\nEpisode: 699\nTrack generation: 1347..1688 -> 341-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2635 - mean_squared_error: 1.2274\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1723 - mean_squared_error: 0.5980\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.5299 - mean_squared_error: 12.3868\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 115\nReplay buffer size: 87956\nTotal frame count: 87956\nEpsilon: 0.05\nTotal reward for episode: 265.76470588234776\nRunning average rewards: 330.7454796618312 \n\nEpisode: 700\nTrack generation: 1313..1645 -> 332-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.3203 - mean_squared_error: 1.8670\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1961 - mean_squared_error: 0.8132\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 122\nReplay buffer size: 88078\nTotal frame count: 88078\nEpsilon: 0.05\nTotal reward for episode: 232.16676737159742\nRunning average rewards: 330.30221943586076 \n\nEpisode: 701\nTrack generation: 1127..1413 -> 286-tiles track\n1/1 [==============================] - 0s 9ms/step - loss: 0.2178 - mean_squared_error: 1.3296\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1961 - mean_squared_error: 0.8273\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1558 - mean_squared_error: 0.5505\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.2441 - mean_squared_error: 1.3472\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 190\nReplay buffer size: 88268\nTotal frame count: 88268\nEpsilon: 0.05\nTotal reward for episode: 429.26315789472403\nRunning average rewards: 329.5295176814748 \n\nEpisode: 702\nTrack generation: 1175..1473 -> 298-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.1480 - mean_squared_error: 0.5674\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1878 - mean_squared_error: 0.8407\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 115\nReplay buffer size: 88383\nTotal frame count: 88383\nEpsilon: 0.05\nTotal reward for episode: 206.5252525252552\nRunning average rewards: 329.79844805907624 \n\nEpisode: 703\nTrack generation: 1034..1287 -> 253-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2766 - mean_squared_error: 1.7821\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2461 - mean_squared_error: 1.7171\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3085 - mean_squared_error: 1.7455\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2525 - mean_squared_error: 1.6474\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3987 - mean_squared_error: 3.3470\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 231\nReplay buffer size: 88614\nTotal frame count: 88614\nEpsilon: 0.05\nTotal reward for episode: 439.34603174602137\nRunning average rewards: 328.2645849564622 \n\nEpisode: 704\nTrack generation: 1198..1501 -> 303-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.1105 - mean_squared_error: 0.3572\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3005 - mean_squared_error: 2.1822\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2608 - mean_squared_error: 1.5812\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4464 - mean_squared_error: 10.0932\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2401 - mean_squared_error: 1.3811\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 0\nTotal frames in episode: 238\nReplay buffer size: 88852\nTotal frame count: 88852\nEpsilon: 0.05\nTotal reward for episode: 633.4768211920405\nRunning average rewards: 334.3011040580623 \n\nEpisode: 705\nTrack generation: 1246..1562 -> 316-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2081 - mean_squared_error: 1.0644\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1974 - mean_squared_error: 0.9160\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3921 - mean_squared_error: 3.6525\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 162\nReplay buffer size: 89014\nTotal frame count: 89014\nEpsilon: 0.05\nTotal reward for episode: 278.0571428571359\nRunning average rewards: 333.92990894966874 \n\nEpisode: 706\nTrack generation: 992..1244 -> 252-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2790 - mean_squared_error: 1.7950\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 9ms/step - loss: 0.3490 - mean_squared_error: 2.3813\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 100\nReplay buffer size: 89114\nTotal frame count: 89114\nEpsilon: 0.05\nTotal reward for episode: 254.82071713146894\nRunning average rewards: 333.418687549555 \n\nEpisode: 707\nTrack generation: 1186..1486 -> 300-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.1932 - mean_squared_error: 1.2919\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2904 - mean_squared_error: 2.8837\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 117\nReplay buffer size: 89231\nTotal frame count: 89231\nEpsilon: 0.05\nTotal reward for episode: 247.51438127089943\nRunning average rewards: 335.11413905457164 \n\nEpisode: 708\nTrack generation: 1057..1325 -> 268-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2878 - mean_squared_error: 1.5495\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2899 - mean_squared_error: 1.6098\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1105 - mean_squared_error: 0.3587\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1831 - mean_squared_error: 0.9112\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1922 - mean_squared_error: 0.8163\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 46\nTotal frames in episode: 238\nReplay buffer size: 89469\nTotal frame count: 89469\nEpsilon: 0.05\nTotal reward for episode: 758.9325842696476\nRunning average rewards: 342.33736653661236 \n\nEpisode: 709\nTrack generation: 1100..1385 -> 285-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.3565 - mean_squared_error: 2.5496\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.3752 - mean_squared_error: 6.1494\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4333 - mean_squared_error: 3.9171\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2008 - mean_squared_error: 0.8749\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2477 - mean_squared_error: 1.4566\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 27\nTotal frames in episode: 238\nReplay buffer size: 89707\nTotal frame count: 89707\nEpsilon: 0.05\nTotal reward for episode: 366.26760563379895\nRunning average rewards: 344.6006802741098 \n\nEpisode: 710\nTrack generation: 1086..1368 -> 282-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.3192 - mean_squared_error: 2.2047\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 73\nReplay buffer size: 89780\nTotal frame count: 89780\nEpsilon: 0.05\nTotal reward for episode: 63.32669039146052\nRunning average rewards: 344.4287350568123 \n\nEpisode: 711\nTrack generation: 1153..1446 -> 293-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.1992 - mean_squared_error: 0.9134\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2503 - mean_squared_error: 1.5753\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3211 - mean_squared_error: 2.9121\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2244 - mean_squared_error: 1.1360\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 196\nReplay buffer size: 89976\nTotal frame count: 89976\nEpsilon: 0.05\nTotal reward for episode: 312.01095890409925\nRunning average rewards: 347.580659460668 \n\nEpisode: 712\nTrack generation: 1088..1372 -> 284-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2480 - mean_squared_error: 1.2806\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2363 - mean_squared_error: 1.3994\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 80\nReplay buffer size: 90056\nTotal frame count: 90056\nEpsilon: 0.05\nTotal reward for episode: 109.34275618374701\nRunning average rewards: 345.0806981336167 \n\nEpisode: 713\nTrack generation: 1017..1281 -> 264-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2797 - mean_squared_error: 1.6857\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3748 - mean_squared_error: 2.4965\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2599 - mean_squared_error: 1.6829\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3369 - mean_squared_error: 2.7068\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 1\nTotal frames in episode: 238\nReplay buffer size: 90294\nTotal frame count: 90294\nEpsilon: 0.05\nTotal reward for episode: 589.4106463878272\nRunning average rewards: 347.7015318702223 \n\nEpisode: 714\nTrack generation: 1143..1433 -> 290-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2574 - mean_squared_error: 1.6454\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3250 - mean_squared_error: 2.1768\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3060 - mean_squared_error: 1.9109\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3360 - mean_squared_error: 2.1689\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 178\nReplay buffer size: 90472\nTotal frame count: 90472\nEpsilon: 0.05\nTotal reward for episode: 357.86574394462787\nRunning average rewards: 345.41358031312893 \n\nEpisode: 715\nTrack generation: 1070..1342 -> 272-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.1953 - mean_squared_error: 0.9436\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.4659 - mean_squared_error: 12.8292\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2961 - mean_squared_error: 1.9630\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4145 - mean_squared_error: 3.1116\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3573 - mean_squared_error: 2.8620\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 0\nTotal frames in episode: 238\nReplay buffer size: 90710\nTotal frame count: 90710\nEpsilon: 0.05\nTotal reward for episode: 753.7084870848576\nRunning average rewards: 350.4620302633425 \n\nEpisode: 716\nTrack generation: 1081..1363 -> 282-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.3289 - mean_squared_error: 2.0162\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2888 - mean_squared_error: 1.6541\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3377 - mean_squared_error: 2.1920\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2656 - mean_squared_error: 1.5277\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 32\nTotal frames in episode: 238\nReplay buffer size: 90948\nTotal frame count: 90948\nEpsilon: 0.05\nTotal reward for episode: 577.5978647686743\nRunning average rewards: 353.75547296331695 \n\nEpisode: 717\nTrack generation: 1267..1588 -> 321-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.4990 - mean_squared_error: 3.6043\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3590 - mean_squared_error: 2.4731\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1366 - mean_squared_error: 0.5239\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4049 - mean_squared_error: 3.4771\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2829 - mean_squared_error: 1.6824\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 23\nTotal frames in episode: 238\nReplay buffer size: 91186\nTotal frame count: 91186\nEpsilon: 0.05\nTotal reward for episode: 414.3749999999908\nRunning average rewards: 354.79205054952376 \n\nEpisode: 718\nTrack generation: 1151..1450 -> 299-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.2745 - mean_squared_error: 1.5306\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3723 - mean_squared_error: 2.4674\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 72\nReplay buffer size: 91258\nTotal frame count: 91258\nEpsilon: 0.05\nTotal reward for episode: 78.58255033557192\nRunning average rewards: 353.5787211233021 \n\nEpisode: 719\nTrack generation: 1184..1484 -> 300-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.3372 - mean_squared_error: 2.9095\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2445 - mean_squared_error: 1.6689\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3125 - mean_squared_error: 2.2014\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3753 - mean_squared_error: 3.2033\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 210\nReplay buffer size: 91468\nTotal frame count: 91468\nEpsilon: 0.05\nTotal reward for episode: 350.78260869564167\nRunning average rewards: 352.63114180485326 \n\nEpisode: 720\nTrack generation: 1206..1512 -> 306-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.3543 - mean_squared_error: 2.9703\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2155 - mean_squared_error: 1.2723\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 105\nReplay buffer size: 91573\nTotal frame count: 91573\nEpsilon: 0.05\nTotal reward for episode: 236.68852459015977\nRunning average rewards: 351.93290424373737 \n\nEpisode: 721\nTrack generation: 1099..1377 -> 278-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.3577 - mean_squared_error: 2.6969\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2372 - mean_squared_error: 1.1071\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4297 - mean_squared_error: 3.1043\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.5366 - mean_squared_error: 10.2272\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 188\nReplay buffer size: 91761\nTotal frame count: 91761\nEpsilon: 0.05\nTotal reward for episode: 462.70613718410215\nRunning average rewards: 353.26835450446737 \n\nEpisode: 722\nTrack generation: 1309..1640 -> 331-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.4166 - mean_squared_error: 5.5108\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2623 - mean_squared_error: 1.4258\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 117\nReplay buffer size: 91878\nTotal frame count: 91878\nEpsilon: 0.05\nTotal reward for episode: 183.50303030303263\nRunning average rewards: 349.11527405831225 \n\nEpisode: 723\nTrack generation: 1286..1612 -> 326-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.3003 - mean_squared_error: 2.7619\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2549 - mean_squared_error: 1.7902\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1841 - mean_squared_error: 0.7393\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2543 - mean_squared_error: 1.4778\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 185\nReplay buffer size: 92063\nTotal frame count: 92063\nEpsilon: 0.05\nTotal reward for episode: 458.307692307684\nRunning average rewards: 346.92380008318565 \n\nEpisode: 724\nTrack generation: 1212..1519 -> 307-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.3210 - mean_squared_error: 2.7188\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4355 - mean_squared_error: 8.3912\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 109\nReplay buffer size: 92172\nTotal frame count: 92172\nEpsilon: 0.05\nTotal reward for episode: 214.56993464052402\nRunning average rewards: 346.4937801313453 \n\nEpisode: 725\nTrack generation: 1223..1533 -> 310-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2890 - mean_squared_error: 2.2424\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2369 - mean_squared_error: 1.2603\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2856 - mean_squared_error: 1.5696\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4921 - mean_squared_error: 3.9155\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 194\nReplay buffer size: 92366\nTotal frame count: 92366\nEpsilon: 0.05\nTotal reward for episode: 521.1055016181125\nRunning average rewards: 348.401047536907 \n\nEpisode: 726\nTrack generation: 1137..1427 -> 290-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.3153 - mean_squared_error: 2.8851\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2894 - mean_squared_error: 1.7605\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 131\nReplay buffer size: 92497\nTotal frame count: 92497\nEpsilon: 0.05\nTotal reward for episode: 210.57577854671482\nRunning average rewards: 349.4379481795169 \n\nEpisode: 727\nTrack generation: 1147..1438 -> 291-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.3818 - mean_squared_error: 3.0694\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3511 - mean_squared_error: 2.1962\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3589 - mean_squared_error: 2.4705\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3750 - mean_squared_error: 2.8323\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3032 - mean_squared_error: 1.7515\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 1\nTotal frames in episode: 238\nReplay buffer size: 92735\nTotal frame count: 92735\nEpsilon: 0.05\nTotal reward for episode: 539.4827586206726\nRunning average rewards: 347.07773979450087 \n\nEpisode: 728\nTrack generation: 1080..1361 -> 281-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2519 - mean_squared_error: 1.4754\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1855 - mean_squared_error: 1.1599\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 72\nReplay buffer size: 92807\nTotal frame count: 92807\nEpsilon: 0.05\nTotal reward for episode: 78.34285714285848\nRunning average rewards: 346.96761997883266 \n\nEpisode: 729\nTrack generation: 1086..1365 -> 279-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2478 - mean_squared_error: 1.1573\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 75\nReplay buffer size: 92882\nTotal frame count: 92882\nEpsilon: 0.05\nTotal reward for episode: 92.30215827338269\nRunning average rewards: 346.92133338546586 \n\nEpisode: 730\nTrack generation: 1192..1494 -> 302-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.3036 - mean_squared_error: 1.9459\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2302 - mean_squared_error: 1.3545\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3780 - mean_squared_error: 5.1797\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2657 - mean_squared_error: 1.3528\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 207\nReplay buffer size: 93089\nTotal frame count: 93089\nEpsilon: 0.05\nTotal reward for episode: 591.6186046511525\nRunning average rewards: 347.08784946498076 \n\nEpisode: 731\nTrack generation: 1264..1584 -> 320-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2802 - mean_squared_error: 1.7434\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2864 - mean_squared_error: 1.5529\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4425 - mean_squared_error: 5.0203\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2776 - mean_squared_error: 1.7341\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2618 - mean_squared_error: 1.4090\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 1\nTotal frames in episode: 238\nReplay buffer size: 93327\nTotal frame count: 93327\nEpsilon: 0.05\nTotal reward for episode: 632.2727272727133\nRunning average rewards: 350.6433986555162 \n\nEpisode: 732\nTrack generation: 1173..1470 -> 297-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2248 - mean_squared_error: 1.4910\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 10ms/step - loss: 0.3911 - mean_squared_error: 2.6873\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 112\nReplay buffer size: 93439\nTotal frame count: 93439\nEpsilon: 0.05\nTotal reward for episode: 225.4702702702679\nRunning average rewards: 349.23048298366064 \n\nEpisode: 733\nTrack generation: 1131..1418 -> 287-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2915 - mean_squared_error: 1.7011\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3286 - mean_squared_error: 3.8746\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2729 - mean_squared_error: 1.5206\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3747 - mean_squared_error: 2.4928\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3091 - mean_squared_error: 1.8641\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 0\nTotal frames in episode: 238\nReplay buffer size: 93677\nTotal frame count: 93677\nEpsilon: 0.05\nTotal reward for episode: 702.202797202784\nRunning average rewards: 350.19633811618246 \n\nEpisode: 734\nTrack generation: 1224..1534 -> 310-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2659 - mean_squared_error: 1.3030\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2953 - mean_squared_error: 1.3625\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2587 - mean_squared_error: 1.3507\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2612 - mean_squared_error: 1.4610\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 9ms/step - loss: 0.2455 - mean_squared_error: 1.0273\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 13\nTotal frames in episode: 238\nReplay buffer size: 93915\nTotal frame count: 93915\nEpsilon: 0.05\nTotal reward for episode: 451.92556634303276\nRunning average rewards: 351.37919871788444 \n\nEpisode: 735\nTrack generation: 1381..1731 -> 350-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2501 - mean_squared_error: 1.8589\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2786 - mean_squared_error: 1.6598\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2448 - mean_squared_error: 1.0938\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 168\nReplay buffer size: 94083\nTotal frame count: 94083\nEpsilon: 0.05\nTotal reward for episode: 225.063610315187\nRunning average rewards: 352.0186681543696 \n\nEpisode: 736\nTrack generation: 1107..1388 -> 281-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.1790 - mean_squared_error: 0.9107\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2464 - mean_squared_error: 1.5242\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2708 - mean_squared_error: 1.6118\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2227 - mean_squared_error: 1.0698\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.2940 - mean_squared_error: 1.9881\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 0\nTotal frames in episode: 238\nReplay buffer size: 94321\nTotal frame count: 94321\nEpsilon: 0.05\nTotal reward for episode: 569.2857142857035\nRunning average rewards: 354.04700581670727 \n\nEpisode: 737\nTrack generation: 1130..1417 -> 287-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.3234 - mean_squared_error: 2.1765\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2803 - mean_squared_error: 1.4618\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.3136 - mean_squared_error: 2.0405\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 139\nReplay buffer size: 94460\nTotal frame count: 94460\nEpsilon: 0.05\nTotal reward for episode: 336.0083916083855\nRunning average rewards: 355.82697246894736 \n\nEpisode: 738\nTrack generation: 1116..1399 -> 283-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.4186 - mean_squared_error: 3.6922\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3107 - mean_squared_error: 1.9456\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3251 - mean_squared_error: 1.9366\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 146\nReplay buffer size: 94606\nTotal frame count: 94606\nEpsilon: 0.05\nTotal reward for episode: 260.74893617020473\nRunning average rewards: 357.5605670938073 \n\nEpisode: 739\nTrack generation: 1135..1423 -> 288-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2000 - mean_squared_error: 1.0188\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2775 - mean_squared_error: 1.4460\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 99\nReplay buffer size: 94705\nTotal frame count: 94705\nEpsilon: 0.05\nTotal reward for episode: 239.1456445992987\nRunning average rewards: 359.0188806826574 \n\nEpisode: 740\nTrack generation: 1088..1372 -> 284-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2312 - mean_squared_error: 1.1565\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 76\nReplay buffer size: 94781\nTotal frame count: 94781\nEpsilon: 0.05\nTotal reward for episode: 107.40918727915333\nRunning average rewards: 352.2710427308877 \n\nEpisode: 741\nTrack generation: 1110..1396 -> 286-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.3849 - mean_squared_error: 2.8689\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 68\nReplay buffer size: 94849\nTotal frame count: 94849\nEpsilon: 0.05\nTotal reward for episode: 64.0280701754399\nRunning average rewards: 344.6362311817198 \n\nEpisode: 742\nTrack generation: 1216..1524 -> 308-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2061 - mean_squared_error: 0.9615\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1659 - mean_squared_error: 0.7967\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3944 - mean_squared_error: 3.1857\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 15ms/step - loss: 0.3776 - mean_squared_error: 3.8596\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.2692 - mean_squared_error: 1.6763\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 212\nReplay buffer size: 95061\nTotal frame count: 95061\nEpsilon: 0.05\nTotal reward for episode: 517.8058631921684\nRunning average rewards: 347.686617682494 \n\nEpisode: 743\nTrack generation: 1038..1302 -> 264-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.3292 - mean_squared_error: 2.0813\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2484 - mean_squared_error: 1.9503\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2811 - mean_squared_error: 1.7684\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 183\nReplay buffer size: 95244\nTotal frame count: 95244\nEpsilon: 0.05\nTotal reward for episode: 455.31711026615073\nRunning average rewards: 344.15633153608496 \n\nEpisode: 744\nTrack generation: 933..1170 -> 237-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2795 - mean_squared_error: 1.6141\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1945 - mean_squared_error: 1.0414\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2788 - mean_squared_error: 1.8036\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3354 - mean_squared_error: 2.1501\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4585 - mean_squared_error: 7.5882\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 1\nTotal frames in episode: 238\nReplay buffer size: 95482\nTotal frame count: 95482\nEpsilon: 0.05\nTotal reward for episode: 502.4576271186347\nRunning average rewards: 343.95849401416797 \n\nEpisode: 745\nTrack generation: 1110..1392 -> 282-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2426 - mean_squared_error: 1.1380\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3197 - mean_squared_error: 1.9630\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2880 - mean_squared_error: 1.7058\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3627 - mean_squared_error: 1.9949\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2559 - mean_squared_error: 1.2771\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 231\nReplay buffer size: 95713\nTotal frame count: 95713\nEpsilon: 0.05\nTotal reward for episode: 605.1088967971384\nRunning average rewards: 347.2083167950891 \n\nEpisode: 746\nTrack generation: 1200..1504 -> 304-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.3197 - mean_squared_error: 2.1420\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4684 - mean_squared_error: 5.3610\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 122\nReplay buffer size: 95835\nTotal frame count: 95835\nEpsilon: 0.05\nTotal reward for episode: 221.82706270626886\nRunning average rewards: 346.3599921044261 \n\nEpisode: 747\nTrack generation: 1040..1309 -> 269-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.3735 - mean_squared_error: 4.2189\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3356 - mean_squared_error: 2.0858\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.4449 - mean_squared_error: 4.4572\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2332 - mean_squared_error: 1.5352\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 178\nReplay buffer size: 96013\nTotal frame count: 96013\nEpsilon: 0.05\nTotal reward for episode: 402.6805970149194\nRunning average rewards: 350.40500722490214 \n\nEpisode: 748\nTrack generation: 1128..1414 -> 286-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2947 - mean_squared_error: 1.5211\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3087 - mean_squared_error: 1.8469\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 118\nReplay buffer size: 96131\nTotal frame count: 96131\nEpsilon: 0.05\nTotal reward for episode: 286.133333333327\nRunning average rewards: 347.28776912966407 \n\nEpisode: 749\nTrack generation: 1140..1429 -> 289-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2432 - mean_squared_error: 1.5146\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1754 - mean_squared_error: 0.8480\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1836 - mean_squared_error: 0.7700\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3319 - mean_squared_error: 2.2468\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2609 - mean_squared_error: 1.3811\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 0\nTotal frames in episode: 238\nReplay buffer size: 96369\nTotal frame count: 96369\nEpsilon: 0.05\nTotal reward for episode: 811.2499999999789\nRunning average rewards: 350.39709187213884 \n\nEpisode: 750\nTrack generation: 1160..1454 -> 294-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2822 - mean_squared_error: 1.8038\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2905 - mean_squared_error: 2.0286\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2980 - mean_squared_error: 2.1338\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 143\nReplay buffer size: 96512\nTotal frame count: 96512\nEpsilon: 0.05\nTotal reward for episode: 226.07645051193973\nRunning average rewards: 348.9662181520023 \n\nEpisode: 751\nTrack generation: 1112..1394 -> 282-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2719 - mean_squared_error: 2.6773\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.3029 - mean_squared_error: 1.8665\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 108\nReplay buffer size: 96620\nTotal frame count: 96620\nEpsilon: 0.05\nTotal reward for episode: 277.08469750889185\nRunning average rewards: 350.98271985021825 \n\nEpisode: 752\nTrack generation: 1056..1331 -> 275-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.1960 - mean_squared_error: 1.1347\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 72\nReplay buffer size: 96692\nTotal frame count: 96692\nEpsilon: 0.05\nTotal reward for episode: 91.63795620438098\nRunning average rewards: 351.2592181066241 \n\nEpisode: 753\nTrack generation: 1065..1337 -> 272-tiles track\nretry to generate track (normal if there are not manyinstances of this message)\nTrack generation: 1242..1561 -> 319-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2548 - mean_squared_error: 1.4138\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3195 - mean_squared_error: 1.9711\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 69\nReplay buffer size: 96761\nTotal frame count: 96761\nEpsilon: 0.05\nTotal reward for episode: 47.87169811320885\nRunning average rewards: 347.6879350877564 \n\nEpisode: 754\nTrack generation: 1134..1421 -> 287-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2674 - mean_squared_error: 2.4733\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3142 - mean_squared_error: 3.2332\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 107\nReplay buffer size: 96868\nTotal frame count: 96868\nEpsilon: 0.05\nTotal reward for episode: 292.86433566433107\nRunning average rewards: 349.6432030500779 \n\nEpisode: 755\nTrack generation: 1223..1533 -> 310-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.3827 - mean_squared_error: 3.4357\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3631 - mean_squared_error: 2.6506\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2473 - mean_squared_error: 1.4781\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3981 - mean_squared_error: 3.6686\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2896 - mean_squared_error: 1.7546\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 1\nTotal frames in episode: 238\nReplay buffer size: 97106\nTotal frame count: 97106\nEpsilon: 0.05\nTotal reward for episode: 526.3592233009562\nRunning average rewards: 352.9389308763077 \n\nEpisode: 756\nTrack generation: 1266..1587 -> 321-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.3893 - mean_squared_error: 2.7642\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.2864 - mean_squared_error: 1.7515\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.5458 - mean_squared_error: 4.4872\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 150\nReplay buffer size: 97256\nTotal frame count: 97256\nEpsilon: 0.05\nTotal reward for episode: 221.25000000000037\nRunning average rewards: 349.8556970879119 \n\nEpisode: 757\nTrack generation: 1160..1462 -> 302-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2297 - mean_squared_error: 1.0978\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.2368 - mean_squared_error: 1.1476\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.2405 - mean_squared_error: 1.4069\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 175\nReplay buffer size: 97431\nTotal frame count: 97431\nEpsilon: 0.05\nTotal reward for episode: 315.38205980065635\nRunning average rewards: 350.6418813222822 \n\nEpisode: 758\nTrack generation: 1168..1464 -> 296-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2775 - mean_squared_error: 1.9805\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2296 - mean_squared_error: 1.3019\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.4532 - mean_squared_error: 7.2370\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 136\nReplay buffer size: 97567\nTotal frame count: 97567\nEpsilon: 0.05\nTotal reward for episode: 230.34576271185972\nRunning average rewards: 348.98305323511516 \n\nEpisode: 759\nTrack generation: 1148..1449 -> 301-tiles track\n1/1 [==============================] - 0s 11ms/step - loss: 0.4289 - mean_squared_error: 3.3289\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.2921 - mean_squared_error: 1.7489\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 9ms/step - loss: 0.2307 - mean_squared_error: 1.3436\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3812 - mean_squared_error: 3.0356\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 184\nReplay buffer size: 97751\nTotal frame count: 97751\nEpsilon: 0.05\nTotal reward for episode: 596.3999999999905\nRunning average rewards: 354.0133784946306 \n\nEpisode: 760\nTrack generation: 1229..1540 -> 311-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2598 - mean_squared_error: 1.7611\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 9ms/step - loss: 0.2266 - mean_squared_error: 1.2447\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4534 - mean_squared_error: 4.6497\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2560 - mean_squared_error: 1.5561\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 203\nReplay buffer size: 97954\nTotal frame count: 97954\nEpsilon: 0.05\nTotal reward for episode: 222.0258064516115\nRunning average rewards: 352.8056086845824 \n\nEpisode: 761\nTrack generation: 1143..1433 -> 290-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.3948 - mean_squared_error: 3.2080\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3447 - mean_squared_error: 2.2231\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 145\nReplay buffer size: 98099\nTotal frame count: 98099\nEpsilon: 0.05\nTotal reward for episode: 346.84429065743166\nRunning average rewards: 353.9174302319334 \n\nEpisode: 762\nTrack generation: 1081..1362 -> 281-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.2339 - mean_squared_error: 1.5644\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4147 - mean_squared_error: 2.5935\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 73\nReplay buffer size: 98172\nTotal frame count: 98172\nEpsilon: 0.05\nTotal reward for episode: 88.65714285714424\nRunning average rewards: 347.8666777168431 \n\nEpisode: 763\nTrack generation: 1061..1330 -> 269-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.3181 - mean_squared_error: 2.0508\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3063 - mean_squared_error: 1.8400\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2280 - mean_squared_error: 1.2810\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.2095 - mean_squared_error: 1.2349\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1538 - mean_squared_error: 0.9400\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 0\nTotal frames in episode: 238\nReplay buffer size: 98410\nTotal frame count: 98410\nEpsilon: 0.05\nTotal reward for episode: 822.9104477611753\nRunning average rewards: 353.5663329190926 \n\nEpisode: 764\nTrack generation: 1319..1653 -> 334-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.3062 - mean_squared_error: 2.9695\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3370 - mean_squared_error: 2.2329\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.3270 - mean_squared_error: 1.8549\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 163\nReplay buffer size: 98573\nTotal frame count: 98573\nEpsilon: 0.05\nTotal reward for episode: 379.2444444444384\nRunning average rewards: 354.6643431998359 \n\nEpisode: 765\nTrack generation: 1096..1380 -> 284-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2618 - mean_squared_error: 1.3612\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.3675 - mean_squared_error: 2.5105\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.4615 - mean_squared_error: 3.4967\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4190 - mean_squared_error: 8.6690\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 198\nReplay buffer size: 98771\nTotal frame count: 98771\nEpsilon: 0.05\nTotal reward for episode: 228.22049469964486\nRunning average rewards: 353.3049988510578 \n\nEpisode: 766\nTrack generation: 1117..1400 -> 283-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2882 - mean_squared_error: 1.8907\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1829 - mean_squared_error: 1.1302\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 122\nReplay buffer size: 98893\nTotal frame count: 98893\nEpsilon: 0.05\nTotal reward for episode: 312.90212765956926\nRunning average rewards: 353.84136603960326 \n\nEpisode: 767\nTrack generation: 1107..1394 -> 287-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.2950 - mean_squared_error: 1.8798\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2370 - mean_squared_error: 1.1404\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 74\nReplay buffer size: 98967\nTotal frame count: 98967\nEpsilon: 0.05\nTotal reward for episode: 64.80559440559577\nRunning average rewards: 351.1269604451976 \n\nEpisode: 768\nTrack generation: 1151..1445 -> 294-tiles track\nretry to generate track (normal if there are not manyinstances of this message)\nTrack generation: 1109..1390 -> 281-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2774 - mean_squared_error: 1.6938\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3754 - mean_squared_error: 3.1237\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3325 - mean_squared_error: 1.6474\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2701 - mean_squared_error: 1.5152\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 207\nReplay buffer size: 99174\nTotal frame count: 99174\nEpsilon: 0.05\nTotal reward for episode: 552.9142857142699\nRunning average rewards: 355.3574094247893 \n\nEpisode: 769\nTrack generation: 1231..1543 -> 312-tiles track\n1/1 [==============================] - 0s 9ms/step - loss: 0.1488 - mean_squared_error: 0.6316\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2508 - mean_squared_error: 2.3106\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.2846 - mean_squared_error: 1.8992\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3170 - mean_squared_error: 2.3443\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2154 - mean_squared_error: 1.0599\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 35\nTotal frames in episode: 238\nReplay buffer size: 99412\nTotal frame count: 99412\nEpsilon: 0.05\nTotal reward for episode: 419.4694533761944\nRunning average rewards: 357.0949611014085 \n\nEpisode: 770\nTrack generation: 1283..1608 -> 325-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.2294 - mean_squared_error: 1.2727\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2492 - mean_squared_error: 1.1086\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.3440 - mean_squared_error: 2.5324\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1825 - mean_squared_error: 0.8769\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2916 - mean_squared_error: 1.7115\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 43\nTotal frames in episode: 238\nReplay buffer size: 99650\nTotal frame count: 99650\nEpsilon: 0.05\nTotal reward for episode: 448.20987654319725\nRunning average rewards: 354.52030311008383 \n\nEpisode: 771\nTrack generation: 1048..1314 -> 266-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.4202 - mean_squared_error: 4.4511\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3525 - mean_squared_error: 2.3786\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.3842 - mean_squared_error: 3.7005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1724 - mean_squared_error: 0.7079\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 20\nTotal frames in episode: 238\nReplay buffer size: 99888\nTotal frame count: 99888\nEpsilon: 0.05\nTotal reward for episode: 799.3396226414943\nRunning average rewards: 362.3122782838672 \n\nEpisode: 772\nTrack generation: 1160..1454 -> 294-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.4730 - mean_squared_error: 12.7650\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1931 - mean_squared_error: 0.8561\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4071 - mean_squared_error: 3.0847\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3397 - mean_squared_error: 2.3333\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 193\nReplay buffer size: 100000\nTotal frame count: 100081\nEpsilon: 0.05\nTotal reward for episode: 462.0491467576645\nRunning average rewards: 362.97323128990547 \n\nEpisode: 773\nTrack generation: 1083..1358 -> 275-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.3482 - mean_squared_error: 2.0927\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2035 - mean_squared_error: 1.2979\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4430 - mean_squared_error: 2.9665\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.4548 - mean_squared_error: 3.5632\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2838 - mean_squared_error: 1.5862\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 1\nTotal frames in episode: 238\nReplay buffer size: 100000\nTotal frame count: 100319\nEpsilon: 0.05\nTotal reward for episode: 766.313868613123\nRunning average rewards: 365.17804739539156 \n\nEpisode: 774\nTrack generation: 1223..1533 -> 310-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2193 - mean_squared_error: 1.4109\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3306 - mean_squared_error: 2.3351\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2329 - mean_squared_error: 1.4718\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3059 - mean_squared_error: 2.5215\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 203\nReplay buffer size: 100000\nTotal frame count: 100522\nEpsilon: 0.05\nTotal reward for episode: 530.4504854368798\nRunning average rewards: 367.4780742623391 \n\nEpisode: 775\nTrack generation: 1072..1353 -> 281-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.3054 - mean_squared_error: 2.2762\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3651 - mean_squared_error: 2.1270\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 78\nReplay buffer size: 100000\nTotal frame count: 100600\nEpsilon: 0.05\nTotal reward for episode: 125.9428571428588\nRunning average rewards: 361.72831916029844 \n\nEpisode: 776\nTrack generation: 1160..1454 -> 294-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.3792 - mean_squared_error: 3.2192\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4377 - mean_squared_error: 3.4164\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 137\nReplay buffer size: 100000\nTotal frame count: 100737\nEpsilon: 0.05\nTotal reward for episode: 252.36723549487232\nRunning average rewards: 363.6766470336417 \n\nEpisode: 777\nTrack generation: 1224..1534 -> 310-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.3838 - mean_squared_error: 3.2690\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2971 - mean_squared_error: 2.3456\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3364 - mean_squared_error: 2.2360\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2381 - mean_squared_error: 1.2438\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2504 - mean_squared_error: 1.7649\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 234\nReplay buffer size: 100000\nTotal frame count: 100971\nEpsilon: 0.05\nTotal reward for episode: 301.22200647247917\nRunning average rewards: 363.4723848288631 \n\nEpisode: 778\nTrack generation: 1187..1488 -> 301-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.5700 - mean_squared_error: 16.0415\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3620 - mean_squared_error: 2.7343\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2954 - mean_squared_error: 2.0980\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 138\nReplay buffer size: 100000\nTotal frame count: 101109\nEpsilon: 0.05\nTotal reward for episode: 224.7999999999984\nRunning average rewards: 363.4699232904015 \n\nEpisode: 779\nTrack generation: 1148..1439 -> 291-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.3167 - mean_squared_error: 1.4420\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2646 - mean_squared_error: 1.4642\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 94\nReplay buffer size: 100000\nTotal frame count: 101203\nEpsilon: 0.05\nTotal reward for episode: 179.64137931034642\nRunning average rewards: 362.4350778242458 \n\nEpisode: 780\nTrack generation: 1159..1453 -> 294-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.3927 - mean_squared_error: 11.7999\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.4035 - mean_squared_error: 2.5579\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 109\nReplay buffer size: 100000\nTotal frame count: 101312\nEpsilon: 0.05\nTotal reward for episode: 260.15426621159924\nRunning average rewards: 361.6527848699235 \n\nEpisode: 781\nTrack generation: 1160..1454 -> 294-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.3399 - mean_squared_error: 2.8516\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3056 - mean_squared_error: 1.4716\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 97\nReplay buffer size: 100000\nTotal frame count: 101409\nEpsilon: 0.05\nTotal reward for episode: 172.80409556314206\nRunning average rewards: 361.94271631546843 \n\nEpisode: 782\nTrack generation: 1136..1424 -> 288-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2736 - mean_squared_error: 1.7140\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3574 - mean_squared_error: 2.0123\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3879 - mean_squared_error: 2.3367\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 165\nReplay buffer size: 100000\nTotal frame count: 101574\nEpsilon: 0.05\nTotal reward for episode: 265.0104529616618\nRunning average rewards: 358.1560612632036 \n\nEpisode: 783\nTrack generation: 1108..1389 -> 281-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.3488 - mean_squared_error: 2.3153\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 10ms/step - loss: 0.2075 - mean_squared_error: 1.1917\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3021 - mean_squared_error: 2.4699\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 144\nReplay buffer size: 100000\nTotal frame count: 101718\nEpsilon: 0.05\nTotal reward for episode: 224.54285714285524\nRunning average rewards: 355.38720412034655 \n\nEpisode: 784\nTrack generation: 1232..1544 -> 312-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.3171 - mean_squared_error: 1.9584\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.2550 - mean_squared_error: 1.3115\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2498 - mean_squared_error: 1.3012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4123 - mean_squared_error: 2.9347\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3619 - mean_squared_error: 2.3323\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 5\nTotal frames in episode: 238\nReplay buffer size: 100000\nTotal frame count: 101956\nEpsilon: 0.05\nTotal reward for episode: 454.8392282958085\nRunning average rewards: 357.5001125323369 \n\nEpisode: 785\nTrack generation: 1059..1328 -> 269-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.2730 - mean_squared_error: 1.3522\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2414 - mean_squared_error: 1.1599\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 119\nReplay buffer size: 100000\nTotal frame count: 102075\nEpsilon: 0.05\nTotal reward for episode: 310.6089552238747\nRunning average rewards: 356.09520917677446 \n\nEpisode: 786\nTrack generation: 1169..1476 -> 307-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.3999 - mean_squared_error: 2.9244\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 27\nTotal frames in episode: 52\nReplay buffer size: 100000\nTotal frame count: 102127\nEpsilon: 0.05\nTotal reward for episode: -12.656862745097087\nRunning average rewards: 352.8867344121394 \n\nEpisode: 787\nTrack generation: 1057..1326 -> 269-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2608 - mean_squared_error: 1.8589\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3037 - mean_squared_error: 2.8262\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2550 - mean_squared_error: 1.3916\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4478 - mean_squared_error: 9.6341\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2979 - mean_squared_error: 1.6447\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 32\nTotal frames in episode: 238\nReplay buffer size: 100000\nTotal frame count: 102365\nEpsilon: 0.05\nTotal reward for episode: 654.9999999999857\nRunning average rewards: 353.54824643963076 \n\nEpisode: 788\nTrack generation: 1174..1472 -> 298-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.3178 - mean_squared_error: 2.4062\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2920 - mean_squared_error: 1.8919\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2759 - mean_squared_error: 1.9237\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4109 - mean_squared_error: 3.1295\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2483 - mean_squared_error: 1.3555\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 29\nTotal frames in episode: 238\nReplay buffer size: 100000\nTotal frame count: 102603\nEpsilon: 0.05\nTotal reward for episode: 517.7946127945964\nRunning average rewards: 350.4544026843084 \n\nEpisode: 789\nTrack generation: 952..1197 -> 245-tiles track\nretry to generate track (normal if there are not manyinstances of this message)\nTrack generation: 1152..1444 -> 292-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.4273 - mean_squared_error: 2.9759\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.2922 - mean_squared_error: 2.2470\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2517 - mean_squared_error: 1.7361\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 186\nReplay buffer size: 100000\nTotal frame count: 102789\nEpsilon: 0.05\nTotal reward for episode: 293.2975945017087\nRunning average rewards: 348.12116241310935 \n\nEpisode: 790\nTrack generation: 1340..1680 -> 340-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2031 - mean_squared_error: 0.9846\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3052 - mean_squared_error: 1.7080\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4575 - mean_squared_error: 3.3097\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1717 - mean_squared_error: 0.6557\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 183\nReplay buffer size: 100000\nTotal frame count: 102972\nEpsilon: 0.05\nTotal reward for episode: 428.27492625368257\nRunning average rewards: 350.0812939386431 \n\nEpisode: 791\nTrack generation: 1180..1479 -> 299-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.1874 - mean_squared_error: 1.0082\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.3001 - mean_squared_error: 1.6851\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3252 - mean_squared_error: 1.9199\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4371 - mean_squared_error: 6.0745\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 182\nReplay buffer size: 100000\nTotal frame count: 103154\nEpsilon: 0.05\nTotal reward for episode: 360.0859060402624\nRunning average rewards: 351.3226478444067 \n\nEpisode: 792\nTrack generation: 1168..1466 -> 298-tiles track\nretry to generate track (normal if there are not manyinstances of this message)\nTrack generation: 1159..1453 -> 294-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2859 - mean_squared_error: 2.2676\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3051 - mean_squared_error: 1.8132\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 131\nReplay buffer size: 100000\nTotal frame count: 103285\nEpsilon: 0.05\nTotal reward for episode: 275.245051194534\nRunning average rewards: 351.82443168968535 \n\nEpisode: 793\nTrack generation: 1124..1409 -> 285-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.3852 - mean_squared_error: 3.2087\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.1978 - mean_squared_error: 1.1188\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2283 - mean_squared_error: 1.5674\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.3860 - mean_squared_error: 3.2485\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 197\nReplay buffer size: 100000\nTotal frame count: 103482\nEpsilon: 0.05\nTotal reward for episode: 449.3690140844964\nRunning average rewards: 351.95102455426587 \n\nEpisode: 794\nTrack generation: 1034..1303 -> 269-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.1993 - mean_squared_error: 1.0035\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1979 - mean_squared_error: 0.9500\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3468 - mean_squared_error: 2.7540\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4359 - mean_squared_error: 3.2232\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3621 - mean_squared_error: 2.8211\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 0\nTotal frames in episode: 238\nReplay buffer size: 100000\nTotal frame count: 103720\nEpsilon: 0.05\nTotal reward for episode: 479.6268656716322\nRunning average rewards: 355.7304360681251 \n\nEpisode: 795\nTrack generation: 1291..1618 -> 327-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2871 - mean_squared_error: 1.3286\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2837 - mean_squared_error: 1.3043\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3112 - mean_squared_error: 1.8667\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3956 - mean_squared_error: 2.5906\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4371 - mean_squared_error: 3.8699\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 1\nTotal frames in episode: 238\nReplay buffer size: 100000\nTotal frame count: 103958\nEpsilon: 0.05\nTotal reward for episode: 558.3742331288231\nRunning average rewards: 357.5698916610621 \n\nEpisode: 796\nTrack generation: 1115..1398 -> 283-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.3340 - mean_squared_error: 2.6792\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2641 - mean_squared_error: 1.5591\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 10ms/step - loss: 0.2700 - mean_squared_error: 1.9684\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2585 - mean_squared_error: 1.3841\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 9\nTotal frames in episode: 238\nReplay buffer size: 100000\nTotal frame count: 104196\nEpsilon: 0.05\nTotal reward for episode: 823.4397163120423\nRunning average rewards: 364.2965965164902 \n\nEpisode: 797\nTrack generation: 1063..1333 -> 270-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2948 - mean_squared_error: 2.0696\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3887 - mean_squared_error: 3.9189\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3275 - mean_squared_error: 1.9344\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2198 - mean_squared_error: 1.1214\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3026 - mean_squared_error: 2.7239\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 9\nTotal frames in episode: 238\nReplay buffer size: 100000\nTotal frame count: 104434\nEpsilon: 0.05\nTotal reward for episode: 823.2156133828878\nRunning average rewards: 369.8189901982119 \n\nEpisode: 798\nTrack generation: 1345..1685 -> 340-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.3135 - mean_squared_error: 1.7359\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2876 - mean_squared_error: 2.5170\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3322 - mean_squared_error: 2.0015\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2496 - mean_squared_error: 1.3401\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2450 - mean_squared_error: 1.4012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 0\nTotal frames in episode: 238\nReplay buffer size: 100000\nTotal frame count: 104672\nEpsilon: 0.05\nTotal reward for episode: 489.07079646016916\nRunning average rewards: 371.0618293103546 \n\nEpisode: 799\nTrack generation: 1239..1553 -> 314-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2895 - mean_squared_error: 1.9142\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4451 - mean_squared_error: 2.8521\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3891 - mean_squared_error: 2.7534\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 144\nReplay buffer size: 100000\nTotal frame count: 104816\nEpsilon: 0.05\nTotal reward for episode: 338.5661341852982\nRunning average rewards: 371.78984359338415 \n\nEpisode: 800\nTrack generation: 1136..1430 -> 294-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.3372 - mean_squared_error: 3.0974\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2870 - mean_squared_error: 1.6420\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3319 - mean_squared_error: 2.4140\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2465 - mean_squared_error: 1.3679\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 187\nReplay buffer size: 100000\nTotal frame count: 105003\nEpsilon: 0.05\nTotal reward for episode: 331.34334470988875\nRunning average rewards: 372.781609366767 \n\nEpisode: 801\nTrack generation: 1014..1280 -> 266-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.5099 - mean_squared_error: 4.2555\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3699 - mean_squared_error: 2.2082\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4352 - mean_squared_error: 4.3860\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3637 - mean_squared_error: 1.9430\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 1\nTotal frames in episode: 238\nReplay buffer size: 100000\nTotal frame count: 105241\nEpsilon: 0.05\nTotal reward for episode: 716.3207547169682\nRunning average rewards: 375.6521853349894 \n\nEpisode: 802\nTrack generation: 1055..1323 -> 268-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2721 - mean_squared_error: 1.6070\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.3343 - mean_squared_error: 2.0496\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4693 - mean_squared_error: 4.2828\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 109\nReplay buffer size: 100000\nTotal frame count: 105350\nEpsilon: 0.05\nTotal reward for episode: 263.516104868909\nRunning average rewards: 376.2220938584259 \n\nEpisode: 803\nTrack generation: 1232..1544 -> 312-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.1493 - mean_squared_error: 0.6285\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 96\nReplay buffer size: 100000\nTotal frame count: 105446\nEpsilon: 0.05\nTotal reward for episode: 199.5421221864968\nRunning average rewards: 373.8240547628307 \n\nEpisode: 804\nTrack generation: 1060..1329 -> 269-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.3272 - mean_squared_error: 2.3901\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4122 - mean_squared_error: 3.2976\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.3307 - mean_squared_error: 1.9519\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2656 - mean_squared_error: 1.2834\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3401 - mean_squared_error: 2.3775\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 3\nTotal frames in episode: 238\nReplay buffer size: 100000\nTotal frame count: 105684\nEpsilon: 0.05\nTotal reward for episode: 666.1940298507346\nRunning average rewards: 374.15122684941764 \n\nEpisode: 805\nTrack generation: 1246..1561 -> 315-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.4127 - mean_squared_error: 2.7586\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4805 - mean_squared_error: 3.2660\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 93\nReplay buffer size: 100000\nTotal frame count: 105777\nEpsilon: 0.05\nTotal reward for episode: 157.06751592356872\nRunning average rewards: 372.94133058008197 \n\nEpisode: 806\nTrack generation: 1267..1549 -> 282-tiles track\nretry to generate track (normal if there are not manyinstances of this message)\nTrack generation: 1253..1570 -> 317-tiles track\n1/1 [==============================] - 0s 9ms/step - loss: 0.4200 - mean_squared_error: 2.9095\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.2872 - mean_squared_error: 1.7367\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 105\nReplay buffer size: 100000\nTotal frame count: 105882\nEpsilon: 0.05\nTotal reward for episode: 185.84810126582536\nRunning average rewards: 372.2516044214255 \n\nEpisode: 807\nTrack generation: 1319..1653 -> 334-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.3161 - mean_squared_error: 1.7371\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2865 - mean_squared_error: 1.7668\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 110\nReplay buffer size: 100000\nTotal frame count: 105992\nEpsilon: 0.05\nTotal reward for episode: 223.267267267267\nRunning average rewards: 372.00913328138915 \n\nEpisode: 808\nTrack generation: 1116..1399 -> 283-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.3798 - mean_squared_error: 2.4932\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3278 - mean_squared_error: 2.0272\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2792 - mean_squared_error: 1.4824\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2158 - mean_squared_error: 1.2421\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2618 - mean_squared_error: 1.4335\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 7\nTotal frames in episode: 238\nReplay buffer size: 100000\nTotal frame count: 106230\nEpsilon: 0.05\nTotal reward for episode: 756.0638297872197\nRunning average rewards: 371.98044573656495 \n\nEpisode: 809\nTrack generation: 1301..1635 -> 334-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.3610 - mean_squared_error: 2.7397\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3104 - mean_squared_error: 1.9730\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 74\nReplay buffer size: 100000\nTotal frame count: 106304\nEpsilon: 0.05\nTotal reward for episode: 87.51711711711845\nRunning average rewards: 369.1929408513981 \n\nEpisode: 810\nTrack generation: 1136..1424 -> 288-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.3732 - mean_squared_error: 3.0209\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2930 - mean_squared_error: 1.6762\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4647 - mean_squared_error: 6.9640\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4556 - mean_squared_error: 3.8578\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 223\nReplay buffer size: 100000\nTotal frame count: 106527\nEpsilon: 0.05\nTotal reward for episode: 642.5073170731548\nRunning average rewards: 374.984747118215 \n\nEpisode: 811\nTrack generation: 1044..1309 -> 265-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.3814 - mean_squared_error: 6.4952\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.3252 - mean_squared_error: 2.2277\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 10ms/step - loss: 0.3487 - mean_squared_error: 2.8582\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2718 - mean_squared_error: 1.7585\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 183\nReplay buffer size: 100000\nTotal frame count: 106710\nEpsilon: 0.05\nTotal reward for episode: 377.55757575756405\nRunning average rewards: 375.6402132867497 \n\nEpisode: 812\nTrack generation: 1099..1378 -> 279-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2180 - mean_squared_error: 1.2170\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.3269 - mean_squared_error: 1.7531\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 115\nReplay buffer size: 100000\nTotal frame count: 106825\nEpsilon: 0.05\nTotal reward for episode: 248.9640287769737\nRunning average rewards: 377.036426012682 \n\nEpisode: 813\nTrack generation: 1189..1490 -> 301-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.3023 - mean_squared_error: 2.1702\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4845 - mean_squared_error: 4.7194\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2500 - mean_squared_error: 1.4246\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2562 - mean_squared_error: 1.6568\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3453 - mean_squared_error: 1.6245\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 1\nTotal frames in episode: 238\nReplay buffer size: 100000\nTotal frame count: 107063\nEpsilon: 0.05\nTotal reward for episode: 681.6666666666525\nRunning average rewards: 377.9589862154702 \n\nEpisode: 814\nTrack generation: 1016..1275 -> 259-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.4569 - mean_squared_error: 4.4774\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2899 - mean_squared_error: 1.6339\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4288 - mean_squared_error: 4.1371\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3837 - mean_squared_error: 2.8096\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 221\nReplay buffer size: 100000\nTotal frame count: 107284\nEpsilon: 0.05\nTotal reward for episode: 803.0728682170429\nRunning average rewards: 382.4110574581944 \n\nEpisode: 815\nTrack generation: 1075..1355 -> 280-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.3663 - mean_squared_error: 2.8100\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3104 - mean_squared_error: 2.1123\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 77\nReplay buffer size: 100000\nTotal frame count: 107361\nEpsilon: 0.05\nTotal reward for episode: 101.81648745519858\nRunning average rewards: 375.89213746189785 \n\nEpisode: 816\nTrack generation: 1176..1474 -> 298-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.3443 - mean_squared_error: 2.4429\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.2859 - mean_squared_error: 1.8161\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 131\nReplay buffer size: 100000\nTotal frame count: 107492\nEpsilon: 0.05\nTotal reward for episode: 378.5764309764245\nRunning average rewards: 373.90192312397545 \n\nEpisode: 817\nTrack generation: 1121..1405 -> 284-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2504 - mean_squared_error: 1.4239\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4243 - mean_squared_error: 3.5901\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3386 - mean_squared_error: 2.4871\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2948 - mean_squared_error: 1.4841\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2616 - mean_squared_error: 1.4155\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 0\nTotal frames in episode: 238\nReplay buffer size: 100000\nTotal frame count: 107730\nEpsilon: 0.05\nTotal reward for episode: 618.780918727904\nRunning average rewards: 375.94598231125457 \n\nEpisode: 818\nTrack generation: 1118..1402 -> 284-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2460 - mean_squared_error: 1.8890\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3768 - mean_squared_error: 3.3593\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3710 - mean_squared_error: 2.4833\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 141\nReplay buffer size: 100000\nTotal frame count: 107871\nEpsilon: 0.05\nTotal reward for episode: 392.36325088338555\nRunning average rewards: 379.08378931673263 \n\nEpisode: 819\nTrack generation: 1130..1417 -> 287-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.4287 - mean_squared_error: 4.0142\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1763 - mean_squared_error: 0.7323\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3669 - mean_squared_error: 2.9875\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 149\nReplay buffer size: 100000\nTotal frame count: 108020\nEpsilon: 0.05\nTotal reward for episode: 227.1132867132835\nRunning average rewards: 377.847096096909 \n\nEpisode: 820\nTrack generation: 1148..1439 -> 291-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.3508 - mean_squared_error: 2.5013\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4040 - mean_squared_error: 3.1928\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.2725 - mean_squared_error: 1.5505\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3086 - mean_squared_error: 1.8962\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 218\nReplay buffer size: 100000\nTotal frame count: 108238\nEpsilon: 0.05\nTotal reward for episode: 499.00689655171027\nRunning average rewards: 380.47027981652457 \n\nEpisode: 821\nTrack generation: 1359..1703 -> 344-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.3151 - mean_squared_error: 2.4576\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.4223 - mean_squared_error: 3.0824\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 94\nReplay buffer size: 100000\nTotal frame count: 108332\nEpsilon: 0.05\nTotal reward for episode: 163.56618075801927\nRunning average rewards: 377.4788802522637 \n\nEpisode: 822\nTrack generation: 1233..1553 -> 320-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.4581 - mean_squared_error: 4.4756\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2527 - mean_squared_error: 1.6083\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2035 - mean_squared_error: 1.0276\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3581 - mean_squared_error: 3.1226\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.5204 - mean_squared_error: 8.4192\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 8\nTotal frames in episode: 238\nReplay buffer size: 100000\nTotal frame count: 108570\nEpsilon: 0.05\nTotal reward for episode: 450.4545454545354\nRunning average rewards: 380.14839540377875 \n\nEpisode: 823\nTrack generation: 1062..1341 -> 279-tiles track\n1/1 [==============================] - 0s 11ms/step - loss: 0.4970 - mean_squared_error: 3.8321\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3604 - mean_squared_error: 2.3331\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3930 - mean_squared_error: 3.3964\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2484 - mean_squared_error: 1.3486\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 189\nReplay buffer size: 100000\nTotal frame count: 108759\nEpsilon: 0.05\nTotal reward for episode: 399.2201438848822\nRunning average rewards: 379.5575199195507 \n\nEpisode: 824\nTrack generation: 1115..1398 -> 283-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2982 - mean_squared_error: 1.8794\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3085 - mean_squared_error: 1.8917\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 104\nReplay buffer size: 100000\nTotal frame count: 108863\nEpsilon: 0.05\nTotal reward for episode: 217.26524822695006\nRunning average rewards: 379.584473055415 \n\nEpisode: 825\nTrack generation: 1241..1555 -> 314-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.3884 - mean_squared_error: 2.6010\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.5158 - mean_squared_error: 5.7595\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2873 - mean_squared_error: 2.0514\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 137\nReplay buffer size: 100000\nTotal frame count: 109000\nEpsilon: 0.05\nTotal reward for episode: 223.15527156549462\nRunning average rewards: 376.60497075488877 \n\nEpisode: 826\nTrack generation: 912..1154 -> 242-tiles track\nretry to generate track (normal if there are not manyinstances of this message)\nTrack generation: 1028..1292 -> 264-tiles track\nretry to generate track (normal if there are not manyinstances of this message)\nTrack generation: 1207..1513 -> 306-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.3227 - mean_squared_error: 2.0150\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2598 - mean_squared_error: 1.6531\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2499 - mean_squared_error: 1.4025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 11ms/step - loss: 0.4655 - mean_squared_error: 4.7665\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 208\nReplay buffer size: 100000\nTotal frame count: 109208\nEpsilon: 0.05\nTotal reward for episode: 428.27540983605286\nRunning average rewards: 378.78196706778215 \n\nEpisode: 827\nTrack generation: 1051..1318 -> 267-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2584 - mean_squared_error: 1.3228\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2438 - mean_squared_error: 1.3653\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.2471 - mean_squared_error: 1.1674\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 161\nReplay buffer size: 100000\nTotal frame count: 109369\nEpsilon: 0.05\nTotal reward for episode: 307.7804511278092\nRunning average rewards: 376.46494399285353 \n\nEpisode: 828\nTrack generation: 1170..1467 -> 297-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.4126 - mean_squared_error: 2.5903\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.3280 - mean_squared_error: 1.6800\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3794 - mean_squared_error: 3.2050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3688 - mean_squared_error: 2.3342\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.3604 - mean_squared_error: 3.4397\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 1\nTotal frames in episode: 238\nReplay buffer size: 100000\nTotal frame count: 109607\nEpsilon: 0.05\nTotal reward for episode: 611.0810810810625\nRunning average rewards: 381.79232623223567 \n\nEpisode: 829\nTrack generation: 1170..1475 -> 305-tiles track\n1/1 [==============================] - 0s 9ms/step - loss: 0.2313 - mean_squared_error: 0.9378\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 74\nReplay buffer size: 100000\nTotal frame count: 109681\nEpsilon: 0.05\nTotal reward for episode: 88.82105263158026\nRunning average rewards: 381.7575151758176 \n\nEpisode: 830\nTrack generation: 1112..1394 -> 282-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.4759 - mean_squared_error: 5.7904\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3170 - mean_squared_error: 2.1816\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 115\nReplay buffer size: 100000\nTotal frame count: 109796\nEpsilon: 0.05\nTotal reward for episode: 295.637010676151\nRunning average rewards: 378.7976992360676 \n\nEpisode: 831\nTrack generation: 1255..1573 -> 318-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2801 - mean_squared_error: 1.6149\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3177 - mean_squared_error: 2.0401\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2015 - mean_squared_error: 1.1011\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 109\nReplay buffer size: 100000\nTotal frame count: 109905\nEpsilon: 0.05\nTotal reward for episode: 230.84794952681017\nRunning average rewards: 374.78345145860857 \n\nEpisode: 832\nTrack generation: 1199..1503 -> 304-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.3176 - mean_squared_error: 2.1440\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3736 - mean_squared_error: 2.7525\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 109\nReplay buffer size: 100000\nTotal frame count: 110014\nEpsilon: 0.05\nTotal reward for episode: 276.5320132013155\nRunning average rewards: 375.2940688879191 \n\nEpisode: 833\nTrack generation: 1076..1349 -> 273-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.3542 - mean_squared_error: 2.0735\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4190 - mean_squared_error: 2.7505\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 115\nReplay buffer size: 100000\nTotal frame count: 110129\nEpsilon: 0.05\nTotal reward for episode: 317.97058823528926\nRunning average rewards: 371.4517467982441 \n\nEpisode: 834\nTrack generation: 1076..1349 -> 273-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.3874 - mean_squared_error: 3.2219\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.3386 - mean_squared_error: 2.0917\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2840 - mean_squared_error: 1.4675\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4354 - mean_squared_error: 3.4094\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4971 - mean_squared_error: 8.4522\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 24\nTotal frames in episode: 238\nReplay buffer size: 100000\nTotal frame count: 110367\nEpsilon: 0.05\nTotal reward for episode: 467.4999999999877\nRunning average rewards: 371.60749113481353 \n\nEpisode: 835\nTrack generation: 1254..1572 -> 318-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2626 - mean_squared_error: 1.5669\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.3085 - mean_squared_error: 1.9975\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3840 - mean_squared_error: 2.3233\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 152\nReplay buffer size: 100000\nTotal frame count: 110519\nEpsilon: 0.05\nTotal reward for episode: 213.6479495268167\nRunning average rewards: 371.49333452692986 \n\nEpisode: 836\nTrack generation: 1180..1479 -> 299-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.3383 - mean_squared_error: 2.1575\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4939 - mean_squared_error: 3.8131\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3686 - mean_squared_error: 2.3145\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 137\nReplay buffer size: 100000\nTotal frame count: 110656\nEpsilon: 0.05\nTotal reward for episode: 243.85771812080117\nRunning average rewards: 368.2390545652808 \n\nEpisode: 837\nTrack generation: 1158..1452 -> 294-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.4257 - mean_squared_error: 3.0759\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3310 - mean_squared_error: 1.9995\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.5729 - mean_squared_error: 13.5934\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 191\nReplay buffer size: 100000\nTotal frame count: 110847\nEpsilon: 0.05\nTotal reward for episode: 466.26211604094544\nRunning average rewards: 369.5415918096065 \n\nEpisode: 838\nTrack generation: 1236..1549 -> 313-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.3352 - mean_squared_error: 2.1639\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4551 - mean_squared_error: 4.1604\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3219 - mean_squared_error: 2.2559\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 148\nReplay buffer size: 100000\nTotal frame count: 110995\nEpsilon: 0.05\nTotal reward for episode: 254.90256410255853\nRunning average rewards: 369.48312808893 \n\nEpisode: 839\nTrack generation: 1336..1682 -> 346-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.3954 - mean_squared_error: 3.5202\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3185 - mean_squared_error: 2.2679\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3107 - mean_squared_error: 2.5529\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 144\nReplay buffer size: 100000\nTotal frame count: 111139\nEpsilon: 0.05\nTotal reward for episode: 327.9072463768067\nRunning average rewards: 370.3707441067051 \n\nEpisode: 840\nTrack generation: 1103..1383 -> 280-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.3362 - mean_squared_error: 2.1233\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2973 - mean_squared_error: 2.0522\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 101\nReplay buffer size: 100000\nTotal frame count: 111240\nEpsilon: 0.05\nTotal reward for episode: 257.0910394265186\nRunning average rewards: 371.8675626281787 \n\nEpisode: 841\nTrack generation: 1170..1476 -> 306-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.3476 - mean_squared_error: 2.3842\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4135 - mean_squared_error: 2.7254\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 10ms/step - loss: 0.2809 - mean_squared_error: 1.4894\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 114\nReplay buffer size: 100000\nTotal frame count: 111354\nEpsilon: 0.05\nTotal reward for episode: 131.44918032787123\nRunning average rewards: 372.54177372970304 \n\nEpisode: 842\nTrack generation: 1086..1361 -> 275-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.6155 - mean_squared_error: 25.4229\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.5310 - mean_squared_error: 12.3303\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 105\nReplay buffer size: 100000\nTotal frame count: 111459\nEpsilon: 0.05\nTotal reward for episode: 286.46715328466695\nRunning average rewards: 370.2283866306281 \n\nEpisode: 843\nTrack generation: 1216..1524 -> 308-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.3019 - mean_squared_error: 1.9593\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3275 - mean_squared_error: 2.4654\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.5329 - mean_squared_error: 4.2256\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.5490 - mean_squared_error: 4.9138\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 232\nReplay buffer size: 100000\nTotal frame count: 111691\nEpsilon: 0.05\nTotal reward for episode: 473.97524429966313\nRunning average rewards: 370.4149679709631 \n\nEpisode: 844\nTrack generation: 1063..1335 -> 272-tiles track\nretry to generate track (normal if there are not manyinstances of this message)\nTrack generation: 1231..1542 -> 311-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.3594 - mean_squared_error: 2.3175\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.2683 - mean_squared_error: 1.5122\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 104\nReplay buffer size: 100000\nTotal frame count: 111795\nEpsilon: 0.05\nTotal reward for episode: 229.36774193548007\nRunning average rewards: 367.6840691191316 \n\nEpisode: 845\nTrack generation: 1108..1389 -> 281-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.3456 - mean_squared_error: 2.2867\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.2302 - mean_squared_error: 1.3912\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4447 - mean_squared_error: 3.8459\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.2739 - mean_squared_error: 1.4681\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3126 - mean_squared_error: 1.5543\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 0\nTotal frames in episode: 238\nReplay buffer size: 100000\nTotal frame count: 112033\nEpsilon: 0.05\nTotal reward for episode: 751.4285714285531\nRunning average rewards: 369.1472658654457 \n\nEpisode: 846\nTrack generation: 1347..1688 -> 341-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.2799 - mean_squared_error: 1.3688\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.3540 - mean_squared_error: 2.6163\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 101\nReplay buffer size: 100000\nTotal frame count: 112134\nEpsilon: 0.05\nTotal reward for episode: 206.65882352941352\nRunning average rewards: 368.9955834736772 \n\nEpisode: 847\nTrack generation: 1097..1384 -> 287-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.3836 - mean_squared_error: 2.4955\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4583 - mean_squared_error: 3.5129\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 76\nReplay buffer size: 100000\nTotal frame count: 112210\nEpsilon: 0.05\nTotal reward for episode: 102.46713286713431\nRunning average rewards: 365.9934488321992 \n\nEpisode: 848\nTrack generation: 1095..1373 -> 278-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.3117 - mean_squared_error: 2.1641\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3840 - mean_squared_error: 2.4840\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 131\nReplay buffer size: 100000\nTotal frame count: 112341\nEpsilon: 0.05\nTotal reward for episode: 247.23898916966817\nRunning average rewards: 365.6045053905627 \n\nEpisode: 849\nTrack generation: 1085..1361 -> 276-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.4477 - mean_squared_error: 3.0089\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3734 - mean_squared_error: 3.7383\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3644 - mean_squared_error: 2.7060\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.2104 - mean_squared_error: 1.1626\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2361 - mean_squared_error: 1.1704\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 48\nTotal frames in episode: 238\nReplay buffer size: 100000\nTotal frame count: 112579\nEpsilon: 0.05\nTotal reward for episode: 592.2727272727097\nRunning average rewards: 363.4147326632899 \n\nEpisode: 850\nTrack generation: 1133..1426 -> 293-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.3433 - mean_squared_error: 3.1947\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4376 - mean_squared_error: 3.1504\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 74\nReplay buffer size: 100000\nTotal frame count: 112653\nEpsilon: 0.05\nTotal reward for episode: 97.11232876712471\nRunning average rewards: 362.1250914458418 \n\nEpisode: 851\nTrack generation: 1056..1324 -> 268-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.4087 - mean_squared_error: 3.2368\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.3652 - mean_squared_error: 2.0381\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 97\nReplay buffer size: 100000\nTotal frame count: 112750\nEpsilon: 0.05\nTotal reward for episode: 212.1363295880147\nRunning average rewards: 361.47560776663306 \n\nEpisode: 852\nTrack generation: 1205..1510 -> 305-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.3727 - mean_squared_error: 2.7275\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4790 - mean_squared_error: 3.6936\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 104\nReplay buffer size: 100000\nTotal frame count: 112854\nEpsilon: 0.05\nTotal reward for episode: 214.9789473684215\nRunning average rewards: 362.70901767827354 \n\nEpisode: 853\nTrack generation: 1181..1480 -> 299-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.3204 - mean_squared_error: 2.1394\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2698 - mean_squared_error: 1.6812\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 131\nReplay buffer size: 100000\nTotal frame count: 112985\nEpsilon: 0.05\nTotal reward for episode: 370.4187919463028\nRunning average rewards: 365.9344886166044 \n\nEpisode: 854\nTrack generation: 1039..1306 -> 267-tiles track\nretry to generate track (normal if there are not manyinstances of this message)\nTrack generation: 1231..1543 -> 312-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.5179 - mean_squared_error: 4.5348\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3677 - mean_squared_error: 2.2524\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.4194 - mean_squared_error: 3.4390\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 139\nReplay buffer size: 100000\nTotal frame count: 113124\nEpsilon: 0.05\nTotal reward for episode: 272.37427652732333\nRunning average rewards: 365.7295880252343 \n\nEpisode: 855\nTrack generation: 1133..1421 -> 288-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.2663 - mean_squared_error: 1.4788\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.5022 - mean_squared_error: 4.8628\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3377 - mean_squared_error: 1.9666\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.3978 - mean_squared_error: 2.9584\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.2477 - mean_squared_error: 1.1264\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 19\nTotal frames in episode: 238\nReplay buffer size: 100000\nTotal frame count: 113362\nEpsilon: 0.05\nTotal reward for episode: 720.3310104529457\nRunning average rewards: 367.6693058967542 \n\nEpisode: 856\nTrack generation: 1137..1425 -> 288-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.2378 - mean_squared_error: 1.4328\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3808 - mean_squared_error: 2.2312\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 130\nReplay buffer size: 100000\nTotal frame count: 113492\nEpsilon: 0.05\nTotal reward for episode: 258.1045296167203\nRunning average rewards: 368.03785119292144 \n\nEpisode: 857\nTrack generation: 1156..1449 -> 293-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.3207 - mean_squared_error: 1.8151\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2672 - mean_squared_error: 1.6432\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.3532 - mean_squared_error: 2.3662\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4193 - mean_squared_error: 3.1369\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3886 - mean_squared_error: 2.4781\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 17\nTotal frames in episode: 238\nReplay buffer size: 100000\nTotal frame count: 113730\nEpsilon: 0.05\nTotal reward for episode: 641.3013698629985\nRunning average rewards: 371.2970442935449 \n\nEpisode: 858\nTrack generation: 1138..1427 -> 289-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.4749 - mean_squared_error: 3.1860\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.3340 - mean_squared_error: 1.9268\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.2686 - mean_squared_error: 1.4961\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.4039 - mean_squared_error: 3.4618\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.5816 - mean_squared_error: 5.6703\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 220\nReplay buffer size: 100000\nTotal frame count: 113950\nEpsilon: 0.05\nTotal reward for episode: 471.0277777777658\nRunning average rewards: 373.703864444204 \n\nEpisode: 859\nTrack generation: 1132..1419 -> 287-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.4154 - mean_squared_error: 4.3776\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2365 - mean_squared_error: 1.4012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 137\nReplay buffer size: 100000\nTotal frame count: 114087\nEpsilon: 0.05\nTotal reward for episode: 340.3048951048903\nRunning average rewards: 371.14291339525306 \n\nEpisode: 860\nTrack generation: 1245..1561 -> 316-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2998 - mean_squared_error: 1.6207\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4945 - mean_squared_error: 3.8851\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 84\nReplay buffer size: 100000\nTotal frame count: 114171\nEpsilon: 0.05\nTotal reward for episode: 141.00317460317615\nRunning average rewards: 370.33268707676865 \n\nEpisode: 861\nTrack generation: 1235..1548 -> 313-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2841 - mean_squared_error: 1.4376\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3147 - mean_squared_error: 1.7848\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 106\nReplay buffer size: 100000\nTotal frame count: 114277\nEpsilon: 0.05\nTotal reward for episode: 294.1384615384572\nRunning average rewards: 369.80562878557896 \n\nEpisode: 862\nTrack generation: 1010..1273 -> 263-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.3147 - mean_squared_error: 1.9425\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3257 - mean_squared_error: 2.1966\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3108 - mean_squared_error: 1.6784\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3185 - mean_squared_error: 2.4504\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 179\nReplay buffer size: 100000\nTotal frame count: 114456\nEpsilon: 0.05\nTotal reward for episode: 390.23206106869407\nRunning average rewards: 372.82137796769445 \n\nEpisode: 863\nTrack generation: 1118..1409 -> 291-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2697 - mean_squared_error: 1.4580\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 82\nReplay buffer size: 100000\nTotal frame count: 114538\nEpsilon: 0.05\nTotal reward for episode: 108.57931034482914\nRunning average rewards: 365.67806659353096 \n\nEpisode: 864\nTrack generation: 1107..1397 -> 290-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2802 - mean_squared_error: 1.4934\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.5203 - mean_squared_error: 5.0433\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 80\nReplay buffer size: 100000\nTotal frame count: 114618\nEpsilon: 0.05\nTotal reward for episode: 96.02768166090111\nRunning average rewards: 362.8458989656956 \n\nEpisode: 865\nTrack generation: 1232..1544 -> 312-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.4222 - mean_squared_error: 2.4984\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.2677 - mean_squared_error: 1.9188\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3531 - mean_squared_error: 2.6489\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2636 - mean_squared_error: 1.6871\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 228\nReplay buffer size: 100000\nTotal frame count: 114846\nEpsilon: 0.05\nTotal reward for episode: 564.7485530546501\nRunning average rewards: 366.2111795492456 \n\nEpisode: 866\nTrack generation: 1171..1468 -> 297-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.3310 - mean_squared_error: 2.0171\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2725 - mean_squared_error: 1.6782\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4144 - mean_squared_error: 2.4264\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 139\nReplay buffer size: 100000\nTotal frame count: 114985\nEpsilon: 0.05\nTotal reward for episode: 288.99459459458706\nRunning average rewards: 365.9721042185958 \n\nEpisode: 867\nTrack generation: 1304..1634 -> 330-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.3975 - mean_squared_error: 3.2789\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4349 - mean_squared_error: 3.8397\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.5087 - mean_squared_error: 4.7593\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.5905 - mean_squared_error: 5.0175\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3210 - mean_squared_error: 1.6969\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 1\nTotal frames in episode: 238\nReplay buffer size: 100000\nTotal frame count: 115223\nEpsilon: 0.05\nTotal reward for episode: 616.2462006078875\nRunning average rewards: 371.4865102806187 \n\nEpisode: 868\nTrack generation: 1232..1544 -> 312-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.6719 - mean_squared_error: 9.5581\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3451 - mean_squared_error: 1.9452\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2135 - mean_squared_error: 1.1482\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4471 - mean_squared_error: 3.3621\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3161 - mean_squared_error: 1.8494\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 35\nTotal frames in episode: 238\nReplay buffer size: 100000\nTotal frame count: 115461\nEpsilon: 0.05\nTotal reward for episode: 419.46945337619456\nRunning average rewards: 370.1520619572379 \n\nEpisode: 869\nTrack generation: 1207..1513 -> 306-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2139 - mean_squared_error: 0.8651\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3233 - mean_squared_error: 2.5602\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 108\nReplay buffer size: 100000\nTotal frame count: 115569\nEpsilon: 0.05\nTotal reward for episode: 215.81639344262368\nRunning average rewards: 368.1155313579022 \n\nEpisode: 870\nTrack generation: 990..1244 -> 254-tiles track\nretry to generate track (normal if there are not manyinstances of this message)\nTrack generation: 1134..1422 -> 288-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.4917 - mean_squared_error: 5.1683\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3983 - mean_squared_error: 3.2870\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 111\nReplay buffer size: 100000\nTotal frame count: 115680\nEpsilon: 0.05\nTotal reward for episode: 304.03205574912346\nRunning average rewards: 366.67375314996156 \n\nEpisode: 871\nTrack generation: 1111..1393 -> 282-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.3479 - mean_squared_error: 2.1018\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.6170 - mean_squared_error: 5.2728\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4145 - mean_squared_error: 2.6701\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 120\nReplay buffer size: 100000\nTotal frame count: 115800\nEpsilon: 0.05\nTotal reward for episode: 222.46263345195533\nRunning average rewards: 360.9049832580661 \n\nEpisode: 872\nTrack generation: 1143..1433 -> 290-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.3417 - mean_squared_error: 2.2018\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.4698 - mean_squared_error: 4.6568\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.5862 - mean_squared_error: 4.8324\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4114 - mean_squared_error: 3.3847\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 1\nTotal frames in episode: 238\nReplay buffer size: 100000\nTotal frame count: 116038\nEpsilon: 0.05\nTotal reward for episode: 687.006920415215\nRunning average rewards: 363.15456099464166 \n\nEpisode: 873\nTrack generation: 1124..1409 -> 285-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.4538 - mean_squared_error: 4.5794\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2126 - mean_squared_error: 1.2105\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 92\nReplay buffer size: 100000\nTotal frame count: 116130\nEpsilon: 0.05\nTotal reward for episode: 181.5098591549317\nRunning average rewards: 357.3065209000597 \n\nEpisode: 874\nTrack generation: 1308..1639 -> 331-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.3727 - mean_squared_error: 2.3758\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3384 - mean_squared_error: 2.4974\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 105\nReplay buffer size: 100000\nTotal frame count: 116235\nEpsilon: 0.05\nTotal reward for episode: 245.87878787878333\nRunning average rewards: 354.46080392447874 \n\nEpisode: 875\nTrack generation: 1232..1544 -> 312-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.3141 - mean_squared_error: 2.1732\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3938 - mean_squared_error: 2.2676\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 94\nReplay buffer size: 100000\nTotal frame count: 116329\nEpsilon: 0.05\nTotal reward for episode: 174.61864951768652\nRunning average rewards: 354.94756184822705 \n\nEpisode: 876\nTrack generation: 1220..1529 -> 309-tiles track\n1/1 [==============================] - 0s 9ms/step - loss: 0.3850 - mean_squared_error: 2.2767\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2469 - mean_squared_error: 1.2688\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 99\nReplay buffer size: 100000\nTotal frame count: 116428\nEpsilon: 0.05\nTotal reward for episode: 158.45194805195024\nRunning average rewards: 354.0084089737978 \n\nEpisode: 877\nTrack generation: 1201..1506 -> 305-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.4465 - mean_squared_error: 3.5584\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3065 - mean_squared_error: 1.9486\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.4781 - mean_squared_error: 4.3734\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 159\nReplay buffer size: 100000\nTotal frame count: 116587\nEpsilon: 0.05\nTotal reward for episode: 354.1631578947267\nRunning average rewards: 354.5378204880203 \n\nEpisode: 878\nTrack generation: 1143..1433 -> 290-tiles track\n1/1 [==============================] - 0s 10ms/step - loss: 0.4405 - mean_squared_error: 3.9327\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.3247 - mean_squared_error: 2.3104\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 99\nReplay buffer size: 100000\nTotal frame count: 116686\nEpsilon: 0.05\nTotal reward for episode: 233.7564013840786\nRunning average rewards: 354.6273845018611 \n\nEpisode: 879\nTrack generation: 1158..1460 -> 302-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.2993 - mean_squared_error: 1.9849\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4410 - mean_squared_error: 3.0970\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3480 - mean_squared_error: 2.9381\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4919 - mean_squared_error: 5.0710\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 189\nReplay buffer size: 100000\nTotal frame count: 116875\nEpsilon: 0.05\nTotal reward for episode: 309.782059800654\nRunning average rewards: 355.9287913067642 \n\nEpisode: 880\nTrack generation: 1329..1664 -> 335-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.5114 - mean_squared_error: 6.2134\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.2932 - mean_squared_error: 1.7698\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3286 - mean_squared_error: 1.9152\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4312 - mean_squared_error: 6.7036\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2946 - mean_squared_error: 1.6265\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 39\nTotal frames in episode: 238\nReplay buffer size: 100000\nTotal frame count: 117113\nEpsilon: 0.05\nTotal reward for episode: 497.8143712574698\nRunning average rewards: 358.3053923572228 \n\nEpisode: 881\nTrack generation: 1256..1574 -> 318-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.4046 - mean_squared_error: 3.7560\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4246 - mean_squared_error: 3.9087\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 117\nReplay buffer size: 100000\nTotal frame count: 117230\nEpsilon: 0.05\nTotal reward for episode: 186.63848580441888\nRunning average rewards: 358.44373625963556 \n\nEpisode: 882\nTrack generation: 1125..1410 -> 285-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.4768 - mean_squared_error: 4.0567\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.5386 - mean_squared_error: 5.2570\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4461 - mean_squared_error: 3.0253\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 155\nReplay buffer size: 100000\nTotal frame count: 117385\nEpsilon: 0.05\nTotal reward for episode: 283.0704225352024\nRunning average rewards: 358.624335955371 \n\nEpisode: 883\nTrack generation: 1248..1564 -> 316-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.4580 - mean_squared_error: 3.2642\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3773 - mean_squared_error: 2.5053\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 97\nReplay buffer size: 100000\nTotal frame count: 117482\nEpsilon: 0.05\nTotal reward for episode: 173.89841269841432\nRunning average rewards: 358.11789151092654 \n\nEpisode: 884\nTrack generation: 1083..1358 -> 275-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.3262 - mean_squared_error: 2.4729\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.3557 - mean_squared_error: 2.2794\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.3880 - mean_squared_error: 2.4032\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 162\nReplay buffer size: 100000\nTotal frame count: 117644\nEpsilon: 0.05\nTotal reward for episode: 230.8204379562009\nRunning average rewards: 355.8777036075305 \n\nEpisode: 885\nTrack generation: 1280..1604 -> 324-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.4792 - mean_squared_error: 6.3334\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2072 - mean_squared_error: 1.3846\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 100\nReplay buffer size: 100000\nTotal frame count: 117744\nEpsilon: 0.05\nTotal reward for episode: 195.29411764706086\nRunning average rewards: 354.72455523176234 \n\nEpisode: 886\nTrack generation: 1207..1513 -> 306-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2580 - mean_squared_error: 1.8732\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2855 - mean_squared_error: 1.7923\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 84\nReplay buffer size: 100000\nTotal frame count: 117828\nEpsilon: 0.05\nTotal reward for episode: 100.82622950819841\nRunning average rewards: 355.85938615429535 \n\nEpisode: 887\nTrack generation: 1124..1409 -> 285-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.4406 - mean_squared_error: 5.1110\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.5313 - mean_squared_error: 6.5765\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3877 - mean_squared_error: 2.7257\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 129\nReplay buffer size: 100000\nTotal frame count: 117957\nEpsilon: 0.05\nTotal reward for episode: 272.3436619718271\nRunning average rewards: 352.0328227740137 \n\nEpisode: 888\nTrack generation: 1043..1308 -> 265-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2913 - mean_squared_error: 2.3941\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4587 - mean_squared_error: 4.1626\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 129\nReplay buffer size: 100000\nTotal frame count: 118086\nEpsilon: 0.05\nTotal reward for episode: 266.58181818181095\nRunning average rewards: 349.5206948278859 \n\nEpisode: 889\nTrack generation: 1227..1537 -> 310-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.3239 - mean_squared_error: 2.5191\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3294 - mean_squared_error: 1.9411\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.5257 - mean_squared_error: 4.5299\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 129\nReplay buffer size: 100000\nTotal frame count: 118215\nEpsilon: 0.05\nTotal reward for episode: 249.37087378640342\nRunning average rewards: 349.0814276207327 \n\nEpisode: 890\nTrack generation: 1302..1631 -> 329-tiles track\n1/1 [==============================] - 0s 9ms/step - loss: 0.3221 - mean_squared_error: 1.8200\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.2330 - mean_squared_error: 1.2881\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 126\nReplay buffer size: 100000\nTotal frame count: 118341\nEpsilon: 0.05\nTotal reward for episode: 248.38048780487293\nRunning average rewards: 347.2824832362448 \n\nEpisode: 891\nTrack generation: 1130..1416 -> 286-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.3678 - mean_squared_error: 2.1549\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4549 - mean_squared_error: 4.7141\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 106\nReplay buffer size: 100000\nTotal frame count: 118447\nEpsilon: 0.05\nTotal reward for episode: 280.40701754385384\nRunning average rewards: 346.48569435128064 \n\nEpisode: 892\nTrack generation: 1047..1313 -> 266-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.3027 - mean_squared_error: 1.8866\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4231 - mean_squared_error: 4.4099\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4431 - mean_squared_error: 3.0648\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 111\nReplay buffer size: 100000\nTotal frame count: 118558\nEpsilon: 0.05\nTotal reward for episode: 363.1471698113143\nRunning average rewards: 347.36471553744855 \n\nEpisode: 893\nTrack generation: 1060..1329 -> 269-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.3544 - mean_squared_error: 2.5524\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.3946 - mean_squared_error: 3.0272\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 95\nReplay buffer size: 100000\nTotal frame count: 118653\nEpsilon: 0.05\nTotal reward for episode: 208.2686567164191\nRunning average rewards: 344.9537119637678 \n\nEpisode: 894\nTrack generation: 1188..1489 -> 301-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.3045 - mean_squared_error: 1.9444\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4240 - mean_squared_error: 3.7189\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3567 - mean_squared_error: 3.4941\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 179\nReplay buffer size: 100000\nTotal frame count: 118832\nEpsilon: 0.05\nTotal reward for episode: 381.7333333333243\nRunning average rewards: 343.97477664038473 \n\nEpisode: 895\nTrack generation: 1239..1553 -> 314-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.3735 - mean_squared_error: 2.6671\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3744 - mean_squared_error: 2.2292\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 116\nReplay buffer size: 100000\nTotal frame count: 118948\nEpsilon: 0.05\nTotal reward for episode: 269.8939297124559\nRunning average rewards: 341.08997360622095 \n\nEpisode: 896\nTrack generation: 1122..1415 -> 293-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.3558 - mean_squared_error: 2.5348\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4191 - mean_squared_error: 3.4171\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 77\nReplay buffer size: 100000\nTotal frame count: 119025\nEpsilon: 0.05\nTotal reward for episode: 113.03561643835761\nRunning average rewards: 333.9859326074841 \n\nEpisode: 897\nTrack generation: 1107..1388 -> 281-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2106 - mean_squared_error: 1.0698\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3486 - mean_squared_error: 2.4306\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3294 - mean_squared_error: 2.3839\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.3739 - mean_squared_error: 2.8328\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 190\nReplay buffer size: 100000\nTotal frame count: 119215\nEpsilon: 0.05\nTotal reward for episode: 506.1428571428472\nRunning average rewards: 330.8152050450837 \n\nEpisode: 898\nTrack generation: 1068..1339 -> 271-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.3377 - mean_squared_error: 2.3729\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4352 - mean_squared_error: 3.2638\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 126\nReplay buffer size: 100000\nTotal frame count: 119341\nEpsilon: 0.05\nTotal reward for episode: 297.7481481481412\nRunning average rewards: 328.90197856196346 \n\nEpisode: 899\nTrack generation: 1067..1340 -> 273-tiles track\nretry to generate track (normal if there are not manyinstances of this message)\nTrack generation: 1160..1454 -> 294-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.3942 - mean_squared_error: 2.5973\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2605 - mean_squared_error: 1.4313\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2737 - mean_squared_error: 1.5591\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2367 - mean_squared_error: 1.1755\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3215 - mean_squared_error: 2.2729\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 3\nTotal frames in episode: 238\nReplay buffer size: 100000\nTotal frame count: 119579\nEpsilon: 0.05\nTotal reward for episode: 662.679180887358\nRunning average rewards: 332.1431090289841 \n\nEpisode: 900\nTrack generation: 1197..1463 -> 266-tiles track\nretry to generate track (normal if there are not manyinstances of this message)\nTrack generation: 1135..1429 -> 294-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.2103 - mean_squared_error: 0.9208\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3490 - mean_squared_error: 3.5764\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2118 - mean_squared_error: 1.1618\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.5576 - mean_squared_error: 6.3324\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 190\nReplay buffer size: 100000\nTotal frame count: 119769\nEpsilon: 0.05\nTotal reward for episode: 422.2935153583513\nRunning average rewards: 333.0526107354687 \n\nEpisode: 901\nTrack generation: 1164..1459 -> 295-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2872 - mean_squared_error: 1.8320\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.5256 - mean_squared_error: 11.1042\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.5015 - mean_squared_error: 8.3897\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4590 - mean_squared_error: 3.8349\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3033 - mean_squared_error: 1.8432\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 48\nTotal frames in episode: 238\nReplay buffer size: 100000\nTotal frame count: 120007\nEpsilon: 0.05\nTotal reward for episode: 496.8367346938712\nRunning average rewards: 330.85777053523765 \n\nEpisode: 902\nTrack generation: 1133..1424 -> 291-tiles track\nretry to generate track (normal if there are not manyinstances of this message)\nTrack generation: 1155..1448 -> 293-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.3732 - mean_squared_error: 2.4004\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2798 - mean_squared_error: 1.6974\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 134\nReplay buffer size: 100000\nTotal frame count: 120141\nEpsilon: 0.05\nTotal reward for episode: 234.07123287670834\nRunning average rewards: 330.5633218153157 \n\nEpisode: 903\nTrack generation: 1180..1479 -> 299-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.3060 - mean_squared_error: 2.2321\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3779 - mean_squared_error: 2.7655\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.3352 - mean_squared_error: 2.4766\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4967 - mean_squared_error: 9.4832\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 201\nReplay buffer size: 100000\nTotal frame count: 120342\nEpsilon: 0.05\nTotal reward for episode: 446.44563758388233\nRunning average rewards: 333.0323569692896 \n\nEpisode: 904\nTrack generation: 1090..1374 -> 284-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.3942 - mean_squared_error: 3.1987\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2967 - mean_squared_error: 1.8272\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 79\nReplay buffer size: 100000\nTotal frame count: 120421\nEpsilon: 0.05\nTotal reward for episode: 92.07491166077881\nRunning average rewards: 327.29116578738996 \n\nEpisode: 905\nTrack generation: 1153..1445 -> 292-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.4092 - mean_squared_error: 2.9940\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3927 - mean_squared_error: 3.6045\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2976 - mean_squared_error: 1.5269\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.4501 - mean_squared_error: 3.5711\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4099 - mean_squared_error: 2.7408\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 7\nTotal frames in episode: 238\nReplay buffer size: 100000\nTotal frame count: 120659\nEpsilon: 0.05\nTotal reward for episode: 715.9965635738641\nRunning average rewards: 332.88045626389294 \n\nEpisode: 906\nTrack generation: 1071..1343 -> 272-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.3534 - mean_squared_error: 2.2892\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4316 - mean_squared_error: 4.9570\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 114\nReplay buffer size: 100000\nTotal frame count: 120773\nEpsilon: 0.05\nTotal reward for episode: 312.3335793357877\nRunning average rewards: 334.1453110445926 \n\nEpisode: 907\nTrack generation: 1137..1426 -> 289-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2824 - mean_squared_error: 1.7101\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.7147 - mean_squared_error: 20.8228\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3375 - mean_squared_error: 2.3121\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 176\nReplay buffer size: 100000\nTotal frame count: 120949\nEpsilon: 0.05\nTotal reward for episode: 429.59999999999025\nRunning average rewards: 336.2086383719199 \n\nEpisode: 908\nTrack generation: 1040..1312 -> 272-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.4407 - mean_squared_error: 3.1487\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.4857 - mean_squared_error: 4.1048\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 76\nReplay buffer size: 100000\nTotal frame count: 121025\nEpsilon: 0.05\nTotal reward for episode: 113.51143911439266\nRunning average rewards: 329.7831144651915 \n\nEpisode: 909\nTrack generation: 1198..1509 -> 311-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.4071 - mean_squared_error: 3.5809\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.3734 - mean_squared_error: 3.3152\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4426 - mean_squared_error: 3.0129\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2192 - mean_squared_error: 0.9803\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 221\nReplay buffer size: 100000\nTotal frame count: 121246\nEpsilon: 0.05\nTotal reward for episode: 363.2129032257976\nRunning average rewards: 332.5400723262782 \n\nEpisode: 910\nTrack generation: 1285..1610 -> 325-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.3288 - mean_squared_error: 2.0978\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3091 - mean_squared_error: 2.1404\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2799 - mean_squared_error: 1.6267\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 133\nReplay buffer size: 100000\nTotal frame count: 121379\nEpsilon: 0.05\nTotal reward for episode: 320.256790123452\nRunning average rewards: 329.31756705678134 \n\nEpisode: 911\nTrack generation: 1111..1393 -> 282-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2959 - mean_squared_error: 1.9676\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2956 - mean_squared_error: 2.3621\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3011 - mean_squared_error: 1.7012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3429 - mean_squared_error: 2.0715\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3531 - mean_squared_error: 2.4197\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 3\nTotal frames in episode: 238\nReplay buffer size: 100000\nTotal frame count: 121617\nEpsilon: 0.05\nTotal reward for episode: 830.2669039145763\nRunning average rewards: 333.8446603383514 \n\nEpisode: 912\nTrack generation: 1149..1447 -> 298-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.3528 - mean_squared_error: 2.2604\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 73\nReplay buffer size: 100000\nTotal frame count: 121690\nEpsilon: 0.05\nTotal reward for episode: 85.27811447811585\nRunning average rewards: 332.20780119536283 \n\nEpisode: 913\nTrack generation: 1167..1462 -> 295-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.4916 - mean_squared_error: 5.1668\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.4125 - mean_squared_error: 3.1809\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4308 - mean_squared_error: 3.4578\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 116\nReplay buffer size: 100000\nTotal frame count: 121806\nEpsilon: 0.05\nTotal reward for episode: 280.1306122448931\nRunning average rewards: 328.1924406511452 \n\nEpisode: 914\nTrack generation: 1239..1553 -> 314-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.3890 - mean_squared_error: 3.2754\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.5641 - mean_squared_error: 8.8045\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.5060 - mean_squared_error: 3.7505\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 186\nReplay buffer size: 100000\nTotal frame count: 121992\nEpsilon: 0.05\nTotal reward for episode: 264.2581469648531\nRunning average rewards: 322.8042934386233 \n\nEpisode: 915\nTrack generation: 1167..1463 -> 296-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.5480 - mean_squared_error: 4.9616\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3527 - mean_squared_error: 2.3571\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3922 - mean_squared_error: 5.8312\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 149\nReplay buffer size: 100000\nTotal frame count: 122141\nEpsilon: 0.05\nTotal reward for episode: 343.7898305084675\nRunning average rewards: 325.224026869156 \n\nEpisode: 916\nTrack generation: 1268..1589 -> 321-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.4419 - mean_squared_error: 4.3015\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4241 - mean_squared_error: 3.9762\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2934 - mean_squared_error: 2.1774\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 152\nReplay buffer size: 100000\nTotal frame count: 122293\nEpsilon: 0.05\nTotal reward for episode: 354.8249999999939\nRunning average rewards: 324.9865125593917 \n\nEpisode: 917\nTrack generation: 1200..1504 -> 304-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.7299 - mean_squared_error: 19.0834\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4574 - mean_squared_error: 3.1905\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.6338 - mean_squared_error: 5.5040\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3038 - mean_squared_error: 2.1290\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 159\nReplay buffer size: 100000\nTotal frame count: 122452\nEpsilon: 0.05\nTotal reward for episode: 603.0666666666591\nRunning average rewards: 324.82937003877925 \n\nEpisode: 918\nTrack generation: 1271..1593 -> 322-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2754 - mean_squared_error: 1.5588\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.6274 - mean_squared_error: 8.4308\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 103\nReplay buffer size: 100000\nTotal frame count: 122555\nEpsilon: 0.05\nTotal reward for episode: 214.25171339564034\nRunning average rewards: 323.0482546639018 \n\nEpisode: 919\nTrack generation: 1027..1288 -> 261-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.5653 - mean_squared_error: 7.6309\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3027 - mean_squared_error: 1.7382\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 119\nReplay buffer size: 100000\nTotal frame count: 122674\nEpsilon: 0.05\nTotal reward for episode: 367.78461538460954\nRunning average rewards: 324.45496795061507 \n\nEpisode: 920\nTrack generation: 1127..1413 -> 286-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.5505 - mean_squared_error: 5.1325\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2922 - mean_squared_error: 1.7791\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.7295 - mean_squared_error: 20.1488\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.4838 - mean_squared_error: 3.9388\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.5184 - mean_squared_error: 4.3731\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 48\nTotal frames in episode: 238\nReplay buffer size: 100000\nTotal frame count: 122912\nEpsilon: 0.05\nTotal reward for episode: 596.2280701754225\nRunning average rewards: 325.4271796868522 \n\nEpisode: 921\nTrack generation: 1136..1433 -> 297-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.3224 - mean_squared_error: 1.8572\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 80\nReplay buffer size: 100000\nTotal frame count: 122992\nEpsilon: 0.05\nTotal reward for episode: 120.02702702702854\nRunning average rewards: 324.9917881495423 \n\nEpisode: 922\nTrack generation: 1305..1635 -> 330-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2849 - mean_squared_error: 1.4285\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3759 - mean_squared_error: 2.4481\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4621 - mean_squared_error: 6.4733\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2620 - mean_squared_error: 1.5052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3504 - mean_squared_error: 2.5133\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 0\nTotal frames in episode: 238\nReplay buffer size: 100000\nTotal frame count: 123230\nEpsilon: 0.05\nTotal reward for episode: 537.2188449847893\nRunning average rewards: 325.85943114484485 \n\nEpisode: 923\nTrack generation: 1023..1285 -> 262-tiles track\nretry to generate track (normal if there are not manyinstances of this message)\nTrack generation: 1064..1337 -> 273-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.3679 - mean_squared_error: 2.1944\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 29\nTotal frames in episode: 46\nReplay buffer size: 100000\nTotal frame count: 123276\nEpsilon: 0.05\nTotal reward for episode: -40.994117647058076\nRunning average rewards: 321.45728852952544 \n\nEpisode: 924\nTrack generation: 1060..1329 -> 269-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.5609 - mean_squared_error: 13.5053\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3701 - mean_squared_error: 2.6005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 115\nReplay buffer size: 100000\nTotal frame count: 123391\nEpsilon: 0.05\nTotal reward for episode: 368.1791044776049\nRunning average rewards: 322.966427092032 \n\nEpisode: 925\nTrack generation: 1041..1305 -> 264-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2552 - mean_squared_error: 1.5770\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3806 - mean_squared_error: 4.4114\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2674 - mean_squared_error: 1.5009\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4457 - mean_squared_error: 3.9950\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3522 - mean_squared_error: 2.0787\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 209\nReplay buffer size: 100000\nTotal frame count: 123600\nEpsilon: 0.05\nTotal reward for episode: 323.2441064638708\nRunning average rewards: 323.9673154410157 \n\nEpisode: 926\nTrack generation: 1223..1532 -> 309-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.3888 - mean_squared_error: 2.8586\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4328 - mean_squared_error: 2.6071\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 115\nReplay buffer size: 100000\nTotal frame count: 123715\nEpsilon: 0.05\nTotal reward for episode: 317.63636363635885\nRunning average rewards: 322.86092497901876 \n\nEpisode: 927\nTrack generation: 1242..1557 -> 315-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.6258 - mean_squared_error: 17.2471\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2740 - mean_squared_error: 1.7545\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 120\nReplay buffer size: 100000\nTotal frame count: 123835\nEpsilon: 0.05\nTotal reward for episode: 308.6878980891661\nRunning average rewards: 322.86999944863237 \n\nEpisode: 928\nTrack generation: 1223..1533 -> 310-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.4184 - mean_squared_error: 3.0051\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3036 - mean_squared_error: 2.1159\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4525 - mean_squared_error: 3.2959\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 129\nReplay buffer size: 100000\nTotal frame count: 123964\nEpsilon: 0.05\nTotal reward for episode: 320.568284789638\nRunning average rewards: 319.96487148571816 \n\nEpisode: 929\nTrack generation: 1091..1368 -> 277-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.4578 - mean_squared_error: 7.9884\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2463 - mean_squared_error: 1.4417\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 96\nReplay buffer size: 100000\nTotal frame count: 124060\nEpsilon: 0.05\nTotal reward for episode: 218.84637681159225\nRunning average rewards: 321.26512472751824 \n\nEpisode: 930\nTrack generation: 1035..1298 -> 263-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.3775 - mean_squared_error: 2.4929\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4869 - mean_squared_error: 3.8315\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 127\nReplay buffer size: 100000\nTotal frame count: 124187\nEpsilon: 0.05\nTotal reward for episode: 391.94809160304743\nRunning average rewards: 322.2282355367872 \n\nEpisode: 931\nTrack generation: 1073..1348 -> 275-tiles track\nretry to generate track (normal if there are not manyinstances of this message)\nTrack generation: 1309..1641 -> 332-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.4368 - mean_squared_error: 4.0153\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.3966 - mean_squared_error: 2.7343\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4466 - mean_squared_error: 3.4518\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.4888 - mean_squared_error: 6.7153\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 199\nReplay buffer size: 100000\nTotal frame count: 124386\nEpsilon: 0.05\nTotal reward for episode: 376.59335347430556\nRunning average rewards: 323.6856895762622 \n\nEpisode: 932\nTrack generation: 936..1179 -> 243-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.2748 - mean_squared_error: 1.9118\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2360 - mean_squared_error: 1.4378\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.3755 - mean_squared_error: 3.0190\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 153\nReplay buffer size: 100000\nTotal frame count: 124539\nEpsilon: 0.05\nTotal reward for episode: 451.1966942148702\nRunning average rewards: 325.4323363863977 \n\nEpisode: 933\nTrack generation: 1059..1332 -> 273-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.4033 - mean_squared_error: 2.3072\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3504 - mean_squared_error: 2.6481\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 67\nReplay buffer size: 100000\nTotal frame count: 124606\nEpsilon: 0.05\nTotal reward for episode: 57.758823529413036\nRunning average rewards: 322.830218739339 \n\nEpisode: 934\nTrack generation: 1146..1437 -> 291-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.4468 - mean_squared_error: 3.6772\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.6550 - mean_squared_error: 7.2241\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 114\nReplay buffer size: 100000\nTotal frame count: 124720\nEpsilon: 0.05\nTotal reward for episode: 244.0551724137872\nRunning average rewards: 320.595770463477 \n\nEpisode: 935\nTrack generation: 1141..1435 -> 294-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.5490 - mean_squared_error: 4.5887\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 69\nReplay buffer size: 100000\nTotal frame count: 124789\nEpsilon: 0.05\nTotal reward for episode: 67.96313993174198\nRunning average rewards: 319.1389223675262 \n\nEpisode: 936\nTrack generation: 1216..1524 -> 308-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.3788 - mean_squared_error: 2.5817\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3726 - mean_squared_error: 2.6915\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3073 - mean_squared_error: 1.6962\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.2299 - mean_squared_error: 1.2429\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.4857 - mean_squared_error: 3.4130\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 0\nTotal frames in episode: 237\nReplay buffer size: 100000\nTotal frame count: 125026\nEpsilon: 0.05\nTotal reward for episode: 876.1840390879262\nRunning average rewards: 325.46218557719743 \n\nEpisode: 937\nTrack generation: 1192..1494 -> 302-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.6165 - mean_squared_error: 5.5160\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4109 - mean_squared_error: 2.6240\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 95\nReplay buffer size: 100000\nTotal frame count: 125121\nEpsilon: 0.05\nTotal reward for episode: 227.7807308970071\nRunning average rewards: 323.07737172575804 \n\nEpisode: 938\nTrack generation: 1079..1353 -> 274-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.4047 - mean_squared_error: 2.9295\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4603 - mean_squared_error: 3.7297\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 100\nReplay buffer size: 100000\nTotal frame count: 125221\nEpsilon: 0.05\nTotal reward for episode: 267.69230769230273\nRunning average rewards: 323.2052691616555 \n\nEpisode: 939\nTrack generation: 1157..1450 -> 293-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.3557 - mean_squared_error: 2.2491\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.5137 - mean_squared_error: 4.4230\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4333 - mean_squared_error: 4.1385\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2813 - mean_squared_error: 1.9532\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 183\nReplay buffer size: 100000\nTotal frame count: 125404\nEpsilon: 0.05\nTotal reward for episode: 505.56712328766\nRunning average rewards: 324.981867930764 \n\nEpisode: 940\nTrack generation: 1108..1389 -> 281-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.4264 - mean_squared_error: 3.2800\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 9ms/step - loss: 0.2439 - mean_squared_error: 1.6902\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.6206 - mean_squared_error: 6.0336\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.3996 - mean_squared_error: 2.4778\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 1\nTotal frames in episode: 238\nReplay buffer size: 100000\nTotal frame count: 125642\nEpsilon: 0.05\nTotal reward for episode: 651.4285714285536\nRunning average rewards: 328.9252432507843 \n\nEpisode: 941\nTrack generation: 1214..1522 -> 308-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.3039 - mean_squared_error: 1.6763\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.4399 - mean_squared_error: 3.9283\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.3958 - mean_squared_error: 4.1267\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.3044 - mean_squared_error: 2.4261\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 167\nReplay buffer size: 100000\nTotal frame count: 125809\nEpsilon: 0.05\nTotal reward for episode: 327.3368078175813\nRunning average rewards: 330.88411952568146 \n\nEpisode: 942\nTrack generation: 1242..1556 -> 314-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.3599 - mean_squared_error: 2.1703\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3842 - mean_squared_error: 2.4665\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.6218 - mean_squared_error: 6.0974\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 180\nReplay buffer size: 100000\nTotal frame count: 125989\nEpsilon: 0.05\nTotal reward for episode: 384.8690095846557\nRunning average rewards: 331.86813808868135 \n\nEpisode: 943\nTrack generation: 1159..1453 -> 294-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.8337 - mean_squared_error: 14.8879\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4883 - mean_squared_error: 4.0838\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4303 - mean_squared_error: 3.2082\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 144\nReplay buffer size: 100000\nTotal frame count: 126133\nEpsilon: 0.05\nTotal reward for episode: 314.41365187712427\nRunning average rewards: 330.272522164456 \n\nEpisode: 944\nTrack generation: 1109..1394 -> 285-tiles track\nretry to generate track (normal if there are not manyinstances of this message)\nTrack generation: 1324..1659 -> 335-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.4033 - mean_squared_error: 2.5327\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3657 - mean_squared_error: 2.9273\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 103\nReplay buffer size: 100000\nTotal frame count: 126236\nEpsilon: 0.05\nTotal reward for episode: 252.21317365269027\nRunning average rewards: 330.5009764816281 \n\nEpisode: 945\nTrack generation: 997..1250 -> 253-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.4296 - mean_squared_error: 3.0857\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4765 - mean_squared_error: 3.6689\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2469 - mean_squared_error: 1.3369\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.6422 - mean_squared_error: 6.4125\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 0\nTotal frames in episode: 191\nReplay buffer size: 100000\nTotal frame count: 126427\nEpsilon: 0.05\nTotal reward for episode: 887.9857142857024\nRunning average rewards: 331.86654791019953 \n\nEpisode: 946\nTrack generation: 1208..1518 -> 310-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.4363 - mean_squared_error: 3.1904\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4192 - mean_squared_error: 3.3895\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.1581 - mean_squared_error: 0.5282\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.3731 - mean_squared_error: 2.5169\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.2732 - mean_squared_error: 1.8923\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 0\nTotal frames in episode: 238\nReplay buffer size: 100000\nTotal frame count: 126665\nEpsilon: 0.05\nTotal reward for episode: 455.16181229772855\nRunning average rewards: 334.3515777978827 \n\nEpisode: 947\nTrack generation: 1104..1384 -> 280-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.3608 - mean_squared_error: 2.4587\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4019 - mean_squared_error: 3.4619\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 111\nReplay buffer size: 100000\nTotal frame count: 126776\nEpsilon: 0.05\nTotal reward for episode: 303.2702508960517\nRunning average rewards: 336.3596089781719 \n\nEpisode: 948\nTrack generation: 1192..1494 -> 302-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.3386 - mean_squared_error: 2.0373\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3712 - mean_squared_error: 3.1244\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3545 - mean_squared_error: 2.2609\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2678 - mean_squared_error: 1.2656\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 9ms/step - loss: 0.4044 - mean_squared_error: 2.8359\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 2\nTotal frames in episode: 238\nReplay buffer size: 100000\nTotal frame count: 127014\nEpsilon: 0.05\nTotal reward for episode: 775.4318936876939\nRunning average rewards: 341.6415380233521 \n\nEpisode: 949\nTrack generation: 1139..1428 -> 289-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.5012 - mean_squared_error: 10.8580\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4541 - mean_squared_error: 3.1409\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3548 - mean_squared_error: 2.6368\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 174\nReplay buffer size: 100000\nTotal frame count: 127188\nEpsilon: 0.05\nTotal reward for episode: 277.6222222222134\nRunning average rewards: 338.4950329728472 \n\nEpisode: 950\nTrack generation: 1061..1338 -> 277-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2973 - mean_squared_error: 1.7803\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.3387 - mean_squared_error: 1.9903\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 77\nReplay buffer size: 100000\nTotal frame count: 127265\nEpsilon: 0.05\nTotal reward for episode: 110.50434782608826\nRunning average rewards: 338.62895316343673 \n\nEpisode: 951\nTrack generation: 1071..1351 -> 280-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.4904 - mean_squared_error: 4.3478\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 78\nReplay buffer size: 100000\nTotal frame count: 127343\nEpsilon: 0.05\nTotal reward for episode: 119.33763440860363\nRunning average rewards: 337.7009662116427 \n\nEpisode: 952\nTrack generation: 1187..1488 -> 301-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.3402 - mean_squared_error: 2.2100\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4026 - mean_squared_error: 4.0678\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 104\nReplay buffer size: 100000\nTotal frame count: 127447\nEpsilon: 0.05\nTotal reward for episode: 248.39999999999543\nRunning average rewards: 338.0351767379584 \n\nEpisode: 953\nTrack generation: 1177..1475 -> 298-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.4310 - mean_squared_error: 3.2849\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2668 - mean_squared_error: 2.1440\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.5609 - mean_squared_error: 5.8162\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.3902 - mean_squared_error: 2.8027\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 174\nReplay buffer size: 100000\nTotal frame count: 127621\nEpsilon: 0.05\nTotal reward for episode: 374.84444444443665\nRunning average rewards: 338.0794332629398 \n\nEpisode: 954\nTrack generation: 1021..1288 -> 267-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.3747 - mean_squared_error: 2.4958\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.2974 - mean_squared_error: 1.8152\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4167 - mean_squared_error: 3.4581\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4294 - mean_squared_error: 3.7519\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3021 - mean_squared_error: 1.6011\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 0\nTotal frames in episode: 238\nReplay buffer size: 100000\nTotal frame count: 127859\nEpsilon: 0.05\nTotal reward for episode: 856.1278195488519\nRunning average rewards: 343.9169686931551 \n\nEpisode: 955\nTrack generation: 1064..1334 -> 270-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.2991 - mean_squared_error: 1.9051\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4887 - mean_squared_error: 4.2385\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 138\nReplay buffer size: 100000\nTotal frame count: 127997\nEpsilon: 0.05\nTotal reward for episode: 316.54721189590566\nRunning average rewards: 339.8791307075847 \n\nEpisode: 956\nTrack generation: 1080..1354 -> 274-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.4597 - mean_squared_error: 5.8378\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3359 - mean_squared_error: 2.5076\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4029 - mean_squared_error: 3.1568\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 114\nReplay buffer size: 100000\nTotal frame count: 128111\nEpsilon: 0.05\nTotal reward for episode: 320.70036630036054\nRunning average rewards: 340.5050890744211 \n\nEpisode: 957\nTrack generation: 1256..1574 -> 318-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.4517 - mean_squared_error: 4.8332\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.4132 - mean_squared_error: 2.9195\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4647 - mean_squared_error: 3.4868\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3699 - mean_squared_error: 2.9515\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 45\nTotal frames in episode: 238\nReplay buffer size: 100000\nTotal frame count: 128349\nEpsilon: 0.05\nTotal reward for episode: 602.1608832807418\nRunning average rewards: 340.11368420859856 \n\nEpisode: 958\nTrack generation: 1095..1373 -> 278-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.3744 - mean_squared_error: 2.3650\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.5737 - mean_squared_error: 5.3960\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3894 - mean_squared_error: 2.7615\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3394 - mean_squared_error: 2.6716\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 159\nReplay buffer size: 100000\nTotal frame count: 128508\nEpsilon: 0.05\nTotal reward for episode: 423.7646209386181\nRunning average rewards: 339.64105264020696 \n\nEpisode: 959\nTrack generation: 1059..1328 -> 269-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.5585 - mean_squared_error: 8.3585\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.3554 - mean_squared_error: 2.4504\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 99\nReplay buffer size: 100000\nTotal frame count: 128607\nEpsilon: 0.05\nTotal reward for episode: 251.44477611939772\nRunning average rewards: 338.7524514503521 \n\nEpisode: 960\nTrack generation: 1091..1375 -> 284-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.4506 - mean_squared_error: 3.2025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4982 - mean_squared_error: 4.5908\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4597 - mean_squared_error: 5.4563\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3750 - mean_squared_error: 3.6134\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 50\nTotal frames in episode: 238\nReplay buffer size: 100000\nTotal frame count: 128845\nEpsilon: 0.05\nTotal reward for episode: 721.2544169611142\nRunning average rewards: 344.55496387393146 \n\nEpisode: 961\nTrack generation: 1203..1508 -> 305-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2941 - mean_squared_error: 1.7216\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.6344 - mean_squared_error: 6.1956\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2942 - mean_squared_error: 1.6114\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 133\nReplay buffer size: 100000\nTotal frame count: 128978\nEpsilon: 0.05\nTotal reward for episode: 259.2999999999921\nRunning average rewards: 344.20657925854687 \n\nEpisode: 962\nTrack generation: 1260..1579 -> 319-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.5488 - mean_squared_error: 5.2549\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4624 - mean_squared_error: 3.3510\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3478 - mean_squared_error: 2.2435\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 167\nReplay buffer size: 100000\nTotal frame count: 129145\nEpsilon: 0.05\nTotal reward for episode: 244.52075471697492\nRunning average rewards: 342.7494661950297 \n\nEpisode: 963\nTrack generation: 1334..1672 -> 338-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.4744 - mean_squared_error: 3.8039\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4056 - mean_squared_error: 3.3353\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.6047 - mean_squared_error: 5.1464\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.3121 - mean_squared_error: 1.7184\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 159\nReplay buffer size: 100000\nTotal frame count: 129304\nEpsilon: 0.05\nTotal reward for episode: 265.7768545994025\nRunning average rewards: 344.3214416375755 \n\nEpisode: 964\nTrack generation: 1024..1284 -> 260-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.6002 - mean_squared_error: 6.8933\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4086 - mean_squared_error: 4.2011\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 112\nReplay buffer size: 100000\nTotal frame count: 129416\nEpsilon: 0.05\nTotal reward for episode: 364.4664092664025\nRunning average rewards: 347.00582891363047 \n\nEpisode: 965\nTrack generation: 1147..1438 -> 291-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.4112 - mean_squared_error: 3.4704\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2514 - mean_squared_error: 1.2002\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 112\nReplay buffer size: 100000\nTotal frame count: 129528\nEpsilon: 0.05\nTotal reward for episode: 320.7172413793038\nRunning average rewards: 344.5655157968769 \n\nEpisode: 966\nTrack generation: 1025..1285 -> 260-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.3886 - mean_squared_error: 2.8667\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3537 - mean_squared_error: 2.6359\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3836 - mean_squared_error: 2.8206\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 143\nReplay buffer size: 100000\nTotal frame count: 129671\nEpsilon: 0.05\nTotal reward for episode: 298.01235521234673\nRunning average rewards: 344.65569340305456 \n\nEpisode: 967\nTrack generation: 1207..1513 -> 306-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.5764 - mean_squared_error: 5.0918\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3218 - mean_squared_error: 1.8861\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3477 - mean_squared_error: 1.8927\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4928 - mean_squared_error: 3.1167\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 219\nReplay buffer size: 100000\nTotal frame count: 129890\nEpsilon: 0.05\nTotal reward for episode: 338.62950819670834\nRunning average rewards: 341.8795264789428 \n\nEpisode: 968\nTrack generation: 1207..1513 -> 306-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.4528 - mean_squared_error: 3.4019\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4137 - mean_squared_error: 3.4921\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.2372 - mean_squared_error: 1.1167\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4928 - mean_squared_error: 4.2036\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4338 - mean_squared_error: 3.5545\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 30\nTotal frames in episode: 238\nReplay buffer size: 100000\nTotal frame count: 130128\nEpsilon: 0.05\nTotal reward for episode: 636.1475409835905\nRunning average rewards: 344.04630735501667 \n\nEpisode: 969\nTrack generation: 1094..1372 -> 278-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.4723 - mean_squared_error: 4.0325\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4322 - mean_squared_error: 3.5036\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 9ms/step - loss: 0.3303 - mean_squared_error: 2.3124\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.5185 - mean_squared_error: 4.0660\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 208\nReplay buffer size: 100000\nTotal frame count: 130336\nEpsilon: 0.05\nTotal reward for episode: 512.4678700360868\nRunning average rewards: 347.0128221209514 \n\nEpisode: 970\nTrack generation: 1113..1395 -> 282-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.5359 - mean_squared_error: 5.8758\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.5252 - mean_squared_error: 4.8324\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3289 - mean_squared_error: 1.8168\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 114\nReplay buffer size: 100000\nTotal frame count: 130450\nEpsilon: 0.05\nTotal reward for episode: 349.41779359430035\nRunning average rewards: 347.4666794994031 \n\nEpisode: 971\nTrack generation: 1103..1383 -> 280-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.6799 - mean_squared_error: 18.4437\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2515 - mean_squared_error: 1.4575\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.6770 - mean_squared_error: 8.1687\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 177\nReplay buffer size: 100000\nTotal frame count: 130627\nEpsilon: 0.05\nTotal reward for episode: 613.7878136200595\nRunning average rewards: 351.3799313010841 \n\nEpisode: 972\nTrack generation: 1204..1507 -> 303-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.3338 - mean_squared_error: 2.4588\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4149 - mean_squared_error: 3.4744\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.5332 - mean_squared_error: 5.0057\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 147\nReplay buffer size: 100000\nTotal frame count: 130774\nEpsilon: 0.05\nTotal reward for episode: 292.19337748343673\nRunning average rewards: 347.4317958717664 \n\nEpisode: 973\nTrack generation: 1126..1414 -> 288-tiles track\nretry to generate track (normal if there are not manyinstances of this message)\nTrack generation: 997..1255 -> 258-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.5887 - mean_squared_error: 5.2313\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 73\nReplay buffer size: 100000\nTotal frame count: 130847\nEpsilon: 0.05\nTotal reward for episode: 83.64046692607147\nRunning average rewards: 346.45310194947785 \n\nEpisode: 974\nTrack generation: 1203..1508 -> 305-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.3802 - mean_squared_error: 2.7151\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4655 - mean_squared_error: 3.5799\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3441 - mean_squared_error: 2.2292\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 134\nReplay buffer size: 100000\nTotal frame count: 130981\nEpsilon: 0.05\nTotal reward for episode: 258.8999999999925\nRunning average rewards: 346.5833140706899 \n\nEpisode: 975\nTrack generation: 1188..1489 -> 301-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.3773 - mean_squared_error: 2.7879\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3514 - mean_squared_error: 2.4826\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3694 - mean_squared_error: 2.6277\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.7245 - mean_squared_error: 9.2316\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.5586 - mean_squared_error: 5.3187\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 235\nReplay buffer size: 100000\nTotal frame count: 131216\nEpsilon: 0.05\nTotal reward for episode: 609.3333333333183\nRunning average rewards: 350.93046090884627 \n\nEpisode: 976\nTrack generation: 1121..1405 -> 284-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.3446 - mean_squared_error: 2.1232\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.5420 - mean_squared_error: 5.1238\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 94\nReplay buffer size: 100000\nTotal frame count: 131310\nEpsilon: 0.05\nTotal reward for episode: 220.3505300353339\nRunning average rewards: 351.5494467286801 \n\nEpisode: 977\nTrack generation: 1214..1522 -> 308-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.5417 - mean_squared_error: 4.7938\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4897 - mean_squared_error: 5.5512\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 124\nReplay buffer size: 100000\nTotal frame count: 131434\nEpsilon: 0.05\nTotal reward for episode: 282.64755700325316\nRunning average rewards: 350.83429071976536 \n\nEpisode: 978\nTrack generation: 1112..1394 -> 282-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2784 - mean_squared_error: 1.4173\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2840 - mean_squared_error: 1.8429\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 101\nReplay buffer size: 100000\nTotal frame count: 131535\nEpsilon: 0.05\nTotal reward for episode: 297.67829181494176\nRunning average rewards: 351.473509624074 \n\nEpisode: 979\nTrack generation: 1047..1313 -> 266-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.6010 - mean_squared_error: 6.3233\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.2945 - mean_squared_error: 2.3470\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3145 - mean_squared_error: 2.0036\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 162\nReplay buffer size: 100000\nTotal frame count: 131697\nEpsilon: 0.05\nTotal reward for episode: 388.0301886792342\nRunning average rewards: 352.2559909128598 \n\nEpisode: 980\nTrack generation: 1053..1321 -> 268-tiles track\n1/1 [==============================] - 0s 9ms/step - loss: 0.4402 - mean_squared_error: 3.2653\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 9ms/step - loss: 0.4548 - mean_squared_error: 3.8058\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4880 - mean_squared_error: 4.2220\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.3238 - mean_squared_error: 2.2458\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 8ms/step - loss: 0.2631 - mean_squared_error: 1.3343\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 13\nTotal frames in episode: 238\nReplay buffer size: 100000\nTotal frame count: 131935\nEpsilon: 0.05\nTotal reward for episode: 792.6404494381874\nRunning average rewards: 355.2042516946669 \n\nEpisode: 981\nTrack generation: 1147..1438 -> 291-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.3581 - mean_squared_error: 2.4374\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3682 - mean_squared_error: 3.0379\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4851 - mean_squared_error: 4.1971\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 142\nReplay buffer size: 100000\nTotal frame count: 132077\nEpsilon: 0.05\nTotal reward for episode: 277.68275862068083\nRunning average rewards: 356.1146944228295 \n\nEpisode: 982\nTrack generation: 1139..1428 -> 289-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.3107 - mean_squared_error: 2.0404\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3577 - mean_squared_error: 2.2018\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 111\nReplay buffer size: 100000\nTotal frame count: 132188\nEpsilon: 0.05\nTotal reward for episode: 219.4888888888883\nRunning average rewards: 355.47887908636636 \n\nEpisode: 983\nTrack generation: 840..1061 -> 221-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.4313 - mean_squared_error: 4.0711\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 9ms/step - loss: 0.4873 - mean_squared_error: 4.4289\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 100\nReplay buffer size: 100000\nTotal frame count: 132288\nEpsilon: 0.05\nTotal reward for episode: 119.09090909091108\nRunning average rewards: 354.9308040502913 \n\nEpisode: 984\nTrack generation: 1148..1439 -> 291-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.5089 - mean_squared_error: 4.6884\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.6074 - mean_squared_error: 9.6139\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3891 - mean_squared_error: 2.6970\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 113\nReplay buffer size: 100000\nTotal frame count: 132401\nEpsilon: 0.05\nTotal reward for episode: 289.282758620684\nRunning average rewards: 355.51542725693616 \n\nEpisode: 985\nTrack generation: 1092..1369 -> 277-tiles track\n1/1 [==============================] - 0s 7ms/step - loss: 0.2971 - mean_squared_error: 2.1406\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4009 - mean_squared_error: 3.5483\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4123 - mean_squared_error: 3.2906\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3084 - mean_squared_error: 1.6924\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done True, consecutive negative rewards 44\nTotal frames in episode: 238\nReplay buffer size: 100000\nTotal frame count: 132639\nEpsilon: 0.05\nTotal reward for episode: 702.1014492753492\nRunning average rewards: 360.583500573219 \n\nEpisode: 986\nTrack generation: 1091..1368 -> 277-tiles track\n1/1 [==============================] - 0s 8ms/step - loss: 0.2284 - mean_squared_error: 1.1765\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.3507 - mean_squared_error: 2.3891\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4201 - mean_squared_error: 2.7004\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - 0s 7ms/step - loss: 0.4042 - mean_squared_error: 2.4551\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEnding episode: done False, consecutive negative rewards 51\nTotal frames in episode: 182\nReplay buffer size: 100000\nTotal frame count: 132821\nEpsilon: 0.05\nTotal reward for episode: 481.54782608694563\nRunning average rewards: 364.39071653900646 \n\nEpisode: 987\nTrack generation: 1225..1535 -> 310-tiles track\n1/1 [==============================] - 0s 9ms/step - loss: 0.3609 - mean_squared_error: 2.9559\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1/1 [==============================] - ETA: 0s - loss: 0.4736 - mean_squared_error: 3.7693"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QnGgCnKxbQ6H",
        "outputId": "90133cc3-97fb-450a-f8bc-3b20da2ce8e3",
        "gather": {
          "logged": 1649481969559
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env.close()"
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1649398304905
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Analysis"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the rewards\r\n",
        "plt.figure(figsize=(8, 6))\r\n",
        "plt.title('DQN Agent')\r\n",
        "plt.plot(episode_rewards, label='Episode reward')\r\n",
        "plt.plot([np.mean(episode_rewards[::-1][i:i+100]) for i in range(len(episode_rewards))][::-1], label='Average reward (last 100 episodes)')\r\n",
        "plt.ylim((-50, 500))\r\n",
        "plt.xlabel('episode')\r\n",
        "plt.ylabel('reward')\r\n",
        "plt.legend()\r\n",
        "plt.show()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 576x432 with 1 Axes>",
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfQAAAGDCAYAAADd8eLzAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAC82UlEQVR4nOxdd9wUxfn/zt7dW3nhpbz03qWDICCCBTv23ktMjCWx9ySWaAwau8YY/dkSe+8au2IXu4hIl95f4AXecnfz+2Nv97bM7M5subcwXz/43u1OeXb3dp55OqGUQkFBQUFBQaF5Q2tsAhQUFBQUFBTCQzF0BQUFBQWFFgDF0BUUFBQUFFoAFENXUFBQUFBoAVAMXUFBQUFBoQVAMXQFBQUFBYUWAMXQFRQUFBQUWgAUQ1dQaIYghCwihGwjhGwmhFQTQj4hhJxBCNEc7XYmhLyba7eREPISIWSw5fxuhBBKCLnb0e8jQsgpPjSckut7dKQX5z3nQ4SQ6wo1n4JCc4Ji6AoKzRcHUkorAPQCMB3ApQDuN04SQiYCeBPAiwC6AugD4HsAHxNCelvG2QLgRMcxEZwMYD2AkwLSr6CgECEUQ1dQaOaglG6klL4E4GgAJxNChuVO3QjgP5TS2ymlmyml6ymlfwbwBYCrLENUA3jIccwThJBeAHYFcDqAfQghnR3nLyGErCCELCeE/DYnyffPnSsmhNxECPmVELKKEHIPIaQ0d243QshSQsiFhJDVuTFOzZ07HcDxAC4hhNQQQl6WvVcKCi0ZiqErKLQQUEq/ALAUwGRCSBmAnQE8zWj6FIC9Hcf+BuBwQsggwelOAjCTUvosgNnQGS0AgBCyL4ALAOwJoD+A3Rx9pwMYCGBU7nw3AFdazncG0CZ3/DQA/ySEtKWU3gvgUQA3UkpbUUoPFKRVQWG7gGLoCgotC8sBtMv90wCsYLRZAaDKeoBSuhLAPQD+KjjPSQAey31+DHa1+1EAHqSUzqKUbgVwtXGCEEKgS/Xn5zQGmwFcD+AYS/8GAH+llDZQSl8DUANAdKOhoLDdQjF0BYWWhW7Q7dobAGQBdGG06QJgLeP4DdDV5yO9JiCETIJuj38id+gxAMMJIaNy37sCWGLpYv1cBaAMwFc5Z75qAG/AvsFYRylNW75vBdDKiyYFBQUg2dgEKCgoRANCyDjoDP0jSukWQsinAI4E8J6j6VEA3nf2p5SuI4TcBuBan6lOBkAAfKsL3Lbj30LXAHS3HO9h+bwWwDYAQymly3zmYUGVh1RQ4EBJ6AoKzRyEkNaEkAOgS8yPUEp/yJ26DLqT3DmEkApCSNtcyNdk6GpuFm6BbnvfgTNXCfQNwenQbeDGvz8COI4QkoRuoz+VELJDzpb/F6M/pTQL4D4AtxJCOubG7EYI2UfwclcB6CvYVkFhu4Ji6AoKzRcvE0I2Q1dp/wk6Mz7VOEkp/QjAPgAOgy41r4cuRU+llP7IGpBSugm6d3w7zpyHQJew/0MpXWn8A/AAdI3fvpTS1wHcAV0zMA/AZ7m+dbm/lxrHCSGbALwNcRv5/QCG5NT1Lwj2UVDYLkAoVRosBYXtAYSQEdCZ7HGU0v8VcN4dAPwIoNhhG1dQUIgQSkJXUNhOQCn9HrqEPTynGo8NhJBDc/HmbaE7272smLmCQryIVUInhCwCsBlABkCaUjqWENIOwJMAegNYBOAoSumGXDjL7QD2h+7Vegql9OvYiFNQUIgNhJA3AEyE/u5/AOAsSikrhE5BQSEiFIKhj6WUrrUcuxHAekrpdELIZQDaUkovJYTsD92xZn8A4wHcTikdHxtxCgoKCgoKLQiNoXI/GMDDuc8PQ1cBGsf/Q3V8BqCSEMKKoVVQUFBQUFBwIG6GTgG8SQj5KpeHGQA6WVRvKwF0yn3uBnsCiqW5YwoKCgoKCgo+iDuxzC6U0mW5eNO3CCE/W09SSikhRErnn9sYnA4A5eXlOw4ePNinh4JC4fDDso0AgGFd28Cec8XdZni3NpHMmaUUs5Zvco25fOM2rKupd7XfoUtrzF6Rb9+QyeLnlZs95+jToRwL124BAHSrLMXKjbXIWMx1PdqWobIsBcB+D1ZvrsXqzXXuAS3oV1WOZRtqUZvOuM4N79YGy6q3Yf2WetsxAJi7qga16QyqWhWjfasi8xpKkgm0KU1h1eZaAMCgThUoSmpoyFD8vDJ/3QadTnRqXYJ0Jot1W9z3ztovoRFkshT9qlqhpi6NVZtqzXYdWhUjqRGstBwDgKFdW0Oz/DB+WrEJmSx7CRzQsQIlKY1LZ9+qcixYs8V2rFVxEjV1/r6H7cuL0LWy1PxuzNGnQzlWb6rDlnpx/8XubUtRmkpg7uoapBIaBneusJ3fuK0Bv67fan7v0a4MS3LfW5ek0L1dKX7K/X4NtC5JoVf7Miyr3oZWxUm0KU255jVoLkkmzN9ORXESm+vS6FpZiuXV22ztre9G9dYGLNmwFSy0Ky+y/d4AoHf7cmSylNsnqRGksxRtSlPo2a4s8nfciq+++motpbSKda5gYWuEkKuh52T+HYDdKKUrcir19ymlgwgh/859fjzXfo7Rjjfm2LFj6cyZMwtAvYKCGHpf9ioA4Odr90VJKuHZZtH0aZHMuam2ASOuftM15tUvzcJDnyxytf/qz3tix+veNtsvr96Gnae/6znHo78dj+P/73MAwLWHDMONb/yMzbX5Rf+Wo0bi0NHdQAgxr2/Odfvin+/Nxx3vzPUc+5kzJuLKF2fhpxWbXOcWTZ+GK57/AY99/qvtGADsc+uHmLNqM87YtR9OnNgLk3LXMLhzBfYb1gW3vv0LAOCDi3dDr/blWLmxFhP+/o45hkGnExfuNRDrttQz7521X2VZCtVbG/D8WTtjxty1uOWtX8x2p+3SB1UVxZj+uk2Gwaxr9kF5cV6OGnnNm9i4rYFJxxvnTcbgzq25dD5zxkQccc+ntmOTB3TAjLmsrL52nLJzb1x90FDzuzHHY78dj9vemYtvft2AhowYb7jygCEY37cdpt3xEbq3LcVHl+5hO//6Dytw5qN5/+Y7jh2Ncx7/BgCw5w4dccvRo8zfr4H9hnXGv07YkfuuZLIU/a54zUXLrgOr8MEva3DNQUNx1UuzbOesY7z47TKc+8S3zOs5bnxP2+8NAB48dRw2bWtw9SEEoBSoqijGms11mDaiC/553JjI33H7nOQrSulY1rnYVO6EkHJCSIXxGXp1px8BvAQ9uQVyf1/MfX4JwElExwQAG5VXrIKCP2T35M7mslt6lhBwwVPfYZ/bPpQcKY+ExlFneNHhQTnrnFf7MKBgP4OwspJf/ziuRr8WCsJTLwUc0/bdcWFB7hNPEKU+58XG9hhYpk8jIE6VeycAz+d+GEkAj1FK3yCEfAngKULIaQAWQ08jCQCvQfdwnwc9bO1U95AKCgouyDL0QAto/jNPRfzLqhp3H4HJKAAvfu7P2KjnAh4lwwgLP+ZmPxcLCZ6gVH++CUmGHpTWpsII7eBsFjxpbRoXEhtDp5QuAOCq2kQpXQdgKuM4BXB2XPQoKBQSTXOh0mGVVIMwLh5DDwVPBhJkgQ3fXgYRCrQm4tIoAN7PPUvlNCbWa4/jPrDgd2d8z0d8a5vK+64yxSkoxIA4F2PRubhqSSrWjocspcICiUizKBZDkTHieiKUuucn4Kj9JS62UST0nLZDxgLiq0Fx/d6s8yGWBxNmz8k0n+T+4/ZxfWgcKIauoNDMEUZSFe1rXcwyWbn5xCYIoXr2sV/LrrFxSplRrvdhGD6vK6VAhlJpnwYZWqLY7Ma52eGNLbZpbFyOrhi6gkIMKKR0xV2cucfliDM8eQ1kqfgIQougTyPuAitIg+g81vnkxg7hgOVDh2ffGH5kFEA2CyQ0cdZgU7nDfyNg31B6S75BEfW98WPyTaXImWLoCgoxoGm83mw4pVe/tci5RGc99Jmn/ydgGGkBjK+FXnPDer43hrRHKUWWUiQkOYNMxEEkJpY4/QskfDaMn21Ted8VQ1dQaOYQtZUbi09WckV1hjBlPPq/+dMq2/wiC6+/Rt3bR8BvUyIrPRXKsQuA58XHGbbmNXaWUiQlJPQwiIsR+v3GPTcgAYhqIgK6YugKCnGgkCo4WdW6U+UpO0c26x0m1hQQF7PjtXfea+6mQEpC9583alDoDmWy/FxO8xC8byHAIkfUDNPY16IYuoJCDHAywPfnrI4vtlnQiSeo4On0j/KS0P1oCNJGxIYupAmQYToxLcwyqmJf34JQtnv+Tc1S+Th0z7mo8zvlngs6pnPsUA6DPmPLnCv0xlcxdAWFmPHo54txyoNf4qXvlhd0XudSYqjOZT3ACYhtYRL1co/KzukvqfoxPjnI8rK4lmzfcWOR0CnSGYqipBxrkCGFcj5HiUILylwtWYEJUQxdQSEGWF/kJRv0IhErN9ZyWoecS9CJx+BTsjZ0fQ7ruBJSplCb8KtecwgpAhjSqkRb1/kI6bCiIZOVZ+i5AYMI9lE+FdamlTmnl+8CK38A+Kp4z+/eZEQOxdAVFOJAId9k7lxsu66dOQswQ6fKPRsxawy6+AawdRcS4dWtPpqHOCR0mmPosm7uHnjYWeQmgA+HKPKOkmF07tH1CbJ5DgPF0BUUmjlk1X3SXt+O76I2dKHNAoJ7udvmYR0MATlbt8y44vDLdhZP/DZQn84iJcHQ9ax4fMxcvME+hyuMLYDGKIQEHgTUxyuOd0oxdAWFFoCw+dIjocGlcs+pI61tBJgCcazYupd7ePpMGoI6RkmOX8inwKtWFmXq11gyxQFIZ+Vt6AaicqUraOigA/x7E8QpLgKCJKAYuoJCDChopjiuwzLbiO4qX+nD6pzZv6S83KNgoyJSvgBN8UUZBF/Mg3hOm+f9h5cGpRQNmSyKpW3owdqKRmi4zvtqbYLfnUAaA/OvU/sQmIxAUAxdQSFmRFlbmgVZp7j/m7GQ24YFQuxziHu5i7YLqx5vfIgu3DK0+poiQjEt+3erf0VDhqI4mZAd0fz07FdLceFT3/E3OrbP8bgqRq3doD59eOcKrXKPsx66gsJ2i4L6xHEldDae+HKJ1PjO7YgUI4lRQLfFM3v2ocw2nnMWRrEQzss9hh9ZQ263FljlTggufPo7AMCzXy/F51e4KmULbyLDIMytifK2FnqzqSR0BYUY0BQyqTmlA41r1/Uex5X6NeJ66P6MS0SdHn6eoIhro+CrVo6BbRkMPZWIptrawrVbGDNb/UvkxhM9HwayG2T9HGX2VU5xCgotDHEzd74Ea/8eVOohjrEyVExRqlfSig+m3bLx904u8DO/ihN7/4yF6H3Zq9zzUV63QW99Wl5CD2tSisPBMmqHQb+IjaAbk6ihGLqCQgworMqdPVtc0kHkXu4hz/u1ytMal1Oc3HFRvPPz6kDzBoHBlE2GnpCzoQfVUvCuwW+PwJsvaAEi29hh+kY4VhAohq6gEAPCejhHMZdTM85aI33Ca/V+rlzuopSJX6PX+h2EYbLOid5uQkh8GzLHwHGEnvmhY0Uxd9763MMNakMXgdvfIbq7HYdzotHDu0QsGxFbp3yhGLqCQoFQ6Nhap5QSVDVKCLEtlKLSj7CXe0jVPEW0GoPmgqAbQq+fQRCVu05LIFICM3O+B728A6R7jOg6KQldQaEFIOrqX4FocDJ0VpsAy1dWQuwolLe4SP+4bjdPduPlBI9u3hB9LZ0Xr9tiOjoaTnHyceh6f6EtozU6IbaHEr3qw1MjxOmkJHQFhZaAAr7IXJW7aLy4z+Knx6HnEbmXu995H2lMZAx9HEF6YtxpResAFlBCd7DdXf/xvvk5b0OPhjUwTR++B4y+8iruuLIC+pmmeM54hS4IpBi6gkKBEF/YlKBTHEN8EooJhn1xzQqqyEXs8x6k5cYovKbDz6PZ3SHEXCE6hxNC2Z2DxqEHdooTbCc7tlff2oaMuXFhjtEINv2ooBLLKCjEACGGFzMNIk5xImDGoRdId+y1KfDylmbFOhdUWiI86TRCZiFDjoUeLxt6XQAb+g1v/Iz7Tx6XG9w9rxOimoWwfhU8DP7LG959eVoFIY2BvY3KFKeg0ALAeo/jcorje4H7O8X9vHIz5q+u8Rzf2UtG4y7k7e+x/Ea6b4jNAzo4QknZMfTNJ5YRZ+hb6zPYuK0hICFeGzYPBupz7YWWjM2yrc6NpZLQFRQUZMBbM9xe7u42h//rE9/xnTZ0YalD2GbtdU5MG1AoNSmLyQRVN4eFzDVbC+Z57SuNZ5vU5HafvN+EkA2dgyC3KhIvd94G2XNeNlSmOAWFFgDRTGqRzMVNLBPJ8HCyABmnOFFvf884dMcYPGlIZB4Dlz/3vV9rucFjGcEbcXhQG46Ustok4zchkvffbkMPGHIYo4TOjE4Q9KtwNlGZ4hQUWgCaQly0aC53PxCHPTiTjatGlhvC0pyHqjMvteUPPv4Fv0CNd91rsWNOT/L82I0Dp7nFT6JMSErovE1eHJKySJ9COxvmnfGcm8/AZASCYugKCs0cIk5jQAinuID9RKWvm96c43kNhbZLBpMYHQs554rcteiDQ0bDY32GXgmGjBFlN39yWhvLZy/zhtfGind/WZNEBKGIC8d3pXJXUGgBEHmNo3rVuXHoMS0mUY/688rNHnO5NwVutabYxkHmdgSxo4aaMADicIozfjOSAjoyMjZ0a2IZeG1+5Giw9Q3eldk3cEa7EHQEgWLoCgoxoLApH3k2dH+nOBHo0lq8qkR+HDrrGLX99YO0rd1zLJZTnPsYV+XeWE5xgs8+H9om6RTHVbl70xj0PeF246i+oxhbaJPuaKQkdAUFhUjgXmOjsaFH4b0uA5dTXNA2QQ3yEeLt2aswa/nGSMaKI7FMXkKX+62kOQyddVg4SCKILTsmmTi4U5xi6AoKzR5hVcCzV2xCXToTai53HLrQcP7zSSybhVjQGlsXIiPRXfPyT5h2x0fejURpkehr1Rh4/Q4MBiytcje83J3Odz5EUnjdv8I6tllnDj6vcopTUFCwYPWmWux3+wz8+fkfhdrz1oyowpoKXCTOBi+nOGHnKrO9oIreZzwD1vtSaFup9JzCKvechB6jlzsrix+bFo9zPvSEczaMbkxVnEVBoYVBdpe+tV6XzD9fuD7U+C4buhwZ+X4uqUusH0V4RsfSBgQvuRm+nT0cjg+XmYI3Xog7FMo+y9Xq6H9lVe4ytPg5OfodFxk7att10NFUcRYFhRaAMIu5kUfbSMMZFK5c7iFE7QAm9NiQj/m1/20sUATbLDVksmjIFIZ4e9gav11QL/c0J7EM68ci+lvyTv3KPlcdNAWtdewA9OTb6H+N+yda8TAqKIauoBADwuzMkwl9NfCqCCU0l0tCj8YpTsYuHpbZCjsjcdTyQP7+CNv9w8Q/S+DIez4N0CvkpD5dX/9xJQB5Cf3tn1Yxj4eRlIP0nJerSxAupC8MzXZfAuXlrqCgAACoF5TQ+Sp3+/egErqzn25jFpFWwi9mcqzYZyyZjYjEnCL12ln4dkm18BwsyDAL6zMU2djJ/lZmLt7APO6bWY9S/v0LYUMPA7bjo9yMjeV3ohi6gkIMsL7/vMXRb40QltAFbehBwWIAUUi7Qv1Zcd8OJzcq5XcvMqfYucZ0FgTkmJrzGfoxqKBpgp3wc4qT7iw6bxxx6BKaIuP2KQldQaEFwCGEBOosKqHzEF09dHHP5KhBGfPJMm+WV7zfnFG2iwtBn4MIr5bN5c4bWyRsjX/Oy4buTUdjPRuTocNQuRd2fsXQFRRiQCTqZmFBhqeydNjQgxZncc0nBhYzDgLnECxnOBGmH9dGhO9EFc98+XnjmyAgP3eBrb72/u53XGjeGPwLhCoHmjZ0gw4loSsobNeQFuhjVrl7zREVZMwSPAYfFUQd8bxoKIQ6XiqxDMMPwrt9RCp3P0k6tk1WGJW7vE3fibzKPTAZgaAYuoJCDIjqPZ67ajNqG8QyxjkRlVOcy54q5Vwm2I4vFnk4ncnOI9qK3465SWok/W4Q6e/YnXoKbTaisqGHuTlB1fFAPJs8mXZ5nwUloSsoNHtEpS7c69YPcfEz3wcaJzIJnbG2BwklCwK26jzYwFHQY90k+cV2N7aN3Qrj2v92yDDbdx4iU7kzvdwt/hicu0RAQoaPRQ+RMY02SkJXUGjhcHsai/X7fME6z/OiNsjGSCwTiw2d8d21+IeZ19PLnTKbNUZyGyfz8ENSI9A0IqRODyqhu37jjDaiSZc8m8Woyg/1LE0JXQevCl1cUAxdQSEWFO5F9qucZSBwYhk4GFkMl+ZlQ+c5UUnbuSXa8doyq4cxWkemsfZAlpedjQGRanRWRKVyZ2mJnBuhOJzion7/KKikDZ3EQIU/FENXUIgBYVK/Oo/7ra2iTnHBE8sE60g9WaOjLW9RF57Lf+xItAWWQbzuShDHOmlaDDoEng+l+ecvZEOPkTN4RScYICDeYWsSc8hC9L30amNK6MrLXUGhZaLQhRqiyiPtDlsroPaBMmaj9g/RO0B5OcWx2kc7vyjyDljRI7DKXdJ/Moxa3bMrV+oXYMohnjGlwOJ1W/L3ocC/jWRhp1NQ2D4QygwXkSrZuXhFlv1Lgr6wzI5lHw8aYy7qZOXVTFTiIgSxL+ZSvgzO776Z4qTJEZpXP2Y13/Ct5SJaF1mEMWmLzDlz8Qbs+o/3I5kvCJSErqAQA1gvf1CnOP9YXp4N3Tl/MGSCrp4yjF9mWCFzhvUzjWwOK0NnzQGfY1HCeO5C+zRq+f0JtI8uDj3Y5kumHbMv597z6rZHNa8TSuWuoLCdQ3YJ4DtwRbOYZLN2h6BYJHSJZB7UdU7cVi9Eise5cx//1t2+0VXueebLY8SyTnGRRaF7PD+vNnq74Dc2TLKlKLMMtjinOEJIghDyDSHkldz3PoSQzwkh8wghTxJCinLHi3Pf5+XO946bNgWFuFAIO/PqTbW45JnvuEVcolL3ZRxq0TiujGs2iJJRRyAZfmoJIbTFoTOD9cXmCwrz3limFslyJsKso5LQmRCMmPA855dYJsCYfggSF98SJfRzAcy2fL8BwK2U0v4ANgA4LXf8NAAbcsdvzbVTUGhWyOdw9m8ravvm4ZqXf8JTM5fiLU4tatc4AdfooM51utwc3ojuDltzq9BFGENcmyzWdQYNEZSaV9YpztrQ51ZElyfOj/Hyz8fhhyJiPooyGWCLyuVOCOkOYBqA/8t9JwD2APBMrsnDAA7JfT449x2581NJrNtEBYXmDdM2LKheDGxDd4j6cSxSMtKYiMo2XJaxaMuxxgUWhXyVu38b+zjBaHLN68McKQ22sfX3nuf5lYio3IPNGVWfMIhbQr8NwCUAjD1+ewDVlNJ07vtSAN1yn7sBWAIAufMbc+1tIIScTgiZSQiZuWbNmhhJV1AIjkJkqvKTPN253IOt0mHUhsLXIuHpnI8rlzQDROyM5dcs7rXclNCFVO7UIaBTz/ZRaRj8wvy87lEUGdtchyMK5RRFi/FyJ4QcAGA1pfSrKMellN5LKR1LKR1bVVUV5dAKCqGRDz8VUe3F+7Y7GXHQUKQslcuSZSAK5zlWghbpeuiOv1GhemuDPm4jecXlk5jIPVgbY+eQHpWEzs4UZ7WhB7t3QTdTQhEbHI1PEEoL/duIMw59EoCDCCH7AygB0BrA7QAqCSHJnBTeHcCyXPtlAHoAWEoISQJoA8A7ibWCwnYMP3u924QebJV2qtxlJPawy5loys3G8jRvTLAkdBGVu8jxoHDO78fQqECbIOCHcoqo3P0dC4XpkO8SCrFJ6JTSyyml3SmlvQEcA+BdSunxAN4DcESu2ckAXsx9fin3Hbnz79LG2voqKISEqFoxDqyrqcOS9VsjS/06pmfbCKjyhuimRD9o+5OT4p12fvE53O08DLsccqK24wvNa8ShC8xJqVM17z12dBI6m5b8F35fb0dH/40Cm55gTnFBUWgO1hiZ4i4F8AQh5DoA3wC4P3f8fgD/JYTMA7Ae+iZAQaFZgRAi/BaLOt/4qhcdHXae/i7q0lmUpOz79aA29OKUFigOXaaghactVTKGWnSc5o68hC6pchewuUeXWIZxzPGZrz2I3nfjiud+9O/LORZQ6R6gT3AUhKFTSt8H8H7u8wIAOzHa1AI4shD0KCg0V8xZuRnzVtdg2ogu3EWrLheXHlHUmj4W53NU4EqWzLb2v7x2fmNz20u1ZqMQ8TkGnfa67GIT5x0q2QhKvrOfn0S8cO0WTL35A+a5UI6lnONvz2aHeMaF7UFCV1Bo8Qi3GDlU5ZbP+9z2IQBg2ohp0jQEraAV5bXIz+0v5YvOEdfiKmUuiGNeQe5r+FBYfSnidooLlfrVc1z5eUXB7Eu3cxu6gsL2CDkvd7ExuVJUbjJeaEx9xh6jE1UoUiFdW1jm7MDFWULMKYtC3KJQKmmfvrGGrQlvwBrHRBKlA2FLi0NXUFDIQVTq2bitQaid7GIRVOpiOZ2J9os69tvaVrh6mvjQufbNw9Zu2tAl+9ls6JxrjTNsTRRhnkJTeYKF/i0phq6gEAOCelm//N1yHHTXx3JzCS4akTk6RTJK8AldEjsV1YjERbm4/T+OWUWfK6sZV+XuMU53sga9yQomRc45mNqjGDZ57r7ROtTRoDr3AkPZ0BUUYoDQq89o9NHctVGTYiIqpzjZkC6xdhymyGDWrFzu7j4haAmokSg4jLC1AA/W9/I8xvyo+FwAQO/ax9ANa7AMVUgijfeKLsSGTZ1wEK6wzMMwj4hTyTy6cO0W7H7T+949Y3CoCzSWcopTUGi+aIzqA6KLRlDa3pi1Elvq0/4NHZBZy7iOZcLiXP6j5kiJZ44dgTMWs72gnT9qGNJvHD85ERv6Dcl7cXTyfQDAK5kJ6KGtQY/0GlRiM6pRAYCnqQrnxPhOgT3VDQSyoUdOhTeUyl1BIQYElfACSVuC7bQQu40ZFs2BHKMOZ+dmpn51MGjr6TalKSHP+EIgdi93SXbBKrYm6+XeARvNzwYzB4ADEp+Zn0dp88zPzNSvMW2sgswh2pn1OxQbStnQFRSaPVivsXORNBbkZ79ainmrN+vHAi0a+c/VW+u57YLmcnfPV9hFSmS2vD3Zq004ybCpIXhiGUvYGs8pLvf3QO0TnJ542Tx+bvJZ3/FHa/PNz2GKk/A3G/7Xy3PGSwq8BM3k8TOhGLqCQoQIEu5z4dPfYc9bPoxk/t8+PJN7rhA1uq2QKWgRJLEMCxohjPPUt5+zvZQWgnXMZ4ClG7ZKzOA9r+hTtTFyav/LatsaW3Bn0V24IvU4dtO+xWgyF8cn3sHcbDezXd/aRzCo9iE8mp6Ku9MHAQDOTT6HSugbVHZxFh1tUINS1HLp9dtsBMG0EV182/Cy2wUxo6iwNQWFFoA4XuSNW3nhbHnnqDkrN3P7R5YsJJphhMbc/ab38eOyjY62dqc4qzo0oRGxiloFgBcDOPXBL8OPb0rocv1EmhMAO2k/m9/vS92MU5L/g0YoTqq/DADwamYnZKGhDkX4U/o03Jg+Bq8X7wsAGKotAgB03fAlRpO5TLq/KzkdrxddjquTD6E1alw0xOHYJnLtUfo/qLA1BYUWAf8XWdiWmGt33pPfMM8//sUS83NDNv6Cz0Fixv0b8k8ZqWxFkNQIslkaOPmMTLug7QFga31GvpNr3vDMgjeCVrcRV6cexnLaDmfVnwMK4ODEJwCAFWiHYbX/h/Ma/uDq99+yEwEAjxb9HQdpH+PQ78/A88VX2STxNTV16IT1AIDe2iqcknwTZyVfwgtFf8YIklfXh8lix3ey9AfvFQprDisEFENXUIgSlpKmD328EBu28G3aMkhnsnhvzhrfqZ2lTq0otNwad6pVK0MzGHhCI0g77oFf3nLe+GHhNU6UzFg4yoHRm0dH8Zf/Qlesw1n15+G17ARMqbvNNlINytDACJLarFXi9vShAIA7iv5pHp9d8huTWb/83XKb9A8AQ8hijNIW4JGi68UuxhccE47AveKZUAJ5uSuGrqDQ/PHDso24+uWfcNHT33HbyLzrL323XKhdQ8aLi0hM6AEZNWIEArpvWys9SY14bmqE5wgppRdiHQ+6KZjU8DE6NOiJYXgjJFZ/j9m0J76l/QEAK9Eez2Z2wSPpqb7j35rO19h6ZdDfzc//V3QzAIAgi5OSb6KGluCE+ssBAMO0hQCA1mQb2mETQMLZ0Fm35vlvloo5WDYRk00QqDh0BYUYUNug6+2qBdO4+iECHtWkU5rKLKJeBT8SGjHvfdA5npy5RMou3Vj3NZANffMq/Knm7/i1vh+Ag7gbF23Tciyn7W3HLmw4S3iaY+v/hAaawM7tp+L39efj30W3oiOpRn+yFMcn3sE47RfckT4EH2WHYxWtRCdSbfY9OvE+fqWDIrehX/nCLOw6qMq3L89DXpaeMtSCZPhOf3FAMXQFhQgR1u+Mxxyctc0B9wIjU4s9DORs6IKhYjLze/RJJTSks+wkOFJzSDR+6ONFGN2zUmJ0YPnG8Au9rModBMAvbwAAetbPB2rWAIlKZlNt8zKsoOMC0/ZpdigAYAIF/pcdh93rbsabRZfg0uST2CvxFQDgXzmveAPLaTtQEPTXluJXr8sQ2MGwfnfprNjWi7V5fmrmEqzbUufZ77jEOxhOFmCvxFf4b3ov/CH5AtZ9sROw0xsCs0YDpXJXUIgBUecWL0kmQo9XCNtwo8Bi30xoBBmHV1Pc5M5cvAEPfbIo5lnckC7OgyzwzSP5Azf1R9HM+/TjFpSiFqS2GitpO2ma3LncdSIX0i54PLOHyczPqT8b21ACAFhNKwEAZ9WfhyzVcHjiI/Som8O8vnQmi6temuVLB+vWZLJihnDWe/TtkmosWb/Nc8brU/fj2OR76EA24fzUs0iRDDqv/bSgL4xi6AoKMSIqe1xJys3QhQphWGmJhBI5BHVE23UgXzVavbUe81bX2PoY99nLhh7nuur0XSjEGi6r6t8Bi4ClX+QPFFWg9J3LcZD2ia1dF6J7oDtV7kFgpfDhzN7m50+zQ8zP5zb8Af9J74UfaB/00HTHz0nVrzKvr6ZOLAUx6/5nKDv6QaSvH9ohHy56e/pQpKmFta78Xn7AgFAMXUEhQhCLl7uBKBZ3EZW7H6LaXITNxc1sa1loF02fhqPG9uC2Pfxfn2LPWz5gnkvkGDpr7pe/F3MsjApxOlclkMHoNS+hBN5qYCuqsAEAcE3FVbimy93A2Z8DAMY7PM67kHUAgBURMHSrPXo+7Yaj6v6Ck+svxRq0NY8voF1xZfpUZJDAH+r/CACo10pAKVCCOgwnC4C0fp1h0sbyfhdeNIuiH9F/W6fUX4Jb00di//q/Y6fafyKjFQE/PC09XlAohq6gECO87H0yy0YUpU+jYi9S44guwC5/APv3IWQRupPVjqGpOYXRPalp3LC1V79nlfxsnjgj8TIO+nU6Dk/MEO4zBbq6e3GiNxYVDQDadEND791wXPJdjCG/mO26Ggwd8ip3J5zP9Qu6Az7IjuS2fyU7EfOzXdA2vRqUUjxbdDVeLv4z8PSp+ngR08NCEAfUvpr+25pHuwIAfqE9sBptsbmsJ7BuvlfXSKEYuoJCjKDUXSM64EjhR2hqtm8LXAzd9jmL14qvwEfF59nsvSzVejJB0JDJYlNtNNEFBtpjI05IvOWyN/MQt+f7EQldQ1ECsTwHXbAOR+FtAMCmRBvzeKZNLwDAc8VXw/iNTdR+Ai1uHY2EHoA7Lqad0K1uPkrWzcJQbbF+cM6rwOuXgQomTuKnEhZQuUs8O4Isrko+jBtS96GOprCcdrCd31zeC1g3j9M7eiiGrqAQIYx86Y0RyzqoU0VB5hFXe4rZLFmwboIGkqXm53FkjvnZZre2hK1lKfDc18sCzcvD80VX4rrUgxhOFgr3CfoLOHsE8H7R+dhP+xxJuG3G/cgy9NH0EqIdiD0trnUjdFLif7gs+RheLroCn5b80TxeT4pN2ur77mUeH5lL/DJZ+x7ZgfszE8f4wbl3DSLtfpUdiE4NSzH4xWmopSkcXfcX/cTn/wKpEdOycDPFiUjoEskWd9O+w6nJ/wEAvqd9kHWw1M1lPYFtG+QGDQHF0BUUYoBIJSypYiECbUuLvD3hm7CA7toAdV38Ip4qugYEWfQm+frX5yaf8+xrraZlSNNhNlcjyTx0wnr0zDlrGbbSOLHzumfRW1uFfxXdjnklJyEBe5rYIxIfIk01NJAidLTEbwP6Mz498TLuTt2Gv6YexhnJVzA8l1cdALD/TTamW99vb5Nhvlh8JfqRZagim0C78NXiMghij346syvWoRKLsx1xbsMf8DndAdj5HABAYvVPQmNsqQ8euij6e0kggwnaT6inCZxdfw5+X3+Bq813A/8IXDQX0ArDalUcuoJCjJCtzR2rYB+VU5xMpriATkwjvrwU0IBdtB/Rjei12J9M74YjEh+gFLVmyJOTpkRu4dyJzMZTxddiKe2A5dmPhem1oh9ZhheLr7Qd66utgKDWPTB6bJuNdbQC7YnuOd2LrMIC2hVV2IBTk//DCYm38V52NAaXb0XV5moAwAgyH5O0WThqxVfok5rLH3yn3wFffGR7Ll/QQVhLW6MD2YR3ii8GANCuOwJYG9MVemM12mKf5P9hbY3FnDDlIuCTO5FY+Q2A0b5jbOIkdIrChv6/okswIzscRyU+QGuyFe9lRuLV7AT2WFoyuqpIAlAMXUEhQphe7tGO2qSk6ziKnNja1m8xP/63aLr5+e3sGBydfB8jtQX4zBL2ZIUuoVNcm3oQANCdrMW6miUAOjPbDya/Ym9tJu7IHAqnwrinwwlvEy1DX1EJnQbbPxFk0XnbfPwnswfey47Co0V/x+8Sr6ItqcE2FOHQhL45ubrhJNybfAZVZBE0msFLxTm1NMd14KKG36OuqC3uBGwMRs9RruE39RebY5xYfxke6DEOwOsBLsB+D4NI6EyUtAG6jkbpj4+jFQahBmWezTdu44W3hbOht8MmDNKWYpCmm4FmZ3vggoYz+WMV+MVVKncFhRggVgSCCqr3xKR8vyaNEocuYW838dZVzDafZodgKy3GNO0zR199niTS+P2qq3Fb6p/mggsAqa2rwUIPsgpvFF+GC1LP4Ivis13nOxE9zOvWhsNxT/pArKRtMS3xBSZq/olNgmCiNgsLS05AEa3DItoZX2UHop4mcGzyPeyb+NJk5ifWX4ZlqEJNsh120JbgKvpP11graDv8mO1tfn8msytmkB3N79T8q3+aRfNtZ2RHhM54aCAyhg4Aky9AYvNSvFd8IXoTb1s6zykyqITelyxHD7IKu2g/mMe20SLsX/93bEBr7liFfueUhK6gsJ0gskxx0Qxjg7GInpT4H/Dlw9ha3gNnbjgOq2kl7kzdif9lx6IGZfgu2w+DtXxi0HLks3f1IGswuuZDjM65Evyx/g+4s+guDHnzOGBnu/MYAEzWfjQ/dyTVqMRm/CX1CKY3HIs1qMRvErqE+s/MwUgjie6p1RiIZdhT+9pMbRolHi/6m/l5Ge2AWhTjs+wQTEnkmchD6b0xIzsCAEBytvUD6IcAgAwluLbzHei87E1MTx8DgGBf7QusoW1y7WH7C8B8mBkkcGTdlViNSr1NRGri4DUIGPPvcCDqO41C1apvcXHySZzdcB63dz2n5G5QG/q7xRcBAGbRvuaxRbQTqJ9MXGARXTF0BYUIYSxDonZmcfV1BGFrEbFiUVIWrtuCN2atFB5zDPkFf009DHQZhU92fgQfPKpn2Nqz/iaz3Uq0xbhczHQPsgozis/HY9WXgNLfoiOqzXbPZXbBW9m8RIrqfM14Ax1zEvi/0gfizOTLOCP5Mg5PzMAmWobr08djoKZ7yqdzy+QlDb/HAYnPkRWUX633uxPWY+/ETDyf2YWpLh5PZtu+/5TVw8nOajgXO2dm4ePsMLQnm7CE5jPoNaDI/LyKVmJC3V2YUtwJD6Xz4WZvZHcSohUAvqSDzc9RSehBf7e8/cSaQx5Du3tGYaL2E9qgBhvRKnJ6KAV2077FGtoGJajHA0X/MM8NJQvwTseT8fLScptWgzuWFHXhoVTuCgoxQFCTHhjzVtdIT1poe96pD34p0ZpiqOGNvc/1QKKI2WoVbYfuZA2uT/4fDtF0FfRxK29Eqm6DGZt9Vv05uKbhJNSiGJc3nKZ3XP61a6yuWIeVtC1+zupZ6c5IvgIAODbxLgbkQuWmNxxjtt+KEizOdnR5lrOvxo5Tk2/g2tRDpm3fCYP28+rPwpUjZ2BVLqlLDcrwZnYctqAUvzokwv91+i3eyYzGYnTBafUXgUKTSLWbT8rDQlAB3RW2FrEDYba4LY6r/xPakRrsnZgp3d/v/lShGllK8VDRjXi1+E/YRfsRbchWW5sFrcbghewumEu7+8+nbOgKCtsPhBdgx/c9b/kAc1dvZraNH+FWqSTSeLboKuyh5ZkspbrNOk01oOdELkNZkSsYclzyXVyYesY8PurD03BkUlc9f5wdZkpur2bG6w02LoUTPcgaLKMdsIjaHeaKkMZFyacAwHVuDSptmgBR9Ce6tG+1wVoxTFuEtzOj8UJ2F+EQp21aK5zWcDEOTdyJHy2qYB4MNbr13vIYTlQq98B5CDjHM1mKb2h/rKetbDkJhOnxIGeq9hW+LDkLO2W/yx9L6L/RqxpOxlPpXQEAi8pHSMxXWI6uGLqCQoQwFkJZScn8LjHX6k3iebz1uaSaxzJOe2zE4YkZ2FGbi1tS/zKdm7KUoiOqsQaVgKZxGfocys7x3mZD3h6+EeXm500oRyZZzlS599WWY0G2C36yqE4PqrsWb2THYY/EtwCADdSerGcx7Yh+mpin+6K1ecnOiF+vIpswgrhTgXYg1VglWd3MdGwL8UDizmgX3IbOG48CIJhLu6OnxnZ29IIXOaM0/bncjJvNYyM0PZHQw5l9cHn6t5iAh5ElqUjmiwOKoSsoNBJkXnbWmu1kek3Ry92JG1P34obUfQCASrIF7xdfiAnaT6igm3FU8gOsypXS5OGHbB/b92pajsc7XWR+v2eHh+FMHFtX3g2oXmzr1xVr0YlUYz7tigYkcVXDyTix/jJ8T/vhvewos9062Bn6j9k+6EiqMZbYC5o4MXvFJnw0z4jjpuhK1pt2cafaPYEM2mMz1sDuvOYH1m9ChLkXLio6uJc7b0NnbBDW0DaoCqAp8bo/xbmYv1Y5R8u70wdhdrYn7kkfAEB3HNyKUuk5CwnF0BUU4oDAQnbnu3NdVcNkFltNk1uaI6u2FqLviJwU9GFmuHns1MQb2Jt+CgB4NLMngHwKXSe2oBS/K74JO9feAQBYQLvgu1a7oLakCk+md8OG1oNcfba16Qus0RlwN6zBZO17fFKiZx57JzsGgC6BGd7jMyy0OaXm/2XGYT1thetT97syuFmxeF1eOm+DLSgmDXg2MxlbaLErPWh7bIJGKNbkNjOi6m7Z52kd1egat0Y46Pi8529c8xpaiSqLLwNBFu8UXYjjE28HmxBAH7ICa2hrPEyn4fKG03Bz+kjsV/93TE8fZ7ZJJfjaIza9gckJBMXQFRQiRN7L3R+PfPYrFq2zO9zw+sWtGo0fFOPJbFSRTbi54Qic3XAuHkzvg1cy47Gr9h3G4CesopV4OqPbKb12NvNTA7AcHXBU3V/w+/oLsCVZifemzcCl6dORYtift1QOAtYvRDtswrvFF5rJatbQNkzHppVoj/9L74cbG47GZodH+nJ0wKUNp2OgtgwHaPompA1qsK+WrzPeh6zApXV3oDtZjQuTT6E70dPGrqJt8UZ2nI0RDSGL8EWJHgO/zFHYww9BfxHWDUPcv6pI49CRl9BX07ZoTbahNbYggQzGkTnop63A31IP4IzESyjiZNjhkVOEBkzUfsKbmXGYnj0Jj2emIoMEnD/EZEJyEy3VOjxU2JqCQhMHpWCuDM6lpVDSgKxkeGHyKfwx+QIAPVb64cze2IwyXJM+GftoX+CAxOfYHx9jFu0F46q8lk1DM/EF3SFPU+4va8Fd32NP9Pzxn/i/optQTPIZxI6r/xN3juvSJ3LPvZXdERtpGcZrP+PF7C54uOgGjNLmY0rdrfiVdsQTRdeiU6Ya04rfBQC0g+68uIq2xQraHt3JWuxEZuMLugN2177VaaSt8Ekutl1UAmRVm5P9DXg9y8qyFKq3hqtaF9SGzle56wP+SjsCAL4v+Z2rzWWpJ6CB4u7Mwa5zrI1xD7IKU7Vv0IrU4q3sGGQ1PtEa4ekO2Ci0U5xi6AoKMaAQ77Em6Ykcd2KZYtSjHklbaFUCGZOZA8D72VHYZIkd/ig7HJ9nB2O89jP6kHzMuoyXNaXUXOhTCbeEvrXtEGDsbzDmi3vNY9Pq/iYUdsQGwXfZfjg88SHKSa3pTDVem41W2W3o5AhrM0LSFtHOqMmU4g/JF/FU8bV4LzMSHUk1NtFSTKm7DfVI5UYXu/YM44F6aXJs3u1GLXmP38TO/drjtR/E8giw5tDHj1pC18f7jvbzbDdCWwCWRcRJTitsxYzi8wEAW2kxPs0OBfXQWxfS/yAIlMpdQSFKmLnc8ytHFOpy1giykUVxqu13JHMwp+QUnJaw5//uTewMYaEjDGwLSnF0/V/wHt0RFzacITQXS41rSIIpnkq0Yz73+8TaOzGL9mG3E8S3tB+KSRoHJz4xj/0jdS+G5Op3n6tdgVPq9UInxSSNpbQD1qASs2kvnFP/B7yeGYcJ2mwM1RajNdlmSzYj+lyD1BoHxJnSLUeNgqSbhgvBbeje4y31MU/wcu476dk3kc+VcEP6GNShyHMTQghRNnQFBYXo4ZRi/Rh2nGFrByT0/Op/Tj2KGUXnYkbRuehFVprx3Pel9weg17p2g+Bseglez463HPEigEUTX0IHALTLM/AVaM9uI4Fvs/3Nzzc2HGV+vjr5MABgFvrh/exobKK6V/R/0/m64y9ld8aZDefjiPqrAQDfWMYCxBkua2Pj/YztRVn8UJJKYGK/cPfq1R/E6pc7wdPQ5K+Z4ML6M/BYenecUX8eAODjzFBc3XASZmd7oi9Zwawl73xHdiI/Yy1tjd61j+LhzD65OXxok5DTC+37olTuCgox4N2fdUcoPWpWRn0sfryx1H8sRjJGy5fs7JGrHf5Bcb4+9E3po/BqZgK+pf1dfQH39XlJQc75qeVYksHQKQB0H4eXspPxVHoX/sASMKq9ZSjB3ZlDcElK37i0IrWoo0msp60AZDAr2wcTEz/hscxU1xizaG+Mqv030vCuY89DJpeFzXo3RBi1SGIZs63kryzu36TVb+DZ7BQ8m52CUtTijcw4XJ8+Dr/STtiKYtyYug9nJF7GT7QXrk09iLvSh+DxzFRQCuytfYlaFGEEWYAJ2k+5TIF5yqN05Cu0hK4YuoJChDCWhdkrNsU/l2X1TAjoRuNaW3YgizFSW4C70wdBA8UZyZddbepQxGXmOm126rwYCes6jBSjSd59KCrH3e0uwc8rNyOhEaZDmQy2ogS/rz8fS3O51WdmB2KspueY/192HNK5h3NWwznonV7l8pY3UO2IcwckVO6SNnRbOyNsLeJfRfxe8+5j21CCMxrON78vyTnMXZR62jz299T96Ew24MfMkbg99U+Uknyt9YXt9wCW5cfz3eTIqNzFm0YCxdAVFGJEZEUuGEuD1SkuqRHfhSgyByXHMFcm/wsAmJEdjrnZ7iZDv7jhdMzNijmeBa6dnoPB3BICq21U9+F/2XHm5+Prr0BvshJbUIKltCPQoKt7N6A1NlB+eU0WRB0CZSVJY1hZqVsGUf3EeLdA5Nk57eubaClak204N/kcsPo510v5fdu9bAy9OUMxdAWFmBGXHc3K0Lm2Yxsd0aMc2zBG+wXPZyaZJUXvTU/De9lRUiVGw6jcQfPXxtJUMJpHjjoUYQ7tGclYouw2mrA1ufa+40U7nAsiipUltBPOqj8HX2YHo4pUYy/tK5yfetY8/2V2IMbltCnH1V+Bvq0GA/iVM5obcmFrEo0jgGLoCgoRIqqiFk74LQxCCS8oMLhzBYqTGr5b6q4PLkyL5fMu2g8oJmk8kd7DPHZ9+vgAYzpV7h5tPZziRO5DoRdZaYRRuQtemxm2JkqTKCK6uX5x6H54LTsBgJ5Rbm6mO17ITsIEbTZuSN2Hyxp+h3eK9QiET7NDMCCmdxZQTnEKCi0KhXqdk5omtJZWVRSjOBkuuMWq9twr8TWqaTlmUpb3usyYjgMeayxL7WpIbkmPSmVNnpHnIKoSN/wGrNflGYfu+hBHnHikwzHGl5+gAUkspp2xONMJr2XGYzPKcGjdNRihLQCFJpVCOZ3NSuZIkCY3FFTYmoJCMwBrXbAuxtz4a58xwmI8mY2PssNzaTKDQ4Y2Z1uKfGIZlsr94/lrXceaMoQzxYWpshYTo2nIRFwA3YFwdBPTOfEbOsAMU+M6UjIQ8+WFhmLoCgoRwrkYyyrzeBIWS5KyHhFTNedjeMPAGKUEdehG1mKOoOObF5ySl6eXO9MpTv/LWpz/9b6eya255MMXjkMPaEO3FWkRnEsU6ZhF9KhzwwP8IkcfX7aH61gmK8fRVT10BYUWBOvrHLV93bpWsIqS8GgJS4Yx777al9AIxQLaNdyADHjRyGLMxsKZ4GxsCr2whkGYsDUvhrd6c5352WgV9W2JSkLn0RU23JAFnoTeptRd91x2fqVyV1BooRCrVc1hSMxj+aPJBPGvh06j21Tspn2D24ruxmZaig9zZUfDwOXl7tHWuaZSmpdWeYvzlvpMs7GhiyIT8HrsP4Fob0o6KFEOyCRYCgteqCPrp5TJUhWHrqCwvcD5rkehcuctCtbFLalpwotHGJY+kszDoeRTnFKk52x/LrMLN2lKGHhtPLzMD7wEOxu21DOPN0WIO8XpV20vutK4iNuGXkiVO+s5ZCiNJPNjXFAMXUEhRkT2PnvYjQHdKa7eRzqKwoZ8ReoxjNd+BgC8mNkZ/0gfHXpMWXjb0NlKx7BlQJsiWOpfYY1wrl3UDEckH0IYxGGi52l1WHtKSRN6waFU7goKzRZWlbvmq9KnVJfOw2jduxM9T/sy2h7XNxxnqxIWJVg07j9cr9Tm8nKnFhs6T0LfWt+o0ut9J42NfEymtCpp1on6nrRm2J2DgPdbDiOh79S7HfM4V0JnHNbD1sTnLLQjZmwMnRBSQgj5ghDyHSFkFiHkmtzxPoSQzwkh8wghTxJCinLHi3Pf5+XO946LNgWFxkAY+zXbESz/WST0xmgfNPVnGWrRjazDzZljMKnuTqwCe4GMAk4KDxvTDSdP7A2AF4fubUNPM0Sr244eFYZEKQgl/slB1inOHocuBpF66EGQjsopjnc8BMG8+8qV0BnviayGoCU5xdUB2INSOhLAKAD7EkImALgBwK2U0v4ANgA4Ldf+NAAbcsdvzbVTUGhWiCtTHAvWtUJU1RmGvD652uYL0SX4IIJwh/8R896yFlXjmFeRGicziFs9bIUWw+8iaOpXQoDNtWlsqo3eDBGVFzrvOsIMz3sG/OPscaRSv0q0jQKx/aKpjprc11TuHwWwB4BncscfBnBI7vPBue/InZ9KCrk6Kig0YXilOwXkJMCg6EP02taLsvEzdBaM1cDJmK2JZXj3obE93CVylwiDxdxEVbw/r9yMEVe/GblKOKo4dCtd1nsXRuXOi+w0NoEdWhWjqqLYPB4J+2lJceiEkAQh5FsAqwG8BWA+gGpKqVF5fimAbrnP3QAsAYDc+Y0A2jPGPJ0QMpMQMnPNmjVxkq+gECnCqAu9HMEA75Sn1vmDLlElqMNdRXcCABahU8BRZGCn1M+T27g/PPUppe5+hRQXZMwccRdnkamHLovIVO4WuqwSdBwSuvGbyTreD95zaMpha7EydEpphlI6CkB3ADsBGBzBmPdSSsdSSsdWVVWFHU5BIVKE5hEBVwAR7XHQxDJtUIMDEp+Z3+tQJDdAALAy7hmHvLQVCc7GhnVbC6n+i0dCD8bQw7T3Q0NkEnoe1t8CKzueKHgM3fjNuLIVMpofPEouiVJLsqGboJRWA3gPwEQAlYQQI1yuO/KVaJcB6AEAufNtAKwrBH0KCoVAOKc4xjGn6tln8VixsTbQ3K8VX46bUv8GANzccERBFinWneKq3Kl36td8w2hoCwSZRy9aDz1rOLblL0zkEu1e7tHelDWWbHRhYH3ExCah2+m9YC/xokC8n4axGXZqPJzv60V7D8TNR46UK87SgrzcqwghlbnPpQD2AjAbOmM/ItfsZAAv5j6/lPuO3Pl3aXPK16igEBP4ITz5zwQEc1ZtdrVxLmKEECkJ/bzkM+hG9H31gmxn3Jk5zLSTxiF1GnAumvpXL6c477A11j1sqip3UbCKs7ScJZNnQ7e36t2hXHhEP6c4PZOie04DrYqTSEo6UrakxDJdADxMCElA3zg8RSl9hRDyE4AnCCHXAfgGwP259vcD+C8hZB6A9QCOiZE2BYVYEBeTYC3UIh7FGiFShU+s6Ix1OC/5HADg3cwo3JeZJtQvLpgSOkPq8fNyp2BJr4Xj6HH8LqLQbjdV/m+9Ns1DQpdTfPBU7nkbuldbI169KXtqx8bQKaXfAxjNOL4Auj3debwWwJFx0aOg0FzBW4hEPH71xdCyUEnMu2fiawDAJlqG0xouAnUo9AghsXEEdwpdi5qYY0PXCF8KY/UppIQuE7Ym2jJwtTXOBEfu2B1Pf7VUcPbCwUquc2Mr8wz5Knf9RCabT+vKNvkQN0E+aFFOcQoKCnyILkaUsi1xdjtjuDlY2F37FouynTCi7j4XMwfilVRcTnGE7xRHkfNQJsTTDNCY6ug4zBNMlbskCwmSlKYQsD4rLy93GVMG38tdy83p3TbII2yRTnEKCtsLnNK0npY0nrlYC7oTzoVJhsEP1RbhKzoQvKUsTgmXtVAb95aXNc9LQm9chXtMKveAEnpzQJazWXVqpWQ2SjxzjGEWt43NaGr8tqSKs7QUpzgFhe0RUlmkJN51dhy6/wDMRUyAyApsRWeyAfOy3fwbFwBWCZ2XKU6X0GXi0AtpQ5dQuQs2ZSeWkUOhGY4XBnRsZX6mHHu2S0KXeIS8tsZvJkPzpVFZTY1XyTlOyiupk5LQFRSaL5iq4phsbkFV7iLk7KjNAQDMpj24beLw3DbHdg2d985nha0ZNnTCWdEam23FcafYiWX8r9TKIJuSRE85nzdua0BNnZ6LLI44dCO7oJ/KPS+h21FWxHdFUzZ0BYVmDCeT81ow5QTEYEuDe2ESm3Qv7WtsoqX4JDss0Lx8esKPwboTWUqh+UnoLvtr4SAloYvWQzeKs1iOyUvols+NzNxt8fQOWi5++jsArOQvMjZ03nGWecfdzpTeHedKUwnunIX221AMXUEhQsQXthasH1Pj7kskxTBtIebTbqhHNOUwDRw8SkyFz3aKc0tSBrJUX5gTMai2o4DMRkZUDc4unyo+T1ODfXNhv5DF67YCYDnFicPPKc46HpvJs23o3o6YEgRGAMXQFRQihEselojsClUakrO0BXGKO1T7CCO1BShBvd+k0iCArQAGv52Y1KSD5rzc+W1o7j+x8aJHLIllWCp3IVos7RtbLOeAR1XGUQZXSkLncF5WtmAvG7oMlMpdQaEZg+XlLgqvtkEXBtaC57cuTUrMAgB8kB3hPXYggoL189UpUL2NTBx6ISHlRyFIK8ucvHDtFvGJ0MQEegsxPIfPhkzwxDLcOHRBRxPThu7SHhXSeOMNxdAVFCJEHAt3GASRKlphG9bTVrgpfZRnu6DrmEiSFZbK3QuUUmgaPw6dgmVDL6SXe8Gm8gWv2lpT8nh3PasczQ0Zp4QuPqafU5w+HuG25XnAe9HQklK/KihsdwizcHu9+74LA0/6cHA4P/Kmal9h38SXeC2zE9IxLA8EYrnkvZySnDCKs3g5xXGIsaFT62JkssDammgKjFghRZcsImQaj/12fOAiPmHh59yXydJQDJ0nSYs7xbG94njx7UDhN0mKoSsoRAipFJ8O+zqlNHKbJosaLxJPSfwPAPCP9NECYwdjUiK9nGOT3H9OFCfzpS81wreT6vdWmtTIEFfoYhA4jEK2bzv37xDz7HxQu7rAhm0NGfS74jVXnyi83G1OcRwp3Nrfec7LEVM5xSkoNGM4X+1vl1TjoU8WMc+JgsJ7p//aOZO555zZ5LzXP4qR2gI8kp6KhbSLHJGC0B3X5O+E0+FtaNfWeP3cyRjQSU9GYiSWkRqTM08ckNr8xMwFuKFqjR22ZvtsJ6auwS6ZG4jCy93qFGc08YxDd5zibSIbA4qhKyhECC+m4rdeUp/+LEzq3x5DurbmLmxOx6ks5S+O7bEJrclWzKXdheYOwvyIYD8/lXtSI9ihS2sAhn2cSocPFdKZqQmt+bbfRNOxmju1VdGP71ecBchvvFg/jbyE7lC5e0roSuWuoNBsEWbdNjKescbkrQt+Kn5nZq1slqK8hJ0IozNZDwBYQdv5E4vg18oj+Zw9+mPH3u2YY/PmIiCglJqJZaTokGodDk1J5c7LttbYzN0qlYukNQbkTFw8STppZeimmZxlV+dJ+ME38VFDSegKClHCY31xnhKOTw9MjFvl3pCl+MsBQ3DTkSNdbbuYDL290NhBVed/2n8H5rldB3XErgOrzHbOuWySUa4BBcV7c9bgqZlLPRk0RfT+CTJoSqFNaUss9wvfLGtESvhwPines4vCyz2VcCeWYZpjOHMmPLiosqErKDRjhJLQPVg370zersee2Zl8JJPNon2rYozr3dbVtjdZCQBYKSihB8W+w7pgeLc2ruN2b2Exz+OlG7ZZzss5JxU2U1zTYejW3CyPfv5r4xHiQBCVu1z5VPZxm8qdYycHgOJcilcppzhVbU1BofkiTFUtz8QyASUUp3o1nUvMwVoI907MxOxsD6xBpfegIeBlo0z6GJpZ7L56a4N5jJXxywCz2hrDkz4uyIwct1QnUnbXQFPZh/Ao9qKve9tS23cZCZ3V1oioUE5xCgrbCaRydjtWqdkrNknP5zedc/E2JHbW2jaALMPM7KDI5pZFgmHLtM3nM6GXFNzY9uGmwhgBdspYgL1pbCqaBd4exIs60YxurN8dq2WJIaE749BV2JqCQstEGCnv0Ls/kWY8vJKOBhypr9HAYehlqEVbUoPlVCIOOYiXu0cfqyOUyynOtTi7+0s7xbE2DVIjSMwlMXLcalpRhzOgsN753qmP5Tm6czzetaRsceh8E5YhoTuhnOIUFFoo5DJXxT+fc/E2ils4F6wuZB0AYJmgQ1wcqEvndx9O+nSGaA0vcsM7Bac7sUyT9XKX5AKyTCOdEe/hlQUtDCb0bYdOrf2L9BgIEuXhZugcCT3h/l0xbegchq4kdAUFhUgKt/jZ7J0qd+Orc53uRtYCAJZLMPQgS72XSrM+zY6Pd/blQVrlToDphw33HrQFQkZCj8s7/+SJvXHNQcNsx4JEIchQJxe25m5nOsW5vNy94ysKCcXQFRQiRKFtjl4SBeDeCBjfnSrgrjkJXUblHmyx5/fZsVdbbitCHE5xrDhhr2kpW21r2EXjRpxx6LJPgWtDZxyLS+XuzPzHm1/knCj4qV+tEjrJtXU3LjGc4pz10L1U7kpCV1BovvBU+0q0dffVex82plvgMaw0ONegrmQtMpRgFdq6+sSBLfUZ2/dh3VrbvY2dNnOBMeUTy0TDrU7ZuXck4wSFLM+Q8XKPb4Mqd/eDaKicEj9X5Z57GbpVlnpqkLgSuoQdP24ohq6gECHisJVa27UtK7Kdk11waV5Etx7FBG02VqA9MhCXWAOlfs31mbe6xrsdMw49hA0dDBs6Q0oMgqk7dPRt05QSy8jsAOIKyWLl9Pd+H6JILMOjheD9i3az1UQwaLtk33zUhxm25ujflKqtKYauoBAh4oplZvJhBGdI1o1AJ2zATtocPJvhF3lhIU4WxfJq95tPxkEqSkT9zOOW6njDs+aNS0K3uzj6I8g9cXbx2pz07lCONmUpV2KZs3brb7YxVPOuOPTm4hRHCHmZEPIS71+hiFRQaAkQcfrhNTEZuovR5RYZYRrgat+brAIAfJUdLDhKcIRhD9ZrZ4atWVazimJ7mQqa+7fXkE5cWoJK7CJ9vJpM6BtvZr4wYPHA48f3DD0uIYRhQ/d/Pyb2tTtterqjuaIa/B8Ucfy1nROIY29s+EnoNwG4GcBCANsA3Jf7VwNgfrykKSi0bARjHvZOskMYi6Z1nPHabADA7w/dE90qS5n9RGgJA7/F1pnLndXekJRmXLI7Prxkd+Y4HVoVm853OlMJfw0iI3hNM7hza7xw9iTze9xqWhlvclZIVseKktA0aCynOM84dB1OHxIvOO+jCN/Ne7nzG0s5xflPGSk8q61RSj8AAELIzZTSsZZTLxNCZsZKmYLCdgiut7px3tVe1oau/zXWoF5kJc5Kvojvs31Q2aUvfjd5I65++SepMWUQlH8KMc3c3x7tylzn9Ep24mNJIYIBbWlvY+YCHCd3JmK1oTtunKeXO3VvRI1xRCEiSRvjWZtedeAQzJi7ljtnc4xDLyeE9DW+EEL6ACiPhyQFheYLGemK9bL7LgAu+13usODKlt8Y6O3PTz6DeiTx2/qLQLSkXC564ZbRwEaapFdcXjORb0YpLcg1PPrb8QIaiAIQkgPvN1rQsDW4nSJEJPQwdneR37ZZa8Ay06mT+uCBU8Zx+zQlpzjReujnAXifELIA+j3tBeD0uIhSUFCww5RQXAVFgo2j1SzHE0XXYoI2Gy9lJmI1DDW0+FiBTAaCFLuSn4S0U+vD8QvThIHfeJP6d8DKjbXCY8TNAmSkRpbDVyRMirDG5o/L8yGReQPkVO5ebRwqd5lY1Zjhy9AJIRqANgAGADC8Zn6mlNbFSZiCQktDFOo3GQ9bJg25v6VvXIAJOdv5N9n+/A4Fgp89lcDuRCUpoNslPJI/Voj0u6JtmiLiCreT9XI3+0l0cnm5C0noxjxeNnQ7POuh+84YLXxV7pTSLIBLKKV1lNLvcv8UM1dQYCAumxlX5Ug4x3O46sAh6Nza4sRk2NDX/YL52S44vv5yPJaZqo/h1oL6QH5J5q2TIrKaH3PxW7CdNvSonlUULK+gKneJ6/ZiVmHA9HL3UrnzNFRemzhnLncJEd2rpUzq1yDpbMNA9HG9TQi5iBDSgxDSzvgXK2UKCi0MUagq3RnUvBeprpWluHS/fHKMJK0HfnwO2sZf8Vp2PD7ODkcdijxGiBaifMu5ELLi0qXGNp2qLIdAGSYMOc46uHOFoG1WHLJMICqmIVo+VXS6Ik4xE8CQ0MXvirmhlXo8jt+QQA+jjSaxkWlKZXtFbehH5/6ebTlGAfRltFVQUBAAIRLSkumd7rTf+cwB+8K5V/oD4Jm7AABzsj3YRAkiUqnSmTWM1cT22T25n8rdjykQzrxeeOqMiZizcrNkL8bcBZXQC5P6tSihcQvuyOZyDwLRamtW5FO/yqjcm5mXO6W0D+OfYuYKCg5EUUHNC86lw1yjBNfdPplFAID0+LPxWnY8e6yAtAj1EfXGd0ro8KfPaxG2FqUx21GnxC6PpCYmZxZLFIFprExxLLCd4sTgJaFrxH3fvDYam2vTABhhawBuOFysYp6I+SBvQ/doI+MUV2AIKxYIIcMIIUcRQk4y/sVJmIJCS4PIQs0rbWmq6yUXE6etcmB2PtB9HDJ7XYss4/VvKksTM++6NbEM0yvOb0y72j1Lw1+vqNq4TWkKQ7u2th3bf3hn5jiy/Fy6PS8bIeNYGBt6kUdnq3Oi1/xuE5M4nOMJmUbM1K8eErqMDd13xmgh9LgIIVcBuDP3b3cANwI4KEa6FBSaJcK+wNzSlhHkcm+NLRianQP03S0SqSJOwURkcXed9xrPwsxFHfNEIJMutqsjC19Vq+IAM4aHjC9HkN/JrUePBACkkl5irnszJLLh5aU+FoGUl7tAGwPN0SnuCABTAayklJ4KYCT0UDYFBQVBiLzaLIZuXRR4cbg8SdF6dCBZggSyQI/x7LAvuD2PvRBlPLdb/eo9F9MpTtSGnhsruqQfYvehosTusmSrHmdV/cetcpcYn8kwfQbI5szm1nK4O/dz5mBnebmzfvsOeli+E5z77y6f6m5zwV4D7WMR+18mJLRkTVJCB7AtF76WJoS0BrAaAMOjRkFBIQz4KncdrjzSEjy1j7ZS/9C+X6PZ/USn7VdVjn2HWlTSRMApTsiGnqeBUnF6vCA6xqBOFYH6icJLxW2FnA2d3/+MXfsx+xib0iKv+vZEdBvk7mf77tHWeZ0sSfqs3ezXYGxgZN4Pz9veFJ3iAMwkhFRCL8zyFYCvAXwaF1EKCs0VYVVsaZ9E2yLhW7zzvclKpJEA2vT0UDuLL2Rx7gmSCQ33nLgjOlZY1NI+8/mFGjkfjRHZbIW0Y6AEY/rdZLsfsb3YjBiuOWgoXj1nFzz8m51c536/q5ifMvcnyjjupU4u5Tj6Gb9h37A1gcgGJ2Q2sGIqfLeTnfUvs4/ju2cu96ZYD51SehaltJpSeg+AvQCcnFO9KygoCEJkgUln5GzohiQhwoh6kVVYTjoCCXbOdi978O3HjPKfQACyavp8GJG/U5ynhG72szifRaDb1lXHYtekaQRVlg0Kjzl5MYHWpUkM7doGfdrnS2ns0EV3tuvUWrQKmvh1B8kUl87p3D2d4hiJZQQpcowj3lMmbM2rrfOUZ7W1ppb6FQAIIf8F8CGAGZTSn+MlSUFh+wXPKc6ArNevzqT1Vn3JSiwlXRCkmvXY3u48UqJrqTXenqsZ8NMYSCzGLFBKXRW7Cm3fdMLKCEQZk1k8xNL+j3v0R5vSlE0i7tW+DI+cNh6Tb3zPNYZcLnf3Mb9naWxKrfSwfCBc3QM4xeUGZ8K5YROqtmb+3gTaABjRvY29Up6LBt8pI4Woyv0BAF0A3EkIWUAIeZYQcm6MdCkoNCpqGzJ466dVkY4pon7L+IStuctHinGCMeQXDNEWYyHxdn3hjcZcRyPUufNGsq6VUU1nDhOBDT2oLdhGhwOyTCCpaRjds62N0Vx14BC0K2dnAJQZ3kudzDtjbEpTHhI6sx66AD1hHpdUcRaBNj3bleGp30/0fA+aqsr9PQB/A/AX6Hb0sQDOjJEuBYVGxbWv/ITf/Wcmvvl1Q0Hn9ZPQnfBbgIxF/qDEJ8hQgke0g/ljCcwTFrLDmHHBAn09F1bKzhQX9rKsTnbSfW0d5QZhqXnt1+V1L3xyHfjMw0JFcV7ZmxZg6KwnKmICcdu8/c0s1tbz/rYfTp7Yy2N8/a+nyj33t21ZCiWpRPNLLEMIeQfAx9BTwM4BMI5SOti7l4JC88XidVsB5DNUFQo8pziemlPEJk0A7KzNwsfZYVhPvKNNG2ttkkn6wWsvQrpVonYysKAah6Dhe0G0D6wNHC/Uijdm+Exx7hF+uGYf83M6o9vQi5N8L/eE5rahn7/XQLQtS3nSI3WnGReadGwynOOxTBp8YvRGXnuepqpy/x5APYBhAEYAGEYIKfXuoqDQ/CG7xntXjPLvn8myc18bXWVzuYMA7dZ+iYHaMnycHRZ4gZHNne4gQboPay4/edY7Dj0vops2dKfXe4CbE9y5K9zmydcpkPA3GmFt6F40AMCAXHjelIEduHP2qyp3UTehb3t8c+XenvTIhL/dfcIYIXpZbbzaykSaNMk4dErp+ZTSKQAOA7AOwIMAqmOkS0GhUVFo25cBlpe79YhLohBYgHovfBwZSvBcZrLnVRELE+jToRxnWmJ0A+QXsfQNzrnyEqmYJoIHay536zFe2JKBP+2/Q+A5/WDdnFnHEdlYsCRnpymBK6HzVO6Mw0GqrQ3v3gZf/XlPHLFj3l/D+T5VlKQCqaplukweUIXz9hzgOi4WHuelcnduqr1NPYWEqMr9D4SQJwF8A+Bg6E5y+8VJmIJCY4LFAAoBXmIZVvlP/bs3fQRAxab5eD87CmtQKbzAJDSCS/eN3qomy9xtTMpHRe2XsSufnCd/zK49sPffqXc7/G6Kf2x3NDZ0yb6Mz17XYoWUyt1DROfNQQC0b1Xs2KSw+ksQYo4t+fthtPd6B4SeidQ72ASd4gCUALgFwGBK6Z6U0msope/GSJeCQqS4/Lkf0PuyV4Xb+4XmcPuFfIGZC5/ts0Oi9KEv0bAZ5TULMY92NSn0BGc8WRW3LHwtBx4qZBl6rLH2kcShh1Gb28axaA4c7QZ3rnDblsPc+4hU7jywtEbs33Ugji51z63vo5BZPPdXxCnOQLOzoVNKbwKQAnAiABBCqgghfeIkTEEhSjz+xa9S7c0wsTiI8ZyXfYzloQ1YnHg4lA74+m9IZBvwSmaiPpbnAuOxxIZQufsM4wkzcY6jM182ZMNOa86GjvCbEkKIFGOy0tGljZ4IppujaIvIfbUxHAYD9VS5C9DJnEewf96xTG4DJiocf3b5VFsfWU2HjclzaPC2oXubaexzFRYy1dYuBXB57lAKwCM+fXoQQt4jhPxECJllxK0TQtoRQt4ihMzN/W2bO04IIXcQQuYRQr4nhIzxGl9BIU5Qp342kjH9X29ZqdFLOuiGNei04Dks6H8yfqC66rixk6lwNQACmgG/ddvPKc5ZPjUqBB1v2oguuP/ksfjNLn2Ef2bWMD7GWSGapGzojB+Y3080zkgJQgg6tS5BSUq+rqtQJIXjr0hb70xxTVPlfij0cqlbAIBSuhxAhWcPIA3gQkrpEAATAJxNCBkC4DIA71BKBwB4J/cd0G3yA3L/TgfwL4nrUFCIBbJqwbDvr48JnZFYhj/WAG0pCChWdNvXMg6fQC9pJ4wvQZj1PV+fmn1cdB5bcRbLMc81XpDwoAxMIwRTd+jkymAmYrbhpe41P0NOc8CnMfQQANj3KJgN3fgbnDARG7qMyj3KBEthIcrQ66m+ElAAIISU+7QHpXQFpfTr3OfNAGYD6Abdqe7hXLOHARyS+3wwgP9QHZ8BqCSEdBG9EAWFKNHokiwHrsXEI262C1kPAKgra9zXyMlopPoKfGbNw4LTbMHa3ARZnIPHoYtJ1Oy+7vndjIbdN6zK3Q/C2ganP4hIJAPH5CQ2n3gbmbA1Txu6wJxRwpehE/0X/goh5N/QmezvALwNPWOcEAghvQGMBvA5gE6U0hW5UysBdMp97gZgiaXb0twxBYXCI6BTnOeQAm83rwlPXey1mHQm60GJhroSSzywz/y84eIWQrgLs2nT9C+CIsoQhnTRk+t0alMSiRRbyDh0LwmVV1/dCRktUqtid7mPfBpiTqcYNRtSiV84sIWBcjVeHhK6xKZCNvNjWPgy9JxkfiSAZwA8C2AQgCsppXeKTEAIaZXrdx6ldBNjbKkrJoScTgiZSQiZuWbNGpmuCgrCCOoUF/b15Yat5eCix2Nl607WoL60I6iWX5SzHguMrPZZ1D7oVyXNuy/ns6QKVy/Oon/+wx798cLZkzCmZ9tIfCSCDsHTXAjdVtb1Oz7z6OKp9FnHpw3vgr5VbIUsj5GJJiEKxNBdphf5MXxmAOCTUMdxfV5t69PsRFFxQVTl/jWAakrpxZTSiyilb4l0IoSkoDPzRymlz+UOrzJU6bm/q3PHlwGwVo7onjtmA6X0XkrpWErp2KqqKkHyFRTkwLNZhxpTYl5nx7y6mL2YsMgcQJZha+v+tuXHV0JvLHMgT0CXIEhEKiWEIKERjOpRGZSkkMg/gTCJVVhpY4mDo/PunVSmOI3g1El9AtFoO8Zi8k6Vu8DtII6/zs+ydPHayKnc+Y0bMk2ToY8H8CkhZH7OA/17Qsj3Xh1yqvr7AcymlN5iOfUSgJNzn08G8KLl+Ek5b/cJADZaVPMKCo2CQjM4loS+uS6NDVvqAbilAZ6UpCGrM/TKgfYTgou5a54QN0I2Ftg2rzm/81noX544fQJKUwlfGin4kmlYBFa5c8YQEtCZToFihMjeBdeowVIZuNsFuW8WE0zQMTyd4nJ/ZTZbXk0bGJkf44RQPXQA+/g3cWES9Lj1Hwgh3+aOXQFgOoCnCCGnAVgM4KjcudcA7A9gHoCtAE4NMKeCQiQQeQ3fnLUSFzz1Hb78054oLdKZStgwFV73O96dp38Q9HLfX/scpaQeW9oNFZ7bmpfc7bDEoFV0XBCJ1k6a8mOwVPcT+rbHzv3a452fV0s5PfG+B0OwUXhMQ+QnxJJQ3V7uHPhEUoiCG2ooyAxdz0JIQifMvkLzRSShu9vyGxda5S7E0Cmli2UHppR+BP59n+o8kLOnny07j4JCHDCd0Dza3PTmHNTUpbF4/RYM7txaYMzwdDnpyUvS9jN3FekuLps6jpOW/oCINRMM9bB4V3/7u8jCSikv/Wj4Cy2sU5xh4/Xu7NZo5BE6m2GAPrHZ0AOxdv4V5BMZ8cflmb1YaKoqdwWF7Qq8zGxWlBXp++Gt9RlXv8Dz+jnFCajCu2AdAODFzM6ob2UPFLGOf90hw9zj8xydYjY98IbnSUx2dbW/1GYyMZ/rsEm5gtcc9NbwNxMicehix5ij8yR0ibkAj2cmRoZUS1ePQM/Jv6GQDd3x3WtzVddEneIUFJoMGjJZ/On5H7Bi47bY5sgvevyXtSynZt9al+G2sY0psFCLptU0vzPIG6fNAQDcm55m9mKN36FVkWNsOcYdLPVrMPbn1YulcnaCUoF7G1jSbjwp3zq/LWwNfLrituoKM9gA0rbI5s0P3jZ097100+D93Ypl1duw47VCPuSRQDF0hWaHj+etxaOf/4rLnv1Buq+ojVtMQs8x9Pq0NB08+IatCSyCO2pzsIUW42fa07XysXKas+dx2tAjsjb7qM296OBJz3k7u8D8Hr4BhS6kYYWw3TnXjFk+VXC88H4efqGVwWzoLOwztJPte+xhawK/Jfem2puIQv6sFENXaHYI84JIO/54nCvNqdy3NVgk9JhSv/LoYakIp5QswA9kIDJIuMf3KEzhNU8Yfh5mzbWG5XE9+hkSqhPU/J+DtggYQtQ8RcgpjrWhEVRDy3u52wfzrUQoLKH7N7z16FHMoUU3QLZ7SRjHnDTl/nrGoTvO+aXHTUaVP1cAiqErbFcQXsxyb71X+7KUIaELqtxDZIoz4LeY7EAWo096Pn5O6d7tBMTWx0oDb3PAmodNq/zuRXZp40rlDGc5z7EFCrMEdbiKwkzhNcTx43sKtRcOW5P0cs9I7oLZ9n33QXdopLtfKqEx21ifeZRSOst8wW2b++vnoOi8hjihGLqCAgPGEua1lpUWyTF0oXkl1ZnO70cn3kNaK8aLqf3Y41v7stS2nPhe1poVpYrat9a5o4Wd0YtJ6LHFoUcso1vv66Lp03DixN6WuXQwVe62DU90SEfgqR10A8IzLIiaSlj3xOt3kNcAiNPkJ4A7i+/ECcXQFbYrCNvQzWb89nmnuLwN3Wv0wJnirOAwWuPwBG02VleOQrVWaTvPIkLKTujR1m+9IjxOLACNs8GwjS8xtEsrEQHrk7kkER8CsWprls+Ov7I0+SHtSI5i+pfwIiIEx+VFLnx75V6WNk57tfcYIhDZAHiHrbmOyBMRExRDV9iuICqjGYuq18tfklO516YjlNB9zrvV5PkjNyb/jcHaEiyp2pXbx8uGbpWCZRbKKCQQIWbMdZBzS20A8NCp48zP/Dh0eTrCICqtBlMbQbhfmDhzt35Cc9VzJHQRR8YgqCzLR1+4N2DuOcS96sU1At5N7Sf9fv5xaYZYUAxdYbuC7ILq1dxgZFHmjvDTIDhVrdZvuye+BQDM63YI87w+vqWvhFqRtRjy8st7QXapN+jVCF9m4uWz79uhVX4cvwphDAQNvwqCOOz1fhjcucJxhP3bk02OwlSvM+3qUsPm+vBYPBus18nrDcvXQ/dqY//uZ0PPFjAUXTF0he0KortlYyGgFJi7ajP+++kiVxvjPbYyYUopJg/o4GprG9STPm/wnOJOnX8uqshGXNlwMhoSZULji1bF0tvykYhbrIW+eeI6xTGOOcGLQ286ytI8ZDPasdTEshoPLzgZum8kRkCJWYTps8wLUULkt+Syoee4aAFeA18ohq6wXUFUQs8zdIppd36Ev7w4i9vGGTverrzI1VYUXuVNAZaKmAB1m9G/5isAwPOZya7z1oXTpgFgqJvNhUxgdaosTQHwv94w5VONDZhG+AyIZ2dna6WjX3ULkVhGxPdD1imubZn+/NrkniMPzgIjfptidmU1Vjt/EEJwmyV0jRWiJwqji+etlBg/b+phm3wMhI37l4Fi6ArNDzG+H0vWb8WqTbV5L3f4F1jw4cEmhJzifM4zazGv0AsfnlJ/MTaDL507x/das9wqd3eb48b3xN8PG47rDnWnkOWPy3Gk4hBjqtzdZeZcn/1ir5kLayTq8mjhxy55x2y3RIAj7dClNf7zm51wzUF6iCOP7/B+/7w5RMPWRJnyIaPz6YtZmRKj3KSJZYpjaxZ4fWTD/sJAMXSFZgvRBaF6a7352e/dmnzjexh//Tvm4m9t75SejTZWCT30qyurziQEWP4NAODHbF/f9nYbOn+RFbm3CY3g2J16YvdBHfHAKWP9OwSA1YZuhZ2f+ytifZOhMM4V1oYewRiShBAAUwZWoSTlzQbSMRmB3YzYn/78JcrfMTGp27+tS+XuM3BGdMcfARRDV2jxuOL5fIpYWY9Ta3unat1qZ7cizOLsl/rVCQIAy79Bdaoj1qKNTg+rDa+v4Dk/KWhAR6eDVR4VJfmijnwbPfuEcS2GnZ7V3xDevRyZKOfJW+cNKkjJSIhhQxdFGY0IRaI1vxvS7N99WITZCDnDNaOCMV4Qpzhel7Ri6AoK/hBdWDbXWuLEZd8tS3un6sz4JsqEo8kU51S56xL60tLB7PaeY/HbizgsiaJb21KM6902UF+zjK1jAWeFLXnSaEjoPvMFUd9G4gxlGUN208m6fhlp1O+u8LzcuRtFj9+V1zEpCdq/KWM+vZdnYhlib+vVxtWH0yWTUQxdQYGPEAuocBy6IX1bjv3jjTnofdmrpuqd5RQXVnqRzeVelN4IrJ+PJSWD+H0kpWLWPH7wW4zH92kfaFwDXrHueack79H94tCDMuaopcSgkN2MuHK0c9o1SEqYftET5ucAN062MAoTXhoQ04YuQwP7uPGbLaSEnvRvoqDQvGFdyMWrrblt6P/30UIAuqSugZhtnO8rv2yl/9yy1da6rv0UALCgbKRQe69zhMjZ0GXg6xntM5+tAAultqWTFzZk/U5ZB30Qh0d82Lk8JV0r0xSxRwuGWzVwneKA3QZVYVzvdq7jnvNK0MiaU2SOoDDG9TRHcFTuThQnNWytzxTUhq4YusJ2BXkJ3d3DYLrW0Lao4C+h2xePbqveB0rbYXHZUAArhMbIjyU+j+8iLbjCSoetObzc8yp326i2c+xx2DfF2WdUj0r8un6rHJFRMxfJOPR8G/ZnbntBcrwSyzx06k7S43LrBQjQwuoj67zonVhGbCxjbsDC0B19iwyGrrzcFRSig5UpC8ehe7R3quOtO/CwaR5lJPQEMui8ZgYwcB9kibtUaq6HJBMVN1J6VW5zjhh0TbPGoQPsBTd/jk+F6eXupM3R58YjRjAyqHmjEPngheLQpef03wgBbpV7sA0scX0KYwePT3sionJ3fOe8MsVJnb0qL3cFhbggnFiGcptn86I5AHfqV95aEIlTnOXzGDIXxQ2bgIH7BmOYLhW1e9HNfw+3gBrkydo8jesyvdwZ0jjXR8ByQvT2lKQSGN6tjee47nkEB/caw/LZW4Jk2acJ95wXnG4JPEbtVLmbz5Izrh8dvLht6/drDhqKvlXlHn09p2DPm/vrtSHJR0zwJ3A7prJpKk7yNtnxQTF0he0K0mFrlLpeVGPHLevlLgK/3byVljHaXP1Dnync65Jd+PjMMVg/IFxsvshGQMSRSSQO3YBoOFd+/mjBYjgyhUX09v7ziCRRAXStxTHjevgPyKCDRY+IZuDknXvj3Qt38x07alu6iBe9n5bHgCGhFxKKoSs0P0hyCLtTnNwUFO4XOGsX0O0qd4/xo2H7OjX9yDLsmfgKW0s7A2XtbIO749DZC45Xik7pjUAAD3MRGMzN9HJnSHf5Ux4qd4kNjya5KspIxlxbvs8YXlIl65kJOcUJkt2jXRmmHz5CrLHAuC7bswRCxZ+L2NBFVO6Oc/k4dPuJVKLw7FU5xSk0W0QcscJuSGF6VpunTHV8TuUeZWYZHxACDCRL8HLRn1BM0pjd82zsAPd1mfHbPmPZvts+E+455xyssbjjCqjHWdA8FnJehSybGpvz4FnjBWE0UcKb4Xids5hMRCR0xz2VdRjlp34VU7m7TD5Cs9u1ClHb0kW83HnvhrMLBXDGrv0wdYeO0RHoA8XQFVo8goWtGX+pa8nIOOLQrYkj4nZoJQAOSHyKYpLGSfWX4vAdTsYOXu1l1cccD+SwCOosaPQyvdwZjF3Gruode29sDAqvcvcbQ9bLXWzOcM86iEe4dd645+TBMxOf64M/LbxMcZRSXLYfO+FTXFAqd4UWD5uXu2gfS2iacxExVe65704JnZvGNApmTyl20X7Et9m++DA70lzonSVcHQQxISW9+0ldnmet7Xjqfw44TnHWDiK2YBnPbK8kNiwEYTJ3HTdavpPE/GK+ApGR4AvZkDoeXDn9pTYVuXfFq42p7fHY+LneDXEa4oZi6ArbFWSZKqVuJuQs3OJX8jRKDPjhJozR5uHHbB8A/upSmbWGEIv6UETlLjiRbrKQIIQxh8gC63WtxiMSWYyj9h9gwSsZS+Bc7oxNjheCamPChmbyppOJnWc52UUJb9OGHbakRxYUMPw8T0vhp1RQiAZBXhjRxcjqFOd8g/MSOseGHnJuL/Sa+zAA4OXMzgDyC5tXFTX+AiouhfjB0yFN0Nbu1deZDc46nylpejBr/r13E5SQv/hmCXfYmlz/oJdtbs4CvA4uO7XEGPl3xcPBUMR8I6jxiuJ9l4WyoSs0P4RZQIXj0I2/1LXwmQyc4eUOxKeC05BFJlGCJ+t3wedUt5wbiyOXXUmqJIOGrfnBN76eM75TQmc1E3GQMiV0HzoAq71e7KJl7g0vhttW9U18OFtfeac4//vGQpCNtG0OLkMU0Co47P5+TDPovZRxirOcsM/dCBK6YugKLR42pzjRPkYud7hf4GyMceheGEN+QaphMz7NDjWPGZRlvWzoHHirb522Sh8bus9aLOJ174WEg8mybLIicegiiMop7r+n7cSf15NWfwnS71xBlAYBd3lhaGNpaGTn9bah29t6tfHr0wj8XDF0hZYP64slHIfuiDVnn8up3LOCzDTkG76z9hMoCN7LjjKPkbyowoQudYsvflLSplXN7zmmnOTImsOzPrUpobKPA8CzXy1lzs+MQ4+IG04eUOU6xh06xJxenv9iAwSfW3gKhs27OBXe4qv7uHjMKzme2V4kqsAnSqBQG30rlA1dYbuCsA3dbMZXueed4uzn41ofR2jzsaV1P2xGWX4uAdWjaGGSMBKef2IU9vFzpw7w7mfmcrczbetsIuk66yVqest7uQeRFj18DqRHC05HkHnDsimDzJJUAjMu2d11XKSvqBk+KK3eG0jnd46JRjnFKSgIQPZFscWhS3al7hfVrLaW+16YakoUI7X52NRuuO2oqXLnFMQqdGwyD4eM7gYAmLpDJ9vx9q2KcvOykZfQ7WKolb6EJk6ziCOgaNESs59gO88xBAcRr2EvoZURbqmDV+hGFNaNV492ZR4t3XA+G5lwRClNVRCVfuPzc6VyV2i+CMJ0guwFXLYxh4Rur7YW3dxWdMNaVJFNmN3OnoLTWByDqPdY98+QiEVurXVGv/bDurXBounT3DT4zWHEoWt8JsuTzIMyeMPLPQ6J1XSKi0GNE1WsdxyIyr5vamjCXKCAVUxGScOKNNG/K5W7gkKsEM4UZ2XajpfbGbbmZKZxLKYjtAUA4JbQBVSPossKgUX6knUMC3nNshW6rBJUUgu+qWHBWMzjzC/gVtta4Om15XHK6qsQgKY4IeuBzx0nhBQs6hnPmsezLed4Y0joiqErtHiEqocukvpVcOEPumPfXfsG/yq6HQCwqfUg2zkzbC3Q0O6lKKg6Nb761Dq87NqaydDlx2VK/JIbhMaQxKyIagMpfh1Ufl7C/SIFngNk1PDMOuhqy2mnwtYUFJoGrF7uPBu6AdFqa0FxeuJVAMD0hmMwJlFkP2mq+ziOb5IrX5wqYS/wbegOpziGDZ1ndmCNKXJdsmaMII/cKywwioQkcpENwR62yCZu2ogujPl4dAjM6ZTQqYz/Qb4PDzJldv0uvzESyygJXaHFI0j5VLM92IuI/pejco9QftiJzMbExE+4seEo3JM5yHXedIqjHpsKy/fz9xyY78vQ++Y3Bv7XYNtExLQByNs07ZKZnaHrf4OoyFkLt1H1UnS48qIkdujSWm5ej+9CxUMkx28s/PO4MfjncWNsx6Kwoec/xMM05d5hQ0tmp0WlflVQiBniqV8NtbqHyt3x3XdMyRdcQxb/SP0bS7JVeDyzB7uNX6Y4C/W7DqzCuXv6hYnl+kmuup4JT4J2hDsOnenEJqFyF1moTQld8LkmNILXz50s1DYOMOvax8jRg2WKyyNUeVpi+xMI3qki5M0JTUnlrhi6wnYF2cQygJuJfLuk2tbGuu5HqWbrSVahl7Yad2UOwQa0zo1vB8/DVgSsdSjoIhSWf3AXxdwVu73crU5WHBW5iAqX0ShM5IAfuHXZCyhST+rf3j53wHGC0sxXufMHdGaIy1cZDD8vC1Je7uJNY4eyoSs0W8g6uDk/i/Sh1P1yX/XSLHStLM0XZxHM5S7LHgaQZQCAOdke3DZ+zEfOW5fAdHgS7xYrXHHoDGgSmxoxG7r+t4BF9GzwrrYm9mS8NBEPnDIO2+ozsmSZCLR5DOmBb/wynVnx9CAUuRGFvNwjeAMaw1lSMXSF5ocQ75p42FruLzMSHVixcZu0l7ssdte+QZpqmEe7uugywJSyBbcOkVZbC+xYJQbNkTxGxClOaH6mDZ1tE40TYRgI6xq8HkdxMoHiZCLwfOYcQfsFyaxHCMAwf8k9IhlHQYlROY1V2JqCgghkHdusDmOSk/AWjJJUgmlDj4oH9CdLcUzifTyc2Qc18MimZUqTfAldxi6YD1uTW3TjkujzTnH8mYxzIhsrIefl3I2KMwOg17NoDO9ooHFsvlZ4PZu8M6R9Y+cHlupcTJPDn4C3qa4oSaEoqeEPu/cHoHK5KyhIIVCmOEkbOkvlDgClqYTZJi2qcpd4v8dpc6ARigcz+3i2CxOH7vK0JvE4xQWjRoeZKc4ZtmZpw4tDD7opyTvFSXUPBdnQqyB9w85tIMiGwzpFBD5xwrT8dnJf17xePYxNYULI/0JH69IUAGDXQVX45br9cNRY3USm4tAVFAQgu6BQj29+fVhha4DO0I1WmRhW/oFkKbbQYiyjHTzbmbZEnrOVrH1RJg63IDBVBtY/TJW7iIpc5LqMsLXGElijYASF8HIP6gkeJFWv09QimnmuVXESAzq2wtzVNUJ0Vm9tAAC0KUsJtQeAduVF+PDi3dGlssRGT2P8fhRDV2h2CLPgifY1C7BQymSKRUktL6FnxFT6H89biye++FVo/gFkKebSbqA+SjSRrGa87G+shTCfy11Wug1nj/fTaniNL6NyF5nX9JpvJK+4KGYNW3ktTgQhzXDYdP4ORN5nZxOvPhu21gMAKsuK+I0Y6NmeUQFRha0pKPgjFEMXbGfs1HkSupUOp8qdpz6es2ozLnvuB6H5B2rL8AvTu92h3nfQ4oRsTurAYWteNmFPr23vcZ0mAJaElneK8x/byRBYG4UE8d8kNRZErikoCmW7D0Qtsf8NwjRF5jXe+7aSDN02j/mQlA1dQcEXsq9JmExxoOyFIEupuQCmLSr3KHhAJTajI6nGL7S7b1uZghOuvowro/mTvoiS3/GmM9To+fXc3ZJIqNxFoJmZ4uKIQw8WXijLBGXaG/dUNgxUZiNht6FzVO5eWh6zr/73rwcPww5dWqNvVbnZZnDnCtx29Chhmlio3paT0EvFVe5OyIRRRg3F0BWaHcIs3PL2d8pcgCjlS+hhtZ0DyVIAwIqiXr5t/RJsWKVuETWsk4F6Ya8hnfwbRQSndzMz9WtENvRwBW/CgzWvFymyYWuRIeAcQbo5nSF36tMOr587GSWpfPhd7/blOGR0N48x/Gce3FlP4NS+FV9C91tDzA2S72zRQzF0hWaHAEJ2/rN0yBtvzPxrTWm0seiTEj8CAM499mDfjFXGac9c7ry+xPmdMD+zMLhzBXp3yEtHIg5NzHM+y/vEfnpWs+Ikf6nipX4VYRws2gyGHmfYmosOC7VH7OjBlATZYdzV72Rh+z0FtqEH8w1wCwD853rr0aPw8h92QUWJv4TOIyUvoSuVu4KCL+TV5sHjxHnNs1n7WHm1u9wEgztX2L73I8twZuIlfJbdAZ179MVvJvWx0+MYnpXLfZcBec946ZAkjgOdH8IyEB6dtxw1Cm9fMAXlxUkbXSwVbhAGXJpyJ1hJRFxfnQWv+7XvMHeFsjgR9DcSeL4QdLCaiJIv0q5VcRLDu7cRHNF7ohYloRNCHiCErCaE/Gg51o4Q8hYhZG7ub9vccUIIuYMQMo8Q8j0hZAx/ZAWFAqrcOc2tNnTALqHLrI/Hje+J/ztpLFphK05IvIWp2tcoIhmcX38WCCH+tlVT3az/ffx3EzC0K3tBEqErSHEKv/ZFHtK1H0pSCfTvmN/05FXv+QkTpopc/nfRu0M5DnOoafPV26SHE4bzdygch850ihNr50uT5O0LuoULUpxFJBSM9247pfq4BefGNNnEKaE/BGBfx7HLALxDKR0A4J3cdwDYD8CA3L/TAfwrRroUFITBWySyFLbVpSET7O0lhKAoqeG85LO4LvUgrkg9jmW0PVagvXneTo+jvykO8BhxQMel3N+DRnZlNZXCLUeNCj2GF3gMmKWeZR07cFRX2zmZuPZCIU6nOFnElVjGi2bTbzzAMyn0cwxDa1jExtAppR8CWO84fDCAh3OfHwZwiOX4f6iOzwBUEkIKq3dSaDYoRBy6gZraNGrq0oxx7MuaWVI1gJRTtfhV/Db5unns9cxO+jnir8h2Si4s6YdHEjMO3eFAd9vRozDvb/v5UOG9GHdqXcLvF4EmIOpUrXHa0NuV685Wzo2F322QdYqLk6N3aFUMAEJ2ZgN7Whwog5hnTOdP6Z7WMRB6DBH4lTSOde4Cz9eJUroi93klAOMpdwOwxNJuae6YQiNh3uoabNzW0NhkMBHGKU4Wf3/9Z+Z9yFL7DjydyYuH1gX28DHeoWeEAB0XPg8A2KduOs6uPwc3p48Upi+vctdpcTrRhbWhaxpBMuG/TIRNZBLGBh+2mIpzZpn66rJ49HcTcP2hw9HGERYlXkUtesiOecFeA3HD4cOxz1DxKIf9h3fBC2dP0udzTOjl8Gjg5J31iI8SRlEZ+d94yAfr0327TCxD9bsqfcmEkNMJITMJITPXrFkTA2UKALDnLR/gyHs+aWwymAjjqR7VS0Ydikd3chkdfouNBqD1uu/wdHoK5tCeeDU7AdtgkWj9+jvyjsswVleSFRJ881Mon+qlG7YBsMf+88qdBhVc8wty9Ctyt8pSHDe+p3S/QjgpiqrSS1IJHD2up/QmLpVge6pXlCRz8/Nx0d6DsOD6/UP5Y0Tt+c8bL+q8CDIodOrXVYSQLpTSFTmV+urc8WUArGmxuueOuUApvRfAvQAwduzYpmPkaoH4ZZVY/uNCI0xGq6iyYWWpfXPw+Be/Yv6aGunRK7YuRapuA76hA1znCNyLhqvSk0ON6ApFgyW2XGA9o04RvUCQlbJ+WZn/bYYpn2qjIfc3Tgndb24e/CKfXUcK/PxEYKRTHde7re14q+Ik1tbUYwvDtGVAxEFUFHE/1sbM5V5oCf0lACfnPp8M4EXL8ZNy3u4TAGy0qOYVFGwopA2dP459a3Dnu/Pw2g8rAdiZsN8atNMPVwIAvsn2Z573zyBmlwZkPIjZudzt44YZCwDuPt47YCXoGm0La+ZI6H79nDAKcpg2dM6AP/3VuwJerGiCjFoU3SpL8db5U/CXA4bYjl++/w4oTmro3IbvayECv3e7UJucxvRyj01CJ4Q8DmA3AB0IIUsBXAVgOoCnCCGnAVgM4Khc89cA7A9gHoCtAE6Niy6F5o8w74ln2IvEG/jmrFWhio4AwGDyKzqun4llA47D7B/calixrGb6X4N0v0Q0XiDI69zlndXcHXbp3wH7DxfzbZWdz7pxCeuVXtuQAQC0Ly+2jceT+Fl23LBozNSvjkCJWDGgU4Xr2D5DO2POdf6Ol3zI3Z24r9P0cm8EGT02hk4pPZZzaiqjLQVwdly0KLQM9L/iNVy8zyCpnXw6k3VkUeO/ZDIv+qs/rMAu/d2lTZ3je0m6E7VZAIAlQ84AfljKbCPu5c6X0HkR8mwJnQrN29jQLLpFnkQtGrO9pkbP311VUZQbTz/udFyzjvvqObtgcy1fRRw1sgwNTEIjyGSpp+e/CJpaVjlZdG9bCgAY2aOycQnJoaXGoSsUECs31mLj1qbplR4V0lmKv7/+s1Sf/n96HbOWbzK/eyemkMPWevaCLrqWjtPmYEtpV9SVs2O9Cdx2Q3dCkuD2XmZxloASOgBUVRTbx4+RT9iqrYUsprJ2cx2AfDiWEa7W2SPcbmjXNpjQt32g+VjwY8Bb6nUtQnlRXgZLePRp3ixaDsO6tcFb50/Bmbv2E2qvbOgKTR4T/v4OJt/4bmOTERuoTcoOM47YHCKoS/unEmOvuRQTtJ8wWfsB69rv6Dmvn/RkqvcC2NC5gwnMy8Jnl0/FdYcMCzi13HxWadzp6e85D+P+HDq6G9qXF+Gosbpf7tqcxN6JowlqjFrj9bnfWllxXt1vOO/5UZMIY4eRgLXyWaExoFMFNM51Rs1Y/cYzfx4tyYauUHhsKqAKsNCwhZ4JqoXZjJL/lslKuT+v3Ow6tmFrAzZYNCWstf+ExNu4LvUg0lTDdz0P445PiIBt1ZHEQvPYojvH6tOhHDv1bocvFuXzP4VZg4IwjqC80crQB3RsBQA4YWIv+9iCm4TeHcrx1V/2Mr8P6aLbeY8Zx6pH37hoVZxfspMe99u4rx9dujvKipIYc+1bvmP7PfuJPhqJV/84GXXpjO88jYWowxH5Ge+Md7IF2dAVmi+aUspLA0GqibEYtKeELvACnjqpNx78eBEAvhf0rGUbPceYon2P1bQSB9Zdhys6jkdlCInP7RQnPlZRUsNTZ0xE78teBZCLQw+hcnf2i1OStWZxa9+qGIumTxPqJ0JS/44VwuMVGmVFeQmdJ5ECeabSvW1ZZHM/fvoEz/OlRQmUFkXvMBgEXUJ6zIdBYyaWUQxdwYVCxt+KIhOIobsbenu5+4/pZbc0kKEUuw6swge/rAFLj9CZrMdP2V5YhXYghPio3L1hLNy8THGA3MIStDgLCyJDBHXI4iXyaekoK3JL6MyN0/ZkRHfgg4t3Q2Wpu555VM5/nVrrvhZjerZlnjdmibNaHw+KoSu40NgS+vtzVmNtTT2O2DGfNpVFkh+VTIYe8tISCQGGnqX494k7onprA+54d66TAgwji/BEdjcAAmFmPpWi3NJAuEUr7DiBF03Jbhkhg3noaZocrGYNLwldBk0xCU0Y9Gofry2/f8cKvHX+FPStasU8n9AI9h/eGcfuJJ8RMCwUQ1dwobGFn1Me/BIAbAzdpnIXHIe15ocNWxOR0CnV02N2bmNXP5ZjG65OPgyNUPxK9TzYXgyQkCBha77k8ccCP+NcoPFiZBTpgNXtWhKSHk5xge69uqXCYMXTGyCE4O7jdywgNXkohq7gQmM4c/jBuskQ1SBIq9wFrlvE8ctKn9F6B7IYd6buRH9tOV7KTMRDGT3bmEa8aXKHrTnP2z282TZ0idhyKtHWBzJjyM4XWJ3ZgsRRr99iy7nK6NCYtu1CQTF0BRea4g8+kIQuqXIX0UyIOJ1ZxyEEGEiW4OWiP6EGpbi84TQ8ntkDxpLrNZyI+tq5pocKW0N4Cb1Q/FLEht6cefdXf97T5jfy4cW7Y1OtPc9EPud8E3xhmxK2o9ujGLqCC01xgXjv59X5L2G83D06i0j+YgzdPs6O2i9IkiwOqfsrFlFnKlS/OHOx88acocLQCcGUAVUAgMN8yr6KjhdHW4AfYeA7T6BehUf7VvYkPT3bu73VvRi6XKa47QNO81RLhGLoCi40QX6Oc5/41vws+kIyGbRn2Jo/kgJOcTYJHQR9yQrU0hQWU3f9aC8NvkgcujNsjZnO1ScUzUghCugx2WFCtqxTiNS5DspNgjL0lgTDhs7SVgQzoat72tyhGLqCC01JQv9uSTVuf8fuKS5KHmvRDxu2JqbSzg904oKLMDD5Kb7P9gFlJGb0k6ScZ12bFJdTnPxSniAEmRgW86BZ40QgwtAjcxZrokjksgixHARlrrMxMt81BvKVCRuZkBihGLqCC01J+Dn/yW+xYO0W2zHTzuvTVzaxjAhPSwgInSazWf0zBm76FBlK8OeG3zDbekroACrL3fG09jaG2tUYL3i2tiiX9SN27O5SG3vSIDn+9hqHbkVS2dADoSXfLpXLPSaM/uubuOSZ7xqbjGBo4j9444VctG4rNm7jF6Rhqdw9begCFy7sFFe7CXj4QNRppZhcdzu+p+zCEcQaK8bAcTv1xAV7DfSgR/+bz+XubpPfALFpN6tD8ckQRkOO0Qqp2xF8ExHcht5ypFHNU+Uuf50tmdFtL1AMPSZs2NqAp2ayS2I2dTT1Hb/BeBeu3YJD//kxt5106lchCV3QKe77J4Etq/Fc76uwHO4yqwb81J0JjXgmqDBzuYuqLThz6GOEf+51udriRYIMPSiUDd0iobMYupTKPSqKmjacTnFHj216ufrDQjF0BRea+lJp5TtOdbwVsnHoIhsZEYZOaBZ47SIAwLLyod5tfUfzXnBNCd38HlzlHgWPrM/oAfHFSbGc3rL2248u3R2AoA2dMXZLYl4JDwldIQ/e3Tl4NLtscXOGYugKLjQpCd1DhewHplOcV6Y4gTFFGGZvmtPMaCnUpLwrVLHG69OhHKN7VgqVx3TncvfOPOdFA0vSk0Vdg8HQ5ZYWUUbbujQFAEiLpH6NGFceMATdKktjnWNo19bCbc/bcwDKihLYoYt/n5f/sAvevmDXMKQ1exg/saa0vEUNxdBbAKLOvd6kGDoLHPo+X7AO89fUeDbbVJs2a0sb+MNjX2Pgn16PTOW+G2bqH87+XKD8qfvYvsM64/mzJpkSppVJu2g0pOts8NSvew/Rw+mKU+GXA6NGfFwq91TOs7sR+Dl+s0sffHzZHrGN/9b5U3wrmlmxc78O+Omv+6JNbpNjhfN3Nbx7G/TvyM49bqCJv/WRoyX5UxhQDL0FIHL+20zf7KPv/QxTb/7A/M7amJzz+Dc46YHPbcde+X4F6jNZwcQy3ueLUY+TyOtA/z2B9v18Fw2WRO2cQ0blzprP77KuP2w4Prt8qq2SV1AYmyVpCV2wXV7N7M/RWWM25c3qgE4VaF3iZs5BIMOsWh5bY4M43pWWCMXQWwAykUvokQ4XOcKkfgWAzxasZx5fvbmOefzFsyeZn/1svmO1OehANgI7nS5Eo+7kTh3HiOd32znHKkUCvNGphIbOEdWPrkvrTnGyDF0U+VCtYP2bMD+PFC3JVyBqGDXlRZJENTeoOPQWgKiljqYkxbBeOfF66GLtkhpBOkvx6/qtzPPtW+Vjwf2WgHHaHGQoQaLnRL29r8rd33HLyqT3G94Zn8zvjhUbazFj7lpTQjdTv/rQFzfyErqYU5wBUec4TSPo3LoE5+45QJo2oDClga86cAhKUnLXr1A4/OOIkXjs818xtlfbxiYlcigJvQUgyBpFKcV3S6rZ58KREzvCVFtjobxY39du4sS0F1myyfgxnj5kJZahA1CiOyr5sSlCgMqyIscxp4SeR3EygRuPGImOFSW5c/YYcpYK39AAFEJqk7Wh7zqwCq2Kkzhtlz7Cc3x2xVShWtPMNLjCswTHqZP6NEotbCsCpX5tQhv5eKDflaqKYpy754AWmSFPMfSYUYiXJIhE/dzXy3DwPz/G6z+scI/XxHXuYVXuThhSrhFy5UTKytAZ1HQnawBQJJFGN7IWS7NVghTq443p2RYPnDLWVAU65/CS4olDQg9bbS0sDJW7KEOvqijGj9fsg2Hd2sRJlomm/tuOCnKFcfS/28edadlQKveYUZ/JSqsfZREkycbc1bo3uFccd1OFCJ+eMXcNnvt6mdB4xuJ35YuzmOetzElz8KnfJV7Fn1KPYQNthTQSqCIb8VQ6Hx7kXFdPndQbD368yDKe3mCPwZ1QnNSwtT7jYsosRzzjkLPGc6H4Oe8ZBHWKKxQU09p+0QIFchea5lvXzGGVAgoRXhNG6GD9yJuUDZ2pQs4jxXFsOfH+L/D8N2IM3c9z3S6h5xu3wyZclHwKALCStkUx6rGRluGVbD70yEm/U3JlTe2yoTNa5fOv+6dtNZl9ASzsRmhUVE52YcC63u1EQG90X4qmhJZvSshDSegxwOp1rofX2CX0K57/AQcM74Kd+/NTgsog+jj0SIdzYcOWeiQSxDdEh3ddH/yyxvwcBZPyU09aNw3Wpscn3kYxSWPvuhvwC2WnkXSOXOyo7mKdOx937qSPNa69LW0iKveL9xmMfYZ2xtCuhVGhy6KlL+4925Xh1/VbJaXR7YP9bw9XqST0GGBVgbPU4Y99/iuO+7/PXcejmC+KBSvuRW/0tW9hxNVv+rbjbSw+tDB0Q5sQhmY/Cd3J8DVkcVbiRVyYegbfZvtxmTkLLgmdxaydTnHMNva2p07SncqSQTLLRIiipIaxvds1Kg1eaErapzjw9BkTce+JOwZy+Grht2a7gGLoMSBrk9Dtb0kczNI6hax0/fTMpVi5sZY7nig+/GUNel/2KtbVsGO5WTAcqHgQ8Q0w7nWYYh0iUq3RJJWuwaOp63FJ6kl8m+2L8xvO8ulo/5pySOjWuXlUJHOG+yN27O6ix+hz+X6DsfDv+5s2eRFatke0dJV7p9Yl2Hto58YmQ6GRoBh6DLAxWMcKEkeVKOpS8Ytj4dotmPD3d2zpUINsOu6bsQAA8MOyjcJ91tbUe54XkaaM2xmmQAWLof/WEUZltBg8+05MTPyE29KH4aj6q7CQdnH1vWL/wZZ+4jZ0gwwnPQmN4Nsr98INh49w9bRK6mxv+O2Xi7PK4SopdPvF9vAuKIYeA6xM28loos7qBtg3EKIbBudiZzBk/RwbDZksHv18MXOOIC+LXwiRzK0Ks1FikZ7QCIZ0aY2L9s7XIp+qfYW+8/+L/6b3xG3pI1APtg/A6VPYtc8BN0NnbSZY9FSWFdnyyGsOlbsXtlcexvr9tHSVexBsB3xuu4FyiosBWQ8behxe79ZNgjBjczSrqUubn3mL3oMfL8T1r/0MADh+fC/fKb7+dQOenrkU1x86jMl4/GiV2fxEXUIymSB47dzJ5vdiksaFyWewpbwX/rruJOFxnJdd5HKKs30DIFZghRD5Qixq3VZQaNlQEnoMyHjY0L1U4rUNGSxYU4MtFuYqAq8NhCgSFs7CI3H9Fj2T2kZORjXAvk845t7P8PgXv5rZw5zwY8JZSoWZUJqTFEYELE1B0hpwXv0rvkj9HkO0xVjU/0Q0SOyDnfQLOcUJXDUBW8Wu4I3tJbGMQh7b0xNXDD0EPpm/lrlA2Bls1nGOP945j3+DPW7+AEOv+h8+X7BOmA4aQOXuhFXaY9ke/cBiLcYmoYHDbP3Un1SCR4dRuTcw+tri22fcgiKkcW3DCVja79jA8wAMCd1y55zZ37xAiLjE3dJDtWSg7gQf6t40fyiGHhDvzVmN4+77HPd/tNB1zsofZGzoH87Nh2PNXLxBmJZsEJW7A1ZpL6r139gkNGTYA6Y5xw3I2DvDqNxZ9yxhSOgLZwDfPY5X6QTcn9kfSMhZqVwqd6cNnfEGikjeBI0fc95cUJLScPJE3USkbOhutPRfUUu/PisUQw+IFdV6qNeCtTWuc142bS+Ga5XWZBZrLxU/D85WVocr3prnzE7mN7ARQhVUQhe1oa/eXBtKQmep61MJAiz+FHj6FKCyF27IHA9AfnFw3itn2JpNQnf89RxXRkTfTmH8IjRCzAI4ip9vf9ieHrli6KHBSC/p5RTnsaJYebiM8EUjkNCtKncrjcfe+5lQ/3yBh3xfY1NSH8aGLnAfvli4PpSEzurbc/2nwIP7AqDAkQ9iAyoBiJU79Trn9nJ3txV1dvNqd/NRozB5QAd0b1tqGX/73AFYtRnK/OABdW+aPRRDt6AunfF0+BKFV9iaF+MRSTLCQpCwNSesi72VoX/KsOVTUDw9cwnen7M6358xpl8Vs0/mr/WkV2R9aVWcxGs/rAjlFOd8JkmkMXzxQ0BJG+CPXwOdhpoXaFyn1RYuo00JkimOBV1A57fbsVdb/Pe08S6NwPYE4xlNG9HFUje+EQlqotheN3otEdvv287AqQ9+iZHX+Kck9YOXyt3Ly9b6Wkmp3DkbiE/mr8Vd785l9nn2q6W279b5/NY8SoGLn/kepzz4peuc1ekv4aNyv/GNObj97V8cY8tpG8b0aotFa7eGk9At9LXHRjyQ+ge6rP8C2PFUoLQSQP7ZaBrw3kW74ZPL9zD7yISPOZ3iYFO5S4Stgaj4YR8UJTV8/Ze9cP2hw11lZhXcaOl3Znt4XVQcugWfzPf3LM9mKV75YYWnfdfKtJ2OX3NWbuYPHlDlbl2krJ+Pu0/PF//tkmocMrobDhjRFQCweN0WrNtiz9Jm83LnXJtx2IvRWsPy/FTugDuznHVskcW3JKkhnc1KayZ++/BMTOjbDr+Z1AdZCpy35wBsrc9gv89OwEgyHz/3/y0GT73K1Y+AoE+HcvsxQsBbDp2X4KVytwzoS/9ug6qkGfr2sKA50a5ct50bUmhLZ1oKbmxPezjF0BmglJoLwOcL1mFUz0qzpvnz3yzDhU9/59nfyls+mb8WVRVF6N+xAgDw2//M5PYLuuBaf7Asz/G3Z6/G27NXmwx9S507h7pmU7mz5zEkWVYOduN+WSVlPwkdALbW28eybpQo9Y/JLkpqSGeobV6vDYSBt2evwtuzV2GfXN7rpEYwYPOXGK3Nwz8ajsLAYRdgsMUF3bw9DHK8JGrnpiThaGyvtsadwoUpA6swZWCVQMt4cNz4no02dxAoCV1he4BSuTNghFn9um4rjr73M/zlhR/Nc+u3eOcfB+xS5p3vzsOet3woNK9mS+0pzt5FwtasjISV3EYT8HI3bOF1DXyGaZ3fuAZeYhkA2NZgZ+iyMfWphIaGbNamNj/vyW98+xnY7ca3UYUNOOjHP+LI2X/EMtoez2d24Xqjs30F+M/KuITjxvfEXw4Ygjal9nSxNqc4gfGCICoe1rZMp33R9Gk4eefe0QxaIJj3VPFzF1q65mZ7Mk0pCZ2B2nQGRUnNZDZfLtJjwjNZir+9NpvZ59sl1fh8wTr8ftd+XCnAKanue9uHOHpcD7P0pfV3Rwhw34cL8LfXZuOhU8dht0EdufTayrVy5jYWYxYdAN/L3QqDkbOc3Izu1phz40WyHnOq851Z8azX8tzXS7HGp3pbKkFcEvprP6zktu9FVmIn7WfsSH7BOG0O+pCVqEMKyY0JfNLvfJw6ayTqUMQtQ8pitl4M2Ljenu3KcNoufVwbQpYGIq4FKOy4n14+NRpCGgHGpSsJnY+Wemta6nWxoBg6A3UNWaAkr1quqUtj9eZaLF63ldvnkH9+DAD4/a79uJLlbx6yO5H9vHIzrnn5pzxDdyR3MTYPZz7yNWZfuy93bruXe57ZEpL/Ma+tqcfXv27AmJ5tXWpuwOEU5yA/nckimdDM++EtoefPmSp3i4TuvDfbPFTud7w7jzuPgWRCQ0OG+krzO5I5uDb1EIZoiwEA1bQcX2YH4Z3sGHQla4Gx52BVxVDUzfopNy6b+7FTtfJhMBBjf+DcJ9hDFflagDCY0Lc9AOCECb1CjVOSSkRBTqMgH7YW3xw792tvCxNUUCg0FENnwGBchq15a10aO/3tHaG+lFKulDxj7lrPvtaF3KoWL0nxLSOPfr4Yf3o+bxKwCs+lqYSNeR929ydYNH0a04a+pT6N5dXb0LWy1CVF16azaJXIayycanIgz5jSDJW7VaJ33putTpW7ZPRZSiNoyGQ97eYEWfwt9QB6kVV4ML0Pnsjsjl9od1CLxen6dsMxqnOF+T2pscPLgkrUxn1x9rf2Ne67Z03zAOjcpgSLpk+LdMzmhrwNPb45HvvdhPgGV1AQgGLoDBg23631ujp4C0OiNbC5tgHT7phh68vyEhcpCmFd3K1q6lIPyej6V+0mAGMjUJfOMCXxhkwW2xrcxV9ufGMObnxjDnbq0w5fLFxvO3fx09/hXyfsiM21er9aBkM3YLeh5+dknQfsTnz/m7XSFU7nh2RCQzqT9bTT/ybxBgZrS/B05Wm4ZiVbbZxKEOzYqy0GdarAnFWbXRK66RPHcorzYMD9O7YCkI9uII69mfV+GJ946n6F4Mh7uW9H+ldBbC825u3hOpVTHANPfbkE81ZvxndLqn3bzltdg1nLN5nf69JZsJy67+DEg1thVblbGZ2h6jzlwS9w1qNfYe6qzZi9Qp8z6XDeMhjEBU+xPfHHXvc2amr51dyczBwAXv9Rt0lvqtWT7tR6ME/rRsRQudd7qNwNlfQjny3G7//7Fd78aRV3bBaSCYIt9Rl8v7SacZbij4nn8Kfko1hUsgPebMsvrGKEk7Uq0fe4Tqe4VO48a03wup879+sAABiQY+xOe7t102XcC6cnvEJ4GHd0e7KnykJtdpo/lIRuQTm2oS3ZjH9/CPz7wwWebfuS5Tg48QkWbxqAraQzKrANWRDU1dchk6WoQjUOSnyCrSjGBlqBpz61eLAjCwrYVL4AX+VuMJv35+jFWwynr0XTp9mrggF49LNf8cSXS/Dq9yuYdG/c1oBvl2xknvNCJkvNLHpWCf3Quz/G82dNMqnPMOLQtzVkMO2OGbho70F4z5JdzhgXAP5siSSQQSqnGr/7/fnmse5kNU5IvINDEzPQiVTj/cxIvNP1T54hcIaK/cARXfDV4g3o1a7Mdt5ICGPddN1/8li0LS/CYXd/wh23R7syfHr5HqhqVQzAbkMvSmjoYZnHYDbNtehKQ0MDli5ditraWt+29x3UBQAwezbbyTRqDG+Vxn0HdUGr4rT0nIWmtdCg6SzuO6gLihKkRV7jNVMqkc62waYVizB7dfORYUtKStC9e3ekUin/xjkohm7BVcn/4KjkB5hUezuWQY/xHUR+xWhtHtJIIEsJ2pLN2EP7FpMSs/ROWQDF+THS/7oJ2e574qXit9CF5KXd9ZnW+DHVC93JGvTVVqKOJrEerbGYdgL+9wnQdTQG0mr01TagJ1mFvqsXYQypx1aUoC3hx/w6Jck3ZvE9vA18vlC8NKuBfle8Zn6uszD0b36ttrWz2tDLinTNwtuzV2PW8k24+JnvsLbG7uUdRGIiyOKkxFvoQtZh8nygX2oDEshiB/IrupB1aEVq0UAT+CA7Ardkx+LpzK44INURhBE/b8DYGJ28c28cN76XKwFMymTo+WNTd+gkRG+XNnlHqdJUAufs0R/7j+iCwZ1b29o1d5X70qVLUVFRgd69e/umE23IaVR26F4ZP2EA1tbUYXn1NrQvL0K3tmX+HSwoNK2Fxtb6NMjqGpSmEhjQqcK/QzMDWbkJ9eksBnauMPOJNHVQSrFu3TosXboUffr0Ee6nGLoFA7RlAICPS87F3emD0IAkzk68gCSxq5i30mL8N70nns7sii5kHdqSGtTSIpSQeuye+Ra7z3sORaQB59Wfhc+yO2CgthSnFL+PjmQVFtIu+CnTC2toJTqRDehC1iPz+b1IZOvxCAAU5SaZBxya2yhkNmjYdENXvFBUhCw0LKVVWE7bo+7bbehJ6rAaFRhKFmFnbRYakMQa2gbLaXsspx2QKWmHTnUL0YAkCCgSyKJ4M8VIbQ2qUY4ltCOGkMV4OzsGacfPoRzb0J8sQ1tSg0rUYKQ2HxO1n/Deln3xPXZFKeqhQb83hAAJZGymAp0JUvy4eBUAjemQJFpRzUACGVycfBJnJF/Rn8WGtmhFUshAQw1K8U52DIaSRbitzSU4/ehD8dEjXyNbvU2n0UNCN1XqhKAo6W5X7KFylwEhBBfsPYh5Li6nuEKhtrZWiJk3BpoeRQoKfBBC0L59e6xZs8a/sQWKoefQkMliGy0yv5+VfAkAsDTRHX/YejpKSR1KUYe1tA1+pH2QzanLv6f9bOM8kdkDZQ216ELWYT7tBgBYmW2PWdo4rNvGTkqTrE9j3nl9ceNDT2POpiSWUV070IlsQAW2YqC2BL1qVqM9NkIDxSgyD/trnyP5wit4EkC6WHNtOmwo5p8yUEdTqEcSm1CGX7OdMDHxk6vNNlqEDDScue0+/Kb4QRSTNBpoAnjwQVy9fCnuKf4VDZ+UA/MHAq274uwNW3Bv8edoQ7ZiY3EZPsmMxh9wBjLI75JF44LHkF/wj9S/0U/TTQmbaBlOb7gAu+56EG74nzu87eIxgzCieyUu2XcQzn3iW1B4O8W4c6w7zifdKveoYdyKRBNkiKJoiszcCmUldqNpP7HtF0HeJcXQc6ipTaMd2Yx3M6Nwe/owTNJ+xNvZHfHm9b/Hr9e97UoI8t1Ve2Pf2z7Eio1ue+FWlJjM3IAX40ojCXQejjeL1mPg0Fb4OWcj/5nmVO3Zia4+SaTx4mGt8MZ7H6B080KUog7/zeyF9bQC7ckmdCNr0YWsR7fkJvzS0BEZaMhA000HINhGS9BTW4Vy1KIT2YDOZD220SK0JTUYoS1AlhI8mNkXn2cHYw2txCaUobL7YCxZsxEnJt5E7/pfMC/bDW3JZpxcvwobE+0wI9MHgzq3x+jSamD9AgytX4UPsiMxP9sVw7UF2C/xMR5KbcT3tC/20WaiFkXYhiJkZ/yCHqQN1tE2qEMKfcgKTNW+wXpUYA2txACyFH9KPYbaZAUert0LM7OD8FF2GDagNSZl2YyYxaC93g8/NbfB0OMUno1fSIITA6/gj0QigeHDh5vfjznmGFx22WXc9vfccw/Kyspw0kknhZq3d+/emDlzJjp06BBqnEKhVatWqKmpaWwyFCJGk2LohJB9AdwOIAHg/yil0ws19+baNNqTTfg62x/f0f74LtMfD506DiCE6XXcpjSFbpWlTIZuYHTPStPGLCIZpDNZV/wzty2SWFo+FO+XFeOHDXYnt2paYW4oSrUEtmXZtuPPMzswjxNk0QGbsCZXA9zAiweNwOXP/YD7Nx6I6oZ8mdmjTt0H0x/5Gh9Wr8Hve/XF6P31cU+96yN8vzRHWwb4beIdXKw9jMnkR3ycGYptKEIHshHaO1djhmFeoCRXv9p+xzKU4PkJz+Cqt+32/wZOOKDTBq5fl7/KnXs+t0GIU8IzvdybuJTblFFaWopvv/3WfcJ0c7cfPuOMM+ImyReZTAaJRHy23XQ6jWSySS31CjGhyTxlQkgCwD8B7AVgKYAvCSEvUUrdut8YsHlbLbpiM9ahjXnMiCF+8JRxOODOjwAAv92lDy7ax24DnX7YcGyqbcD1r/1sO966JO+d6KdZrm3IoCFDuRnKWPh68QbfECdZGzWge987mTkAdK0sBSHAVkdimiFX/s/8bA3DchaKeYLug0frJqEE9diAvEPY12f3xS33/BtVpBrFSKOKVOP+9H5ohW3oTNajDikspF1wSkVXAHaGnmHkpQfYoV8Hj+qKV39ge//7qtxz50UKvwSFqXJvpjb0pozRQwZi6v4H49MP3kHrVuV47LHH0L9/f1x99dVo1aoVLrroItxxxx245557kEwmMWTIEDzxxBNYv349zjvtRCz9dRHatanAvffeixEjRmDdunU49thjsWzZMkycONGWe+KRRx7BHXfcgfr6eowfPx533323i2H37t0bRx99NN566y1ccsklaNeuHa666irU1dWhX79+ePDBBzF79mz8/e9/x3PPPYcXX3wRxxxzDDZu3IhsNoshQ4ZgwYIFuO+++3Dvvfeivr4e/fv3x3//+1+UlZXhlFNOQUlJCb755htMmjQJf/zjH3HcccehpqYGBx98cKFvv0KB0GQYOoCdAMyjlC4AAELIEwAOBlAQhl63YTmSJIsVtL15rKxIvz3DurXBeXsOwG1vz0VZUcKVArNteRHTO7SiJH97t9ankUoQdG5TgiXrt7naPvjxIqzZXCeVXtMvtA7gl0IVQc92ZfjrwUPNuufty4ugEcLM5W7AiFUH2DHn21CCbSixHd9S3guPZPZiD2gZorTIzXSdm4aTJvbCfz5dzMxXv/fQzmhdksQmRty4M1rAieJUIRh6y4lDv+blWfjJkp/BCSOHf3mx+BI0pGtrXHXgUM8227Ztw6hRo8zvl19+OY4++mgABK0qWuOtj77Ee688g/POOw+vvPKKre/06dOxcOFCFBcXo7q6GgBw1VVXYfCwEbjt/kex9pevcdJJJ+Hbb7/FNddcg1122QVXXnklXn31Vdx///0A9NC2J598Eh9//DFSqRTOOussPProo0yVfvv27fH1119j7dq1OOyww/D222+jvLwcN9xwA2655RZcccUVprZhxowZGDZsGL788kuk02mMHz8eAHDYYYfhd7/7HQDgz3/+M+6//3788Y9/BKBHHXzyySdIJBI46KCDcOaZZ+Kkk07CP//5T+F7rtC80JQYejcASyzflwIY72xECDkdwOkA0LNndCUc0xv0DGXLbQw9z1yNKllVrfPMyGAlFSVJ5kJfUWItiEIxumclahuyANwM/YY3dOm+Q3mR61wYhEl1ed9JYzHIkg5V04hvtqWN2xpQn86iels9GhzSM8+PwLNGvAWsjHlpxwUajJlXspWXFMdPM2JI6F4Z6cJCSejhwVW5A9jv4CMAAMceeyzOP/981/kRI0bg+OOPxyGHHIJDDjkEAPDRRx/hb3c9CADYY489sG7dOmzatAkffvghnnvuOQDAtGnT0LZtWwDAO++8g6+++grjxo0DoG8wOnZkF1bSNxrAZ599hp9++gmTJk0CANTX12PixIlIJpPo168fZs+ejS+++AIXXHABPvzwQ2QyGUyePBkA8OOPP+LPf/4zqqurUVNTg3322ccc/8gjjzQ1Ax9//DGeffZZAMCJJ56ISy+9VOBuKjQ3NCWGLgRK6b0A7gWAsWPHRmbSpBv1vcSfjt0L7z+qhwoUW+yqJ07ohbKiBI7YsYeVFgD6Ym+o561w5mAvSSZcjP/6Q4fjiud/ML93qLC7pBclNE+J2A+ZLMXI7m3wXc6W3bl1CVZu8k/8AeSdyO48djSqc0ll/DwvN25rwJ+e/wFPM1K41nKKunjViHdQ5DqSdtybPENn/zR4Eraol7tXbfewMChurollrPCTpI3MfiMKGdttqz3vvsevvvoqPvzwQ7z88sv429/+hh9+0N/LDq2KhXMDUEpx8skn4+9//7tv2/LycrPPXnvthccff9zVZsqUKXj99deRSqWw55574pRTTkEmk8E//vEPAMApp5yCF154ASNHjsRDDz2E999/3zW+1zUrtCw0pbQ5ywD0sHzvnjtWEJS16YjvyiaiY/f+uOHw4RjVo9L2AiQTGo4e19MmPbXPZf8qSmqoLCvCj9fsYxvTuTCvqalzHetbZX/p2pcX22tkO97BW48eyaT/gVPGAtA3IVceMATPnrmzee7R303AexfthkXTp6FLpa5hOHVSb+Y4dvr1vweO7IoTBSt1LVm/lcnMw+CIHbujvChhqvDLLZoTQ0Lv26Ecv5vcB0UJe7rZ3QZ2RP+OrfDHPfoDAI4a2505h5/KvTA2dP1ammtimaYMjQAfvP4iOrUuwZNPPomJE+2RI9lsFkuWLMHuu++OG264ARs3bkRNTQ0mT56M/730DIZ0bYP3338fHTp0QOvWrTFlyhQ89thjAIDXX38dGzboJZanTp2KZ555BqtX6xkR169fj8WLF3vSNmHCBHz88ceYN08Pv9yyZQt++eUXAMDkyZNx2223YeLEiaiqqsK6deswZ84cDBs2DACwefNmdOnSBQ0NDXj00Ue5c0yaNAlPPPEEAHDbqZC+5o+mxNC/BDCAENKHEFIE4BgALxVq8uFTDsbIS95Am7btcPS4nnjh7Em+fW48fASuPGAIhnfTHelaFSdx0Miu5nmn6nR0j0p3+UzozLVzTpVflNRszMU5xqGju+PBU8a5aBnTU1f5FSU0/GaXPhhsUZW3Kk6iTwd94zB5gB7jfvCobq4xnGDt6GssNvIHT3XT4cwExwLLA52HfxwxAjcdORKz/rqv6eBnrQ1/0sTeqCxL4bHfTcCfpg0xU6lW5TQdbcpSePuCXTEw5+Pw98NGYP/hnQEANx4xApW5OvF+KvfRvfT7G2d5zKxSuYeGYUM3/tlC1uq3YOyYUbj99ttx66232vplMhmccMIJGD58OEaPHo1zzjkHlZWVuPrqq/HVV19hxIgRuOyyy/Dwww8D0G3rH374IYYOHYrnnnvONP8NGTIE1113Hfbee2+MGDECe+21F1asYDtiGqiqqsJDDz2EY489FiNGjMDEiRPx88+6CW78+PFYtWoVpkyZAkA3CwwfPtx8N6+99lqMHz8ekyZNwuDBg7lz3H777fjnP/+J4cOHY9mygslJTQPb0U6lyajcKaVpQsgfAPwPetjaA5TSWY1MlifalhfhN7vY0/LdcexovPTdcgBuCf26Q4fhhtfn4LulG9GtshTLqrehPpPFVQcOxSX7DMYTX/6KPQZ3RFFCM2211hCmqw8cAgDYfbDbJme84ANzjJzHNM/fcwBOm9QHbcpSKEpq6NWuDHNXs+NRWWzFymzKLDbt6w8djpKUxi0KY8URO3bHY5//6tsOAI4cm1fa7D2kEw4a2RWX7z/Y9FYf1LkC3165t23syrIiTGXcI4P+imKdiaczVFi9fcL4nhjfp525MYgDRnGMlqBybyxkMvz0vhdffDFuuOEG27Grr77a/PzRRx+5+rRr1w4vvPCC63j79u3x5ptvMuc5+uijTfs4D4sWLbJ932OPPfDll1+62pWWlqKurs78fu+999rOn3nmmTjzzDNd/R566CHb9z59+uDTTz81v1933XWe9Ck0TzQZhg4AlNLXALzm27CJ4z+/2Qk1dWlM6tcBi9dtwes/rsTO/dqjOJnA5fsPxpFju2POys0478lv0a9Kt72XFiVw6iR9c9CmLIXNOS9gY20/csfuOGUSP6dvm9IUHjhlrCmpG2pbp0RJCEGbnFT6y3X7YeO2Boy8Rl+Y+laV47+njceJ//c5Fqzd4rLnO2H1UD5wZBdUlKRw2Jju6H3ZqzhkVFdM3aETNm5rMAuvVBQnsbkubbNXD+5cgZ9XbsZx43vamPy1hwxzFUgpSSVwx7GjAQBPnD7B5UVvXN9eQ7xzrF+4z0BsqU/j4FFd0aY0hatfnmU6PfJACImVmQN5pziZ0EUFBQUFA02KobcUTBlYZX7+1wk7Yuai9dihix53nUpo2KFLa+zQpTUOGc1We//nNzth39tmoD6TNSViL6HNsG/vMTjPyAgheOjUcea8PFjHTWoE3SpL8cAp40CIPY7egNVRfWjX1rj5yJGY0K+9zaN/7t/2Q4IQaBpBNktRlNBQlNTwwMcL8f3SjShKaphxye5YtG6LaQKglGJQpwr07lCOQZ0q0LlNiXNqGyb0be953gsdK0pw13FjAADTRnTBtBFdAo8VJZp7tbWmDKdErGDF9vF72x6uUjH0AmBs73ZS7ftWtcJXf9kTf3nhRwzq3Bo3vPEzN8vZBxfvhl7ty5nnrLZmHqzMY81mXbXXuwN7PCsqy1IghODwHd1OZlYfAE0jOGqcrjZ/8JNFufMEPdqV2UqHEkJw8s69fedtijhtlz5oW5bCTW/+EmocQ+WubOgKhYTxusrkwFBommhKTnEKFlSUpHDbMaNNpy0ewr6EVtYxrFsbbjsDhoB+IadimAj8PMqbG/5ywBD8YY8BAPzD37xgqtwVQ1coIIqSCfStaoXulfE5fCoUBkpCb+IwFnmeFrZYwmOcBauEfuvRoyT6yc9lhGW1NIZu4Ier9w4V65tt5uVTFZovWklk7FNoulBPsZmjOBlSQrfwDpGX2qzZHYJxtVQTcQXD50AGZrW1lnqDFBQUYkXLFJVaEAy7Km+Nl4npZsE6rgyTDiNEKobFhkr9Gg1eeOEFEELMWG4FNhYtWmQmqHFixYoVOOCAAwAA77//vvlZBtXV1bj77ru553/zm9+gY8eOLhrWr1+PvfbaCwMGDMBee+1lJu2hlOKcc85B//79MWLECHz99dfSNLFw5ZVX4u233w49TqtW7myhIjjmmGMwd+7c0PMDiqE3eYztpTvU7T20s+34PSfsiF0HVoVe/K3OdjJjBVEtKy9uMSiGHg6PP/44dtllF2Yq1SDwim2PEnHPk067ixLxcMstt5hFX4LCj6GfcsopeOONN1zHp0+fjqlTp2Lu3LmYOnUqpk/Xq2i//vrrmDt3LubOnYt7772XGX8fBH/961+x5557RjJWEJx55pm48cYbIxlLMfQmjkGdK7Bo+jTs7vBY33dYZzz8m51Cj2+X0P3bR5FvXNmIvaE0GMFRU1ODjz76CPfff7+Z6vSNN97AkUceabaxSpxvvvkmJk6ciDFjxuDII49ETY2eZKl379649NJLMWbMGDz99NO47777MG7cOIwcORKHH344tm7dCgCYP38+JkyYgOHDh+PPf/6zTUr7xz/+gXHjxmHEiBG46qqrmPS2atUKF154IUaOHIlPP/0UjzzyCHbaaSeMGjUKv//975HJZPD000/jggsuAKBnfOvbty8AYMGCBWZBl7/+9a8YN24chg0bhtNPP900je22224477zzMHbsWNx+++346quvMHLkSIwcOdKz6tqzzz6Lfffd13X8iy++wMSJEzF69GjsvPPOmDNnDgBg1qxZJt0jRozA3Llzcdlll2H+/PkYNWoULr74YtdYU6ZMQbt27gigF198ESeffDIA4OSTTzYT+7z44os46aSTQAjBhAkTUF1dzczCx7qHANCusg3OP/98DB06FFOnTsWaNXrNjlNOOQXPPPMMAOCyyy7DkCFDMGLECFx00UUAdE3GHnvsgREjRmDq1Kn49Vc9X8bChQsxceJE89lbwXr2W7ZswbRp0zBy5EgMGzYMTz75JAA9ve/bb78tteHiQdnQt3NYGbOM1B2GJyt+7o1ES0gs8/plwMofuKf75hInQcYZq/NwYL/pnk1efPFF7Lvvvhg4cCDat2+Pr776CnvuuSdOP/10bNmyBeXl5XjyySdxzDHHYO3atbjuuutcZUuvvPJKAPnypgCwbt06ZpnSc889F+eeey6OPfZY3HPPPSYdb775JubOnYsvvvgClFIcdNBB+PDDD80Urga2bNmC8ePH4+abb8bs2bNxww03uEqv7r333qYEN2PGDLRv3x7Lli3DjBkzzPH+8Ic/mHSfeOKJeOWVV3DggQcC0Ku3zZypF0AaMWIE7rrrLkyZMoXJZAGdUbVt2xbFxe7EUoMHD8aMGTOQTCbx9ttv44orrsCzzz6Le+65B+eeey6OP/541NfXI5PJYPr06fjxxx+51e94WLVqFbp00XNDdO7cGatWrQIALFu2DD165DNHdu/eHcuWLTPbAuzytS8/9xT2P+xobNmyBWPHjsWtt96Kv/71r7jmmmtw1113mX3XrVuH559/Hj///DMIIWYJ3T/+8Y84+eSTcfLJJ+OBBx7AOeecgxdeeAHnnnsusyQt79mvWbMGXbt2xauvvgoA2LhRL5ilaRr69++P7777DjvuuKPUvXJCSejbOaRZRwi1uYqzFoOS0IPj8ccfxzHHHANAt00+/vjjSCaT2HffffHyyy8jnU7j1VdfxcEHH2wrWzpq1Cg8/PDDtkIq1vStP/74IyZPnozhw4fj0UcfxaxZelbqTz/91JT+jzvuOLP9m2++iTfffBOjR4/GmDFj8PPPPzPtpIlEAocffjgAe+nVUaNG4Z133sGCBQvQuXNn1NTUYPPmzViyZAmOO+44fPjhh5gxY4ZZRvW9997D+PHjMXz4cLz77rsmfdbrqK6uRnV1tbkJOPHEE5n3cMWKFaiqqmKe27hxI4488kgMGzYM559/vjnPxIkTcf311+OGG27A4sWLUVoaTQgcIURK0GDdw6WLFwHQGadxL0444QRXqt82bdqgpKQEp512Gp577jmUlel5Mj799FPz2Z544olmv48//hjHHnusedwA79kPHz4cb731Fi699FLMmDEDbdrkw4Q7duyI5cuXS94dN5SEvp0jKO8Iw3OUDd0bWkvYZvtI0gtiKJ+6fv16vPvuu/jhhx9ACEEmkwEhBP/4xz9wzDHH4K677kK7du0wduxYVFRUeJYtBezlR73KlLJAKcXll1+O3//+957tSkpKzJrlXqVXd955Zzz44IMYNGgQJk+ejAceeACffvopbr75ZtTW1uKss87CzJkz0aNHD1x99dWorc2XSHaWUfVDaWmprb8Vf/nLX7D77rvj+eefx6JFi7DbbrsB0Dcz48ePx6uvvor9998f//73v03TgCw6deqEFStWoEuXLlixYoVZT75bt25YsmSJ2W7p0qXo1s2ebZN1D39esYlZgtq5UUgmk/jiiy/wzjvv4JlnnsFdd92Fd99915NW1mbD69l//fXXeO211/DnP/8ZU6dONbUqtbW1kWyCWsLSoRACQeOmw8RbK4bujWSL4OjeiENL88wzz+DEE0/E4sWLsWjRIixZsgR9+vTBjBkzsOuuu+Lrr7/GfffdZ0rwXmVLneCVKZ0wYQKeffZZADBt9gCwzz774IEHHjBt8suWLTNLqvLgVXp18uTJuOmmmzBlyhSMHj0a7733HoqLi9GmTRuT+Xbo0AE1NTWmPdiJyspKVFZWmhImr4zqwIEDualyN27caDJRawGYBQsWoG/fvjjnnHNw8MEH4/vvv0dFRQU2b97sec0sHHTQQWZVu4cffhgHH3ywefw///kPKKX47LPP0KZNG5u6HWDfw2VLdZt3Nps1781jjz2GXXbZxda3pqYGGzduxP77749bb70V332nF5raeeedbaVnDa0IryQt79kvX74cZWVlOOGEE3DxxRfbvPR/+eUXbsSBDFr+yqEQC0KFralfnSe2B4vEoE4VGNQ52mI3jz/+OA499FDbscMPPxyPP/44EokEDjjgALz++uumQ5xX2VIneGVKb7vtNtxyyy0YMWIE5s2bZ6pR9957bxx33HGm09QRRxzhy9y8Sq9OnjwZ/9/e/QdZWdVxHH9/AnTXNVzB0mJJQJhE13VRRGmRKXXAkMlomIp0cBDoHyizRpKpxqFpJmscCJlybITVSEEjDcdpUn5YWZnoqiMIEpgmmAKuiiDTqPXtj+fcZYHlx/0h93L385q5w33O89zL2e+eu9/7nHOe52zZsoXRo0fTo0cP+vfv35GQ6uvrmT59Oo2NjYwdO5YLLjhwWeOc1tZWZsyYQXNzc8fEuf3V1dVxxhlndHzR6WzWrFnMnj2bYcOG7TOJ67777qOxsZHm5mbWrVvH5MmT6du3Ly0tLTQ2NnY5Xj9p0iRGjhzJxo0baWhoYOHChUA2MW3FihUMGTKElStXdiyBO27cOAYNGsTgwYOZPn16lzPou4rhjjQGX1dXx5o1a2hsbGT16tUdZ8c5u3btYvz48TQ1NTFq1Cjmzp0LwIIFC2htbaWpqYnFixczf/584OBL0h7sd7927dqOyXpz5szpmEi3bds2amtrOe20fa9kKoQO9ks9FgwfPjxykz2scANuzCZpvHzzFYc99nO3/JGX3niXX1x1HuPOyW9RkytufYzn//0OP53YxJc7LYtqmXx+D5Vow4YNDB06tNzVOKr27NlDbW0tkli6dClLlixh+fLl5a5W0R544AHa2tqqYpnVXJf7Z85s6DhrriTz5s2jd+/eTJ069YB9XX2mJLVFxPCu3stj6FYQ31im9O6ediEPPXfgZThWudra2pg5cyYRQX19PYsWLSp3lUpiwoQJtLe3l7sa3UJ9ff1BJyjmywnd8pLr0SlqDN1d7l1qGXwKLYNPKXc1LA8XX3xxx1hrtZk2bVq5q1BSb769s9xV6NKUKVNK9l7+02oFKeiyNd8pzszsQ+OEbnnZe6e4wt/D16FXr2N5To5ZJSnks+SEbgUp7MYyhb/WKl9NTQ3t7e1O6lZRetdmqyAeS7ecjgja29upqanJ63UeQ7e8HG599iPhhF6dGhoa2Lp1a8c9ss0qQQR8JIJNu46tCac1NTU0NDTk9RondCtIUYuzOJ9XpV69ejFw4MByV8Os23KXu+Uldz/2YhK6x9DNzErPCd0KUkhOzo2tusvdzKz0nNCtMMWMofsM3cys5I7pW79K2gH867AHHrlTgDdK+H7dleNYPMeweI5h8RzD0ihlHE+PiC7Xtz2mE3qpSXrqYPfItSPnOBbPMSyeY1g8x7A0jlYc3eVuZmZWBZzQzczMqoAT+r5+We4KVAnHsXiOYfEcw+I5hqVxVOLoMXQzM7Mq4DN0MzOzKuCEnki6XNJGSZsl3Vju+lQqSf0lPSppvaTnJV2XyvtIWiFpU/r35FQuSbemuD4n6bzy/gSVQ1IPSc9IeihtD5T0RIrVvZKOS+XHp+3Naf+Asla8Qkiql7RM0guSNkga6XaYP0nXp8/yOklLJNW4LR6apEWStkta16ks77Yn6Zp0/CZJ1xRbLyd0sj+swM+BzwNnAZMknVXeWlWsD4DvRMRZwEXAjBSrG4FVETEEWJW2IYvpkPT4OnDb0a9yxboO2NBp+yfAvIgYDLwFTE3lU4G3Uvm8dJzBfOAPEXEmcC5ZLN0O8yCpH/BNYHhENAI9gK/itng4dwKX71eWV9uT1Ae4CbgQGAHclPsSUCgn9MwIYHNE/DMi3gOWAleWuU4VKSJei4in0/NdZH9E+5HF66502F3AF9PzK4FfRebvQL2kTxzdWlceSQ3AFcAdaVvAJcCydMj+MczFdhlwaTq+25J0EjAaWAgQEe9FxNu4HRaiJ1ArqSdwAvAabouHFBF/Bt7crzjftjcWWBERb0bEW8AKDvySkBcn9Ew/YEun7a2pzA4hdbcNA54ATo2I3PqErwOnpueObdd+BswC/pe2+wJvR8QHabtznDpimPbvTMd3ZwOBHUBrGra4Q1Idbod5iYhXgVuAV8gS+U6gDbfFQuTb9kreJp3QrSCSTgR+C3wrIt7pvC+ySyd8+cRBSBoPbI+ItnLX5RjWEzgPuC0ihgHvsreLE3A7PBKpi/dKsi9InwTqKPIs0crX9pzQM68C/TttN6Qy64KkXmTJ/O6IuD8Vb8t1YaZ/t6dyx/ZALcAXJL1MNrxzCdl4cH3q9oR949QRw7T/JKD9aFa4Am0FtkbEE2l7GVmCdzvMz2XASxGxIyLeB+4na59ui/nLt+2VvE06oWeeBIakmZ3HkU0KebDMdapIabxsIbAhIuZ22vUgkJuleQ2wvFP55DTT8yJgZ6duqW4pImZHRENEDCBra6sj4irgUWBiOmz/GOZiOzEd363PPCPidWCLpE+nokuB9bgd5usV4CJJJ6TPdi6Obov5y7ftPQyMkXRy6ikZk8oKFxF+ZO1xHPAP4EXge+WuT6U+gFFkXUnPAc+mxziycbRVwCZgJdAnHS+yKwheBNaSzaYt+89RKQ/gs8BD6fkgYA2wGfgNcHwqr0nbm9P+QeWudyU8gGbgqdQWfwec7HZYUBznAC8A64DFwPFui4eN2RKyOQfvk/UWTS2k7QHXplhuBqYUWy/fKc7MzKwKuMvdzMysCjihm5mZVQEndDMzsyrghG5mZlYFnNDNzMyqgBO6mXVJ0g8lXVaC99ldivqY2aH5sjUz+1BJ2h0RJ5a7HmbVzmfoZt2IpKslrZH0rKTbla3JvlvSvLQm9ipJH0vH3ilpYnp+s6T1aT3nW1LZAEmrU9kqSZ9K5QMlPS5praQf7ff/3yDpyfSaOUf75zerZk7oZt2EpKHAV4CWiGgG/gtcRbYgx1MRcTbwJ7I1mju/ri8wATg7IpqAXJJeANyVyu4Gbk3l88kWTTmH7G5aufcZQ7Ym9Aiyu7ydL2l06X9Ss+7JCd2s+7gUOB94UtKzaXsQ2RKu96Zjfk12e9/OdgL/ARZK+hKwJ5WPBO5Jzxd3el0L2a0xc+U5Y9LjGeBp4EyyBG9mJdDz8IeYWZUQ2Rn17H0KpR/sd9w+E2si4gNJI8i+AEwEZpKtEHcoXU3OEfDjiLg9r1qb2RHxGbpZ97EKmCjp4wCS+kg6nezvQG5lra8Bf+n8IkknAidFxO+B64Fz066/ka0WB1nX/WPp+V/3K895GLg2vR+S+uXqYmbF8xm6WTcREeslfR94RNJHyFaKmgG8C4xI+7aTjbN39lFguaQasrPsb6fybwCtkm4AdgBTUvl1wD2SvsveJSSJiEfSOP7j2Uqd7AauZu+60WZWBF+2ZtbN+bIys+rgLnczM7Mq4DN0MzOzKuAzdDMzsyrghG5mZlYFnNDNzMyqgBO6mZlZFXBCNzMzqwJO6GZmZlXg/843ZXv7lqe0AAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1649482017246
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the rewards\r\n",
        "plt.figure(figsize=(8, 6))\r\n",
        "plt.title('DQN Agent')\r\n",
        "plt.plot(episode_rewards, label='Episode reward')\r\n",
        "plt.plot([np.mean(episode_rewards[::-1][i:i+100]) for i in range(len(episode_rewards))][::-1], label='Average reward (last 100 episodes)')\r\n",
        "plt.ylim((-50, 200))\r\n",
        "plt.xlabel('episode')\r\n",
        "plt.ylabel('reward')\r\n",
        "plt.legend()\r\n",
        "plt.show()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 576x432 with 1 Axes>",
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "execution_count": 15,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1649440027918
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the rewards\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.title('DQN Agent')\n",
        "plt.plot(episode_rewards, label='Episode reward')\n",
        "plt.plot([np.mean(episode_rewards[::-1][i:i+100]) for i in range(len(episode_rewards))][::-1], label='Average reward (last 100 episodes)')\n",
        "plt.ylim((-50, 200))\n",
        "plt.xlabel('episode')\n",
        "plt.ylabel('reward')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 576x432 with 1 Axes>",
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "zwNvAYZr02RA",
        "outputId": "133ead6c-12ab-4a0d-bd60-8c49beb5f113",
        "gather": {
          "logged": 1649427420436
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "idx = 1015\r\n",
        "\r\n",
        "s_0_img = d[idx][0].reshape(56, 56, 3)\r\n",
        "s_1_img = d[idx][3].reshape(56, 56, 3)\r\n",
        "action = actions[d[idx][1]]\r\n",
        "\r\n",
        "print(f'Action: {action}, reward: {d[idx][2]}')\r\n",
        "fig, ax = plt.subplots(nrows=2, ncols=3, figsize=(12, 8))\r\n",
        "ax[0, 0].imshow(np.round(s_0_img[:, :, 0]), cmap='gray')\r\n",
        "ax[0, 1].imshow(np.round(s_0_img[:, :, 1]), cmap='gray')\r\n",
        "ax[0, 2].imshow(np.round(s_0_img[:, :, 2]), cmap='gray')\r\n",
        "\r\n",
        "ax[1, 0].imshow(np.round(s_1_img[:, :, 0]), cmap='gray')\r\n",
        "ax[1, 1].imshow(np.round(s_1_img[:, :, 1]), cmap='gray')\r\n",
        "ax[1, 2].imshow(np.round(s_1_img[:, :, 2]), cmap='gray')\r\n",
        "\r\n",
        "ax[0, 0].axis('off')\r\n",
        "ax[0, 1].axis('off')\r\n",
        "ax[0, 2].axis('off')\r\n",
        "ax[1, 0].axis('off')\r\n",
        "ax[1, 1].axis('off')\r\n",
        "ax[1, 2].axis('off')\r\n",
        "plt.show()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Action: [0. 1. 0.], reward: -0.4000000000000057\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 864x576 with 6 Axes>",
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "execution_count": 37,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1649421639357
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Render the DQN agent"
      ],
      "metadata": {
        "id": "JsWoSJDwlfkl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython import display as ipythondisplay\r\n",
        "from pyvirtualdisplay import Display\r\n",
        "display = Display(visible=0, size=(1400, 900))\r\n",
        "display.start()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 16,
          "data": {
            "text/plain": "<pyvirtualdisplay.display.Display at 0x7f314201ead0>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 16,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1649538340469
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Utility functions to enable video recording of gym environment and displaying it\n",
        "To enable video, just do \"env = wrap_env(env)\"\"\n",
        "\"\"\"\n",
        "\n",
        "def show_video():\n",
        "  mp4list = glob.glob('video/*.mp4')\n",
        "  if len(mp4list) > 0:\n",
        "    mp4 = mp4list[0]\n",
        "    video = io.open(mp4, 'r+b').read()\n",
        "    encoded = base64.b64encode(video)\n",
        "    ipythondisplay.display(HTML(data='''<video alt=\"test\" autoplay \n",
        "                loop controls style=\"height: 400px;\">\n",
        "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
        "             </video>'''.format(encoded.decode('ascii'))))\n",
        "  else: \n",
        "    print(\"Could not find video\")\n",
        "    \n",
        "\n",
        "def wrap_env(env):\n",
        "  env = Monitor(env, './video', force=True)\n",
        "  return env"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "id": "0MGVX0pBk6I7",
        "gather": {
          "logged": 1649538560141
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_stacked_state_live(gs_buffer):\r\n",
        "    \"\"\"Returns a stacked image from the grayscale buffer.\"\"\"\r\n",
        "\r\n",
        "    # Create image from grayscale buffer\r\n",
        "    img = np.zeros((56, 56, 4))\r\n",
        "    img[:, :, 0] = gs_buffer[0]\r\n",
        "    img[:, :, 1] = gs_buffer[4]\r\n",
        "    img[:, :, 2] = gs_buffer[8]\r\n",
        "    img[:, :, 3] = gs_buffer[12]\r\n",
        "    img = np.reshape(img, (1, 56, 56, 4))\r\n",
        "\r\n",
        "    # Remove first image from buffer\r\n",
        "    gs_buffer.popleft()\r\n",
        "    return img"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1649538561231
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results['actions']"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 9,
          "data": {
            "text/plain": "array([[ 0. ,  1. ,  0. ],\n       [ 0. ,  0.5,  0. ],\n       [ 1. ,  0. ,  0. ],\n       [-1. ,  0. ,  0. ],\n       [ 0. ,  0. ,  1. ],\n       [ 0. ,  0. ,  0.5],\n       [ 0. ,  0. ,  0. ]])"
          },
          "metadata": {}
        }
      ],
      "execution_count": 9,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1649538864751
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "actions = results['actions']\r\n",
        "model = results['model']\r\n",
        "\r\n",
        "render = True\r\n",
        "\r\n",
        "episode_rewards = 0\r\n",
        "\r\n",
        "env = wrap_env(gym.make(\"CarRacing-v0\"))\r\n",
        "s_0 = env.reset()\r\n",
        "s_0 = image_processing(s_0, 56)\r\n",
        "grayscale_state_buffer = deque([s_0]*13)\r\n",
        "s_0_stacked = get_stacked_state_live(grayscale_state_buffer)\r\n",
        "\r\n",
        "i = 0\r\n",
        "while True:\r\n",
        "    if render:\r\n",
        "        env.render()\r\n",
        "    if i < 5:\r\n",
        "        a_0 = 0\r\n",
        "    else:\r\n",
        "        a_0 = np.argmax(model.predict(s_0_stacked))\r\n",
        "    s_1, reward, done, _ = env.step(actions[a_0])\r\n",
        "    episode_rewards += reward\r\n",
        "\r\n",
        "    if done:\r\n",
        "        break\r\n",
        "\r\n",
        "    # Append latest state and get new stacked representation\r\n",
        "    s_1 = image_processing(s_1, 56)\r\n",
        "    grayscale_state_buffer.append(s_1)\r\n",
        "    s_0_stacked = get_stacked_state_live(grayscale_state_buffer)\r\n",
        "\r\n",
        "    i += 1\r\n",
        "\r\n",
        "env.close()\r\n",
        "if render:\r\n",
        "    show_video()\r\n",
        "\r\n",
        "print(episode_rewards)\r\n"
      ],
      "outputs": [],
      "execution_count": 12,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1649539046149
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env.close()"
      ],
      "outputs": [],
      "execution_count": 14,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1649482231103
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_q_model():\r\n",
        "    \"\"\"Returns a CNN model.\"\"\"\r\n",
        "\r\n",
        "    model = Sequential()\r\n",
        "    model.add(Conv2D(32, 8, activation='relu', strides=4,\r\n",
        "            input_shape=(56, 56, 3,)))\r\n",
        "    model.add(Conv2D(64, 4, activation='relu', strides=2))\r\n",
        "    model.add(Conv2D(64, 3, activation='relu', strides=1))\r\n",
        "    model.add(Flatten())\r\n",
        "    model.add(Dense(512, activation='relu'))\r\n",
        "    model.add(Dense(num_actions, activation=\"linear\"))\r\n",
        "\r\n",
        "    return model\r\n",
        "\r\n",
        "def create_q_model_2():\r\n",
        "    \"\"\"Returns a CNN model.\"\"\"\r\n",
        "\r\n",
        "    model = Sequential()\r\n",
        "    model.add(Conv2D(16, 12, activation='relu', strides=4,\r\n",
        "            input_shape=(96, 96, 3,)))\r\n",
        "    model.add(Conv2D(32, 8, activation='relu', strides=2))\r\n",
        "    model.add(Conv2D(64, 4, activation='relu', strides=2))\r\n",
        "    model.add(Flatten())\r\n",
        "    model.add(Dense(256, activation='relu'))\r\n",
        "    model.add(Dense(num_actions, activation=\"linear\"))\r\n",
        "\r\n",
        "    return model\r\n",
        "\r\n",
        "def cnn_model():\r\n",
        "    \"\"\"Returns a CNN model.\"\"\"\r\n",
        "\r\n",
        "    model = Sequential()\r\n",
        "    model.add(Conv2D(32, (4, 4), activation='relu', strides=1,\r\n",
        "            input_shape=(96, 96, 3,)))\r\n",
        "    model.add(Conv2D(64, (4, 4), activation='relu', strides=2))\r\n",
        "    model.add(Conv2D(128, (4, 4), activation='relu', strides=2))\r\n",
        "    model.add(Flatten())\r\n",
        "    model.add(Dense(512, activation='relu'))\r\n",
        "    model.add(Dense(num_actions, activation=\"linear\"))\r\n",
        "\r\n",
        "    return model\r\n",
        "\r\n",
        "def build_model():\r\n",
        "    \"\"\" Neural Net for Deep-Q learning Model\"\"\"\r\n",
        "\r\n",
        "    model = Sequential()\r\n",
        "    model.add(Conv2D(filters=6, kernel_size=(7, 7), strides=3, activation='relu', input_shape=(56, 56, 3)))\r\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\r\n",
        "    model.add(Conv2D(filters=12, kernel_size=(4, 4), activation='relu'))\r\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\r\n",
        "    model.add(Flatten())\r\n",
        "    model.add(Dense(216, activation='relu'))\r\n",
        "    model.add(Dense(num_actions, activation=None))\r\n",
        "\r\n",
        "    return model\r\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rgb2gray(rgb):\r\n",
        "    \"\"\"Converts RGB image to grayscale.\r\n",
        "        https://stackoverflow.com/questions/63900600/turn-a-image-to-grayscale-in-python\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    return np.dot(rgb[...,:3], [0.2989, 0.5870, 0.1140]).astype(np.int16)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "action = [0.0, 1.0, 0.0]\r\n",
        "gs_buffer = deque()\r\n",
        "\r\n",
        "frame_count = 0\r\n",
        "\r\n",
        "env = gym.make(\"CarRacing-v0\")\r\n",
        "s_prev = env.reset()\r\n",
        "for i in range(50):\r\n",
        "\r\n",
        "    action_reward = 0\r\n",
        "\r\n",
        "    for _ in range(2):\r\n",
        "        s_1, reward, done, info = env.step(action)\r\n",
        "        s_1 = s_1[20:76, 20:76, :]\r\n",
        "        s_1_gs = rgb2gray(s_1)\r\n",
        "        frame_count+=1\r\n",
        "        action_reward += reward\r\n",
        "\r\n",
        "    gs_buffer.append((s_1_gs, frame_count, round(action_reward, 2)))\r\n",
        "\r\n",
        "    if i%3==0 and i>0:\r\n",
        "        img = np.zeros((56, 56, 3))\r\n",
        "        img[:, :, 0] = gs_buffer[0][0]\r\n",
        "        img[:, :, 1] = gs_buffer[1][0]\r\n",
        "        img[:, :, 2] = gs_buffer[2][0]\r\n",
        "\r\n",
        "        fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(8, 8))\r\n",
        "        ax[0].imshow(img[:, :, 0], cmap='gray')\r\n",
        "        ax[1].imshow(img[:, :, 1], cmap='gray')\r\n",
        "        ax[2].imshow(img[:, :, 2], cmap='gray')\r\n",
        "\r\n",
        "        ax[0].set_title(f'frame: {gs_buffer[0][1]}, reward: {gs_buffer[0][2]}')\r\n",
        "        ax[1].set_title(f'frame: {gs_buffer[1][1]}, reward: {gs_buffer[1][2]}')\r\n",
        "        ax[2].set_title(f'frame: {gs_buffer[2][1]}, reward: {gs_buffer[1][2]}')\r\n",
        "\r\n",
        "        ax[0].axis('off')\r\n",
        "        ax[1].axis('off')\r\n",
        "        ax[2].axis('off')\r\n",
        "        plt.show()\r\n",
        "\r\n",
        "        # Remove first image from buffer\r\n",
        "        gs_buffer.popleft()\r\n",
        "\r\n",
        "    s_prev = s_1.copy()\r\n",
        "\r\n",
        "env.close()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "colab": {
      "name": "car_racing.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "gymenv",
      "language": "python",
      "display_name": "Python (gymenv)"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.4",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "accelerator": "GPU",
    "kernel_info": {
      "name": "gymenv"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}